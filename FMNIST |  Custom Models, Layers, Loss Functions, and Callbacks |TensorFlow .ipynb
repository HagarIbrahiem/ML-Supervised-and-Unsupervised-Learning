{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HagarIbrahiem/ML-Supervised-and-Unsupervised-Learning/blob/main/FMNIST%20%7C%20%20Custom%20Models%2C%20Layers%2C%20Loss%20Functions%2C%20and%20Callbacks%20%7CTensorFlow%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYysdyb-CaWM"
      },
      "source": [
        "### Basic classification: Classify images of clothing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbVhjPpzn6BM"
      },
      "source": [
        "This notebook trains a neural network model to classify images of clothing, like sneakers and shirts.\n",
        "\n",
        "The notebook usesthe [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset which contains 70,000 grayscale images in 10 categories.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYa1e1t8piNG"
      },
      "source": [
        "## Import Libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzLKpmZICaWN",
        "outputId": "25b0f74f-58a0-4a3a-bedb-3e8496486d9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import datetime\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR0EdgrLCaWR"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MqDQO0KCaWS",
        "outputId": "3b939d75-dd52-4ecd-92fd-84e4eab6c95f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9FDsUlxCaWW"
      },
      "source": [
        "Loading the dataset returns four NumPy arrays:\n",
        "\n",
        "* The `train_images` and `train_labels` arrays are the *training set*â€”the data the model uses to learn.\n",
        "\n",
        "The images are 28x28 NumPy arrays, with pixel values ranging from 0 to 255. The *labels* are an array of integers, ranging from 0 to 9. These correspond to the *class* of clothing the image represents:\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Label</th>\n",
        "    <th>Class</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>0</td>\n",
        "    <td>T-shirt/top</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>1</td>\n",
        "    <td>Trouser</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>2</td>\n",
        "    <td>Pullover</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>3</td>\n",
        "    <td>Dress</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>4</td>\n",
        "    <td>Coat</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>5</td>\n",
        "    <td>Sandal</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>6</td>\n",
        "    <td>Shirt</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>7</td>\n",
        "    <td>Sneaker</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>8</td>\n",
        "    <td>Bag</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>9</td>\n",
        "    <td>Ankle boot</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "Each image is mapped to a single label. Since the *class names* are not included with the dataset, store them here to use later when plotting the images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjnLH5S2CaWx"
      },
      "outputs": [],
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Brm0b_KACaWX"
      },
      "source": [
        "## Explore the data\n",
        "\n",
        "Let's explore the format of the dataset before training the model. The following shows there are 60,000 images in the training set, with each image represented as 28 x 28 pixels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zW5k_xz1CaWX",
        "outputId": "8cffda88-145d-4016-d8c0-214c5bfbdef3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_images.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIAcvQqMCaWf"
      },
      "source": [
        "Likewise, there are 60,000 labels in the training set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRFYHB2mCaWb",
        "outputId": "c24174fc-1d58-4a46-8809-c49d2b205e80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSlYxFuRCaWk"
      },
      "source": [
        "Each label is an integer between 0 and 9:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKnCTHz4CaWg",
        "outputId": "d69d30a6-f152-4eae-915c-e43f59eafb2f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMPI88iZpO2T"
      },
      "source": [
        "There are 10,000 images in the test set. Again, each image is represented as 28 x 28 pixels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KFnYlcwCaWl",
        "outputId": "9a883361-e0ca-4fd9-a2aa-44d4bca38224"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_images.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd0A0Iu0CaWq"
      },
      "source": [
        "And the test set contains 10,000 images labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJmPr5-ACaWn",
        "outputId": "3201dd36-a82d-41b0-c7e7-3e10d7b61b0a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES6uQoLKCaWr"
      },
      "source": [
        "## Preprocess the data\n",
        "\n",
        "The data must be preprocessed before training the network. If you inspect the first image in the training set, you will see that the pixel values fall in the range of 0 to 255:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "m4VEw8Ud9Quh",
        "outputId": "1b5b57ab-e88e-403d-a048-040edc1243b9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 300x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(3,3))\n",
        "plt.imshow(train_images[0])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz7l27Lz9S1P"
      },
      "source": [
        "Scale these values to a range of 0 to 1 before feeding them to the neural network model. To do so, divide the values by 255. It's important that the *training set* and the *testing set* be preprocessed in the same way:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bW5WzIPlCaWv"
      },
      "outputs": [],
      "source": [
        "train_images = train_images / 255.0\n",
        "\n",
        "test_images = test_images / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee638AlnCaWz"
      },
      "source": [
        " let's display the first 15 images from the *training set* and display the class name below each image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 733
        },
        "id": "oZTImqg_CaW1",
        "outputId": "a09147d0-fae2-401d-c7a1-d2fcb59a3320"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x1000 with 15 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(15):\n",
        "    plt.subplot(3,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[train_labels[i]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59veuiEZCaW4"
      },
      "source": [
        "## Build the model\n",
        "\n",
        "Building the neural network requires configuring the layers of the model, then compiling the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxg1XGm0eOBy"
      },
      "source": [
        "### Set up the layers\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FFHXcxPounU"
      },
      "source": [
        "### 1- Custom Layer | Lambda\n",
        "Define custom layers with the [Lambda](https://keras.io/api/layers/core_layers/lambda/) layer. WE can either use:\n",
        "- [lambda functions](https://www.w3schools.com/python/python_lambda.asp) within the Lambda layer ,or\n",
        "- Define a custom function that the Lambda layer will call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LV25Bins1Ty"
      },
      "outputs": [],
      "source": [
        "# Define a custom function that the Lambda layer will call.\n",
        "def my_relu(x):\n",
        "    return K.maximum(-0.1, x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu17_HE0rZ58"
      },
      "source": [
        "### 2- Custom Layer Class\n",
        "\n",
        "Define a custom layer that inherits the [Layer](https://keras.io/api/layers/base_layer/#layer-class) class. Unlike simple Lambda layers we did previously, the custom layer here will contain weights that can be updated during training.\n",
        "\n",
        "\n",
        "To make custom layer that is trainable, we need to define a class that inherits the [Layer](https://keras.io/api/layers/base_layer/#layer-class) base class from Keras. This class requires three functions:\n",
        "- `__init__()`,\n",
        "- `build()` and\n",
        "-  `call()`.\n",
        "\n",
        " These ensure that our custom layer has a *state* and *computation* that can be accessed during training or inference.\n",
        "\n",
        "\n",
        " **P.S.** : To use the built-in **activations within Custome Layer Class**, we can specify an `activation` parameter in the `__init__()` method of our custom layer class.\n",
        "\n",
        " From there, we can initialize it by using the `tf.keras.activations.get()` method. This takes in a string identifier that corresponds to one of the [available activations](https://keras.io/api/layers/activations/#available-activations) in Keras.\n",
        "\n",
        "  Next, you can now pass in the forward computation to this activation in the `call()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oz1yWTMs6bW"
      },
      "outputs": [],
      "source": [
        "class SimpleDense(Layer):\n",
        "\n",
        "    # add an activation parameter\n",
        "    def __init__(self, units=32, activation=None):\n",
        "        super(SimpleDense, self).__init__()\n",
        "        self.units = units\n",
        "\n",
        "        # define the activation to get from the built-in activation layers in Keras\n",
        "        self.activation = tf.keras.activations.get(activation)\n",
        "\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        w_init = tf.random_normal_initializer()\n",
        "        self.w = tf.Variable(name=\"kernel\",\n",
        "            initial_value=w_init(shape=(input_shape[-1], self.units),\n",
        "                                 dtype='float32'),\n",
        "            trainable=True)\n",
        "        b_init = tf.zeros_initializer()\n",
        "        self.b = tf.Variable(name=\"bias\",\n",
        "            initial_value=b_init(shape=(self.units,), dtype='float32'),\n",
        "            trainable=True)\n",
        "        super().build(input_shape)\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        # pass the computation to the activation layer\n",
        "        return self.activation(tf.matmul(inputs, self.w) + self.b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9H_mgOvJ2qZC"
      },
      "source": [
        "### 3- Custom Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzAtpCcC2vfi"
      },
      "outputs": [],
      "source": [
        "class MyIdentityBlock(tf.keras.Model):\n",
        "    def __init__(self, filters, kernel_size):\n",
        "        super(MyIdentityBlock, self).__init__(name='')\n",
        "\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters, kernel_size, padding='same')\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "        self.conv2 = tf.keras.layers.Conv2D(filters, kernel_size, padding='same')\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "        self.act = tf.keras.layers.Activation('relu')\n",
        "        self.add = tf.keras.layers.Add()\n",
        "\n",
        "    def call(self, input_tensor):\n",
        "        x = self.conv1(input_tensor)\n",
        "        x = self.bn1(x)\n",
        "        x = self.act(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "\n",
        "        x = self.add([x, input_tensor])\n",
        "        x = self.act(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ODch-OFCaW4"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "\n",
        "    #transforms the format of the images from a two-dimensional array (of 28 by 28 pixels) to a one-dimensional array (of 28 * 28 = 784 pixels).\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128),\n",
        "\n",
        "    # # Custom SubModel| Block\n",
        "    # # Use the Identity blocks that you just defined\n",
        "    # MyIdentityBlock(128, 3),\n",
        "\n",
        "\n",
        "    # Custom Lambda Layer : Custome Fun used by Lambda Layer (2nd way)|  Pass in a function defined outside the model.\n",
        "    tf.keras.layers.Lambda(my_relu),\n",
        "    # Custom Lambda Layer: Define Custom Lambda Layer (1nd way)\n",
        "    tf.keras.layers.Lambda(lambda x: tf.abs(x)),\n",
        "\n",
        "    # Custom Layer Class | Without Activation\n",
        "    SimpleDense(128),\n",
        "    # Custom Layer Class | With Activation\n",
        "    SimpleDense(128, activation='relu'),\n",
        "\n",
        "    tf.keras.layers.Dense(10 , activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPVnILI9uYqR"
      },
      "source": [
        "## Compile Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-L4fTJauQ7J"
      },
      "source": [
        "### 4- Custom loss function\n",
        "Define the custom loss function below called `my_rmse()` that returns the RMSE between the target (`y_true`) and prediction (`y_pred`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7mhYwHzuXSX"
      },
      "outputs": [],
      "source": [
        "def my_crossentropy(y_true, y_pred):\n",
        "    # Define your custom loss function\n",
        "    loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lhan11blCaW7"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=my_crossentropy,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKF6uW-BCaW-"
      },
      "source": [
        "## Train Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUJWJs1cvVEs"
      },
      "source": [
        "### 5- Custom Callbacks\n",
        "\n",
        "A custom callback is a powerful tool to customize the behavior of a Keras model during training, evaluation, or inference.\n",
        "\n",
        "\n",
        "Define a simple custom callback to track\n",
        "- the start and\n",
        "- the end of every batch of data.\n",
        "\n",
        " During those calls, it prints the index of the current batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84Tm37MmvpLo"
      },
      "outputs": [],
      "source": [
        "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
        "\n",
        "    def on_train_batch_begin(self, batch, logs=None):\n",
        "        print('Training: batch {} begins at {}'.format(batch, datetime.datetime.now().time()))\n",
        "\n",
        "    # def on_train_batch_end(self, batch, logs=None):\n",
        "    #     print('Training: batch {} ends at {}'.format(batch, datetime.datetime.now().time()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDVjxb6Ix7IM"
      },
      "outputs": [],
      "source": [
        "class DetectOverfittingCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, threshold=0.7):\n",
        "        super(DetectOverfittingCallback, self).__init__()\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        ratio = logs[\"val_loss\"] / logs[\"loss\"]\n",
        "        print(\"Epoch: {}, Val/Train loss ratio: {:.2f}\".format(epoch, ratio))\n",
        "\n",
        "        if ratio > self.threshold:\n",
        "            print(\"Stopping training...\")\n",
        "            self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niX_uSlmw-CB"
      },
      "source": [
        "### An overview of callback methods\n",
        "\n",
        "#### Common methods for training/testing/predicting\n",
        "For training, testing, and predicting, following methods are provided to be overridden.\n",
        "#### `on_(train|test|predict)_begin(self, logs=None)`\n",
        "Called at the beginning of `fit`/`evaluate`/`predict`.\n",
        "#### `on_(train|test|predict)_end(self, logs=None)`\n",
        "Called at the end of `fit`/`evaluate`/`predict`.\n",
        "#### `on_(train|test|predict)_batch_begin(self, batch, logs=None)`\n",
        "Called right before processing a batch during training/testing/predicting. Within this method, `logs` is a dict with `batch` and `size` available keys, representing the current batch number and the size of the batch.\n",
        "#### `on_(train|test|predict)_batch_end(self, batch, logs=None)`\n",
        "Called at the end of training/testing/predicting a batch. Within this method, `logs` is a dict containing the stateful metrics result.\n",
        "\n",
        "### Training specific methods\n",
        "In addition, for training, following are provided.\n",
        "#### `on_epoch_begin(self, epoch, logs=None)`\n",
        "Called at the beginning of an epoch during training.\n",
        "#### `on_epoch_end(self, epoch, logs=None)`\n",
        "Called at the end of an epoch during training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvwvpA64CaW_",
        "outputId": "92b08c77-4e99-4337-803f-acbf750ef11c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Training: batch 630 begins at 08:25:58.420535\n",
            "Training: batch 631 begins at 08:25:58.427067\n",
            "Training: batch 632 begins at 08:25:58.434458\n",
            "Training: batch 633 begins at 08:25:58.441700\n",
            " 634/1875 [=========>....................] - ETA: 10s - loss: 0.2571 - accuracy: 0.9039Training: batch 634 begins at 08:25:58.450573\n",
            "Training: batch 635 begins at 08:25:58.457915\n",
            "Training: batch 636 begins at 08:25:58.465303\n",
            "Training: batch 637 begins at 08:25:58.472705\n",
            "Training: batch 638 begins at 08:25:58.479036\n",
            "Training: batch 639 begins at 08:25:58.485908\n",
            "Training: batch 640 begins at 08:25:58.493442\n",
            " 641/1875 [=========>....................] - ETA: 10s - loss: 0.2585 - accuracy: 0.9035Training: batch 641 begins at 08:25:58.501541\n",
            "Training: batch 642 begins at 08:25:58.508834\n",
            "Training: batch 643 begins at 08:25:58.516210\n",
            "Training: batch 644 begins at 08:25:58.523488\n",
            "Training: batch 645 begins at 08:25:58.531026\n",
            "Training: batch 646 begins at 08:25:58.537941\n",
            "Training: batch 647 begins at 08:25:58.545898\n",
            " 648/1875 [=========>....................] - ETA: 10s - loss: 0.2590 - accuracy: 0.9035Training: batch 648 begins at 08:25:58.555987\n",
            "Training: batch 649 begins at 08:25:58.562846\n",
            "Training: batch 650 begins at 08:25:58.572207\n",
            "Training: batch 651 begins at 08:25:58.578733\n",
            "Training: batch 652 begins at 08:25:58.585615\n",
            "Training: batch 653 begins at 08:25:58.592783\n",
            "Training: batch 654 begins at 08:25:58.599637\n",
            " 655/1875 [=========>....................] - ETA: 10s - loss: 0.2595 - accuracy: 0.9034Training: batch 655 begins at 08:25:58.608326\n",
            "Training: batch 656 begins at 08:25:58.618559\n",
            "Training: batch 657 begins at 08:25:58.626137\n",
            "Training: batch 658 begins at 08:25:58.632331\n",
            "Training: batch 659 begins at 08:25:58.639475\n",
            "Training: batch 660 begins at 08:25:58.646723\n",
            "Training: batch 661 begins at 08:25:58.655187\n",
            " 662/1875 [=========>....................] - ETA: 10s - loss: 0.2593 - accuracy: 0.9035Training: batch 662 begins at 08:25:58.663541\n",
            "Training: batch 663 begins at 08:25:58.672047\n",
            "Training: batch 664 begins at 08:25:58.677775\n",
            "Training: batch 665 begins at 08:25:58.684736\n",
            "Training: batch 666 begins at 08:25:58.692933\n",
            "Training: batch 667 begins at 08:25:58.700310\n",
            "Training: batch 668 begins at 08:25:58.706838\n",
            " 669/1875 [=========>....................] - ETA: 9s - loss: 0.2595 - accuracy: 0.9034 Training: batch 669 begins at 08:25:58.714378\n",
            "Training: batch 670 begins at 08:25:58.721281\n",
            "Training: batch 671 begins at 08:25:58.728374\n",
            "Training: batch 672 begins at 08:25:58.735554\n",
            "Training: batch 673 begins at 08:25:58.744531\n",
            "Training: batch 674 begins at 08:25:58.750537\n",
            "Training: batch 675 begins at 08:25:58.757901\n",
            " 676/1875 [=========>....................] - ETA: 9s - loss: 0.2593 - accuracy: 0.9033Training: batch 676 begins at 08:25:58.766810\n",
            "Training: batch 677 begins at 08:25:58.774976\n",
            "Training: batch 678 begins at 08:25:58.783019\n",
            "Training: batch 679 begins at 08:25:58.792647\n",
            "Training: batch 680 begins at 08:25:58.801103\n",
            "Training: batch 681 begins at 08:25:58.809132\n",
            " 682/1875 [=========>....................] - ETA: 9s - loss: 0.2597 - accuracy: 0.9032Training: batch 682 begins at 08:25:58.818075\n",
            "Training: batch 683 begins at 08:25:58.824715\n",
            "Training: batch 684 begins at 08:25:58.831554\n",
            "Training: batch 685 begins at 08:25:58.837929\n",
            "Training: batch 686 begins at 08:25:58.843886\n",
            "Training: batch 687 begins at 08:25:58.850782\n",
            "Training: batch 688 begins at 08:25:58.858006\n",
            "Training: batch 689 begins at 08:25:58.865388\n",
            " 690/1875 [==========>...................] - ETA: 9s - loss: 0.2594 - accuracy: 0.9034Training: batch 690 begins at 08:25:58.874633\n",
            "Training: batch 691 begins at 08:25:58.881488\n",
            "Training: batch 692 begins at 08:25:58.888594\n",
            "Training: batch 693 begins at 08:25:58.895501\n",
            "Training: batch 694 begins at 08:25:58.903133\n",
            "Training: batch 695 begins at 08:25:58.910337\n",
            "Training: batch 696 begins at 08:25:58.917631\n",
            " 697/1875 [==========>...................] - ETA: 9s - loss: 0.2591 - accuracy: 0.9034Training: batch 697 begins at 08:25:58.925986\n",
            "Training: batch 698 begins at 08:25:58.933076\n",
            "Training: batch 699 begins at 08:25:58.939858\n",
            "Training: batch 700 begins at 08:25:58.946656\n",
            "Training: batch 701 begins at 08:25:58.954603\n",
            "Training: batch 702 begins at 08:25:58.961116\n",
            "Training: batch 703 begins at 08:25:58.968321\n",
            " 704/1875 [==========>...................] - ETA: 9s - loss: 0.2597 - accuracy: 0.9033Training: batch 704 begins at 08:25:58.977109\n",
            "Training: batch 705 begins at 08:25:58.983072\n",
            "Training: batch 706 begins at 08:25:58.989326\n",
            "Training: batch 707 begins at 08:25:58.996848\n",
            "Training: batch 708 begins at 08:25:59.004462\n",
            "Training: batch 709 begins at 08:25:59.011711\n",
            "Training: batch 710 begins at 08:25:59.018562\n",
            "Training: batch 711 begins at 08:25:59.025365\n",
            " 712/1875 [==========>...................] - ETA: 9s - loss: 0.2602 - accuracy: 0.9030Training: batch 712 begins at 08:25:59.033318\n",
            "Training: batch 713 begins at 08:25:59.039989\n",
            "Training: batch 714 begins at 08:25:59.046892\n",
            "Training: batch 715 begins at 08:25:59.052799\n",
            "Training: batch 716 begins at 08:25:59.059834\n",
            "Training: batch 717 begins at 08:25:59.066507\n",
            "Training: batch 718 begins at 08:25:59.073599\n",
            "Training: batch 719 begins at 08:25:59.080914\n",
            " 720/1875 [==========>...................] - ETA: 9s - loss: 0.2600 - accuracy: 0.9030Training: batch 720 begins at 08:25:59.088925\n",
            "Training: batch 721 begins at 08:25:59.096390\n",
            "Training: batch 722 begins at 08:25:59.103602\n",
            "Training: batch 723 begins at 08:25:59.111082\n",
            "Training: batch 724 begins at 08:25:59.118356\n",
            "Training: batch 725 begins at 08:25:59.125666\n",
            "Training: batch 726 begins at 08:25:59.131956\n",
            " 727/1875 [==========>...................] - ETA: 9s - loss: 0.2600 - accuracy: 0.9032Training: batch 727 begins at 08:25:59.142454\n",
            "Training: batch 728 begins at 08:25:59.149748\n",
            "Training: batch 729 begins at 08:25:59.157567\n",
            "Training: batch 730 begins at 08:25:59.163701\n",
            "Training: batch 731 begins at 08:25:59.170654\n",
            "Training: batch 732 begins at 08:25:59.178214\n",
            "Training: batch 733 begins at 08:25:59.184114\n",
            " 734/1875 [==========>...................] - ETA: 9s - loss: 0.2607 - accuracy: 0.9030Training: batch 734 begins at 08:25:59.193222\n",
            "Training: batch 735 begins at 08:25:59.200328\n",
            "Training: batch 736 begins at 08:25:59.207618\n",
            "Training: batch 737 begins at 08:25:59.214687\n",
            "Training: batch 738 begins at 08:25:59.221642\n",
            "Training: batch 739 begins at 08:25:59.229120\n",
            "Training: batch 740 begins at 08:25:59.236431\n",
            " 741/1875 [==========>...................] - ETA: 9s - loss: 0.2605 - accuracy: 0.9030Training: batch 741 begins at 08:25:59.244757\n",
            "Training: batch 742 begins at 08:25:59.251770\n",
            "Training: batch 743 begins at 08:25:59.259626\n",
            "Training: batch 744 begins at 08:25:59.265894\n",
            "Training: batch 745 begins at 08:25:59.272838\n",
            "Training: batch 746 begins at 08:25:59.279034\n",
            "Training: batch 747 begins at 08:25:59.286779\n",
            "Training: batch 748 begins at 08:25:59.292952\n",
            " 749/1875 [==========>...................] - ETA: 9s - loss: 0.2606 - accuracy: 0.9030Training: batch 749 begins at 08:25:59.301695\n",
            "Training: batch 750 begins at 08:25:59.309073\n",
            "Training: batch 751 begins at 08:25:59.315737\n",
            "Training: batch 752 begins at 08:25:59.323562\n",
            "Training: batch 753 begins at 08:25:59.330718\n",
            "Training: batch 754 begins at 08:25:59.337822\n",
            "Training: batch 755 begins at 08:25:59.345037\n",
            " 756/1875 [===========>..................] - ETA: 9s - loss: 0.2609 - accuracy: 0.9028Training: batch 756 begins at 08:25:59.352730\n",
            "Training: batch 757 begins at 08:25:59.359558\n",
            "Training: batch 758 begins at 08:25:59.366485\n",
            "Training: batch 759 begins at 08:25:59.373177\n",
            "Training: batch 760 begins at 08:25:59.380133\n",
            "Training: batch 761 begins at 08:25:59.387476\n",
            "Training: batch 762 begins at 08:25:59.395308\n",
            " 763/1875 [===========>..................] - ETA: 9s - loss: 0.2606 - accuracy: 0.9028Training: batch 763 begins at 08:25:59.403933\n",
            "Training: batch 764 begins at 08:25:59.411045\n",
            "Training: batch 765 begins at 08:25:59.417799\n",
            "Training: batch 766 begins at 08:25:59.425406\n",
            "Training: batch 767 begins at 08:25:59.431913\n",
            "Training: batch 768 begins at 08:25:59.438931\n",
            "Training: batch 769 begins at 08:25:59.446389\n",
            " 770/1875 [===========>..................] - ETA: 8s - loss: 0.2607 - accuracy: 0.9027Training: batch 770 begins at 08:25:59.454836\n",
            "Training: batch 771 begins at 08:25:59.461622\n",
            "Training: batch 772 begins at 08:25:59.469269\n",
            "Training: batch 773 begins at 08:25:59.477281\n",
            "Training: batch 774 begins at 08:25:59.484313\n",
            "Training: batch 775 begins at 08:25:59.490591\n",
            "Training: batch 776 begins at 08:25:59.497504\n",
            " 777/1875 [===========>..................] - ETA: 8s - loss: 0.2610 - accuracy: 0.9025Training: batch 777 begins at 08:25:59.506852\n",
            "Training: batch 778 begins at 08:25:59.515715\n",
            "Training: batch 779 begins at 08:25:59.523682\n",
            "Training: batch 780 begins at 08:25:59.530983\n",
            "Training: batch 781 begins at 08:25:59.538872\n",
            "Training: batch 782 begins at 08:25:59.546161\n",
            "Training: batch 783 begins at 08:25:59.553536\n",
            " 784/1875 [===========>..................] - ETA: 8s - loss: 0.2613 - accuracy: 0.9025Training: batch 784 begins at 08:25:59.562377\n",
            "Training: batch 785 begins at 08:25:59.569100\n",
            "Training: batch 786 begins at 08:25:59.575728\n",
            "Training: batch 787 begins at 08:25:59.583322\n",
            "Training: batch 788 begins at 08:25:59.589745\n",
            "Training: batch 789 begins at 08:25:59.596643\n",
            "Training: batch 790 begins at 08:25:59.603745\n",
            "Training: batch 791 begins at 08:25:59.610658\n",
            " 792/1875 [===========>..................] - ETA: 8s - loss: 0.2616 - accuracy: 0.9023Training: batch 792 begins at 08:25:59.619928\n",
            "Training: batch 793 begins at 08:25:59.627311\n",
            "Training: batch 794 begins at 08:25:59.634490\n",
            "Training: batch 795 begins at 08:25:59.643691\n",
            "Training: batch 796 begins at 08:25:59.649764\n",
            "Training: batch 797 begins at 08:25:59.656919\n",
            "Training: batch 798 begins at 08:25:59.664542\n",
            " 799/1875 [===========>..................] - ETA: 8s - loss: 0.2614 - accuracy: 0.9024Training: batch 799 begins at 08:25:59.673622\n",
            "Training: batch 800 begins at 08:25:59.681756\n",
            "Training: batch 801 begins at 08:25:59.687450\n",
            "Training: batch 802 begins at 08:25:59.695354\n",
            "Training: batch 803 begins at 08:25:59.701738\n",
            "Training: batch 804 begins at 08:25:59.708954\n",
            "Training: batch 805 begins at 08:25:59.715796\n",
            "Training: batch 806 begins at 08:25:59.721842\n",
            " 807/1875 [===========>..................] - ETA: 8s - loss: 0.2610 - accuracy: 0.9026Training: batch 807 begins at 08:25:59.730313\n",
            "Training: batch 808 begins at 08:25:59.737133\n",
            "Training: batch 809 begins at 08:25:59.744726\n",
            "Training: batch 810 begins at 08:25:59.751965\n",
            "Training: batch 811 begins at 08:25:59.760353\n",
            "Training: batch 812 begins at 08:25:59.767572\n",
            "Training: batch 813 begins at 08:25:59.775976\n",
            " 814/1875 [============>.................] - ETA: 8s - loss: 0.2606 - accuracy: 0.9026Training: batch 814 begins at 08:25:59.784855\n",
            "Training: batch 815 begins at 08:25:59.794756\n",
            "Training: batch 816 begins at 08:25:59.801508\n",
            "Training: batch 817 begins at 08:25:59.808894\n",
            "Training: batch 818 begins at 08:25:59.816369\n",
            "Training: batch 819 begins at 08:25:59.823617\n",
            "Training: batch 820 begins at 08:25:59.830659\n",
            " 821/1875 [============>.................] - ETA: 8s - loss: 0.2601 - accuracy: 0.9028Training: batch 821 begins at 08:25:59.839162\n",
            "Training: batch 822 begins at 08:25:59.846066\n",
            "Training: batch 823 begins at 08:25:59.851960\n",
            "Training: batch 824 begins at 08:25:59.858879\n",
            "Training: batch 825 begins at 08:25:59.865425\n",
            "Training: batch 826 begins at 08:25:59.872508\n",
            "Training: batch 827 begins at 08:25:59.880051\n",
            "Training: batch 828 begins at 08:25:59.887461\n",
            " 829/1875 [============>.................] - ETA: 8s - loss: 0.2605 - accuracy: 0.9028Training: batch 829 begins at 08:25:59.894834\n",
            "Training: batch 830 begins at 08:25:59.901262\n",
            "Training: batch 831 begins at 08:25:59.908058\n",
            "Training: batch 832 begins at 08:25:59.915826\n",
            "Training: batch 833 begins at 08:25:59.922594\n",
            "Training: batch 834 begins at 08:25:59.929369\n",
            "Training: batch 835 begins at 08:25:59.936383\n",
            "Training: batch 836 begins at 08:25:59.942841\n",
            " 837/1875 [============>.................] - ETA: 8s - loss: 0.2602 - accuracy: 0.9029Training: batch 837 begins at 08:25:59.952065\n",
            "Training: batch 838 begins at 08:25:59.959718\n",
            "Training: batch 839 begins at 08:25:59.967451\n",
            "Training: batch 840 begins at 08:25:59.975050\n",
            "Training: batch 841 begins at 08:25:59.981442\n",
            "Training: batch 842 begins at 08:25:59.988528\n",
            "Training: batch 843 begins at 08:25:59.995963\n",
            " 844/1875 [============>.................] - ETA: 8s - loss: 0.2608 - accuracy: 0.9027Training: batch 844 begins at 08:26:00.004468\n",
            "Training: batch 845 begins at 08:26:00.012552\n",
            "Training: batch 846 begins at 08:26:00.020329\n",
            "Training: batch 847 begins at 08:26:00.027859\n",
            "Training: batch 848 begins at 08:26:00.035457\n",
            "Training: batch 849 begins at 08:26:00.043055\n",
            "Training: batch 850 begins at 08:26:00.050919\n",
            " 851/1875 [============>.................] - ETA: 8s - loss: 0.2611 - accuracy: 0.9026Training: batch 851 begins at 08:26:00.059247\n",
            "Training: batch 852 begins at 08:26:00.066602\n",
            "Training: batch 853 begins at 08:26:00.074538\n",
            "Training: batch 854 begins at 08:26:00.082490\n",
            "Training: batch 855 begins at 08:26:00.090932\n",
            "Training: batch 856 begins at 08:26:00.098674\n",
            "Training: batch 857 begins at 08:26:00.106528\n",
            " 858/1875 [============>.................] - ETA: 8s - loss: 0.2615 - accuracy: 0.9024Training: batch 858 begins at 08:26:00.115278\n",
            "Training: batch 859 begins at 08:26:00.122879\n",
            "Training: batch 860 begins at 08:26:00.130445\n",
            "Training: batch 861 begins at 08:26:00.137029\n",
            "Training: batch 862 begins at 08:26:00.144593\n",
            "Training: batch 863 begins at 08:26:00.152436\n",
            "Training: batch 864 begins at 08:26:00.160016\n",
            " 865/1875 [============>.................] - ETA: 8s - loss: 0.2616 - accuracy: 0.9024Training: batch 865 begins at 08:26:00.169926\n",
            "Training: batch 866 begins at 08:26:00.177618\n",
            "Training: batch 867 begins at 08:26:00.189298\n",
            "Training: batch 868 begins at 08:26:00.200193\n",
            "Training: batch 869 begins at 08:26:00.207984\n",
            "Training: batch 870 begins at 08:26:00.215204\n",
            " 871/1875 [============>.................] - ETA: 8s - loss: 0.2614 - accuracy: 0.9024Training: batch 871 begins at 08:26:00.224231\n",
            "Training: batch 872 begins at 08:26:00.231253\n",
            "Training: batch 873 begins at 08:26:00.239883\n",
            "Training: batch 874 begins at 08:26:00.245684\n",
            "Training: batch 875 begins at 08:26:00.252957\n",
            "Training: batch 876 begins at 08:26:00.259718\n",
            "Training: batch 877 begins at 08:26:00.266810\n",
            " 878/1875 [=============>................] - ETA: 8s - loss: 0.2613 - accuracy: 0.9024Training: batch 878 begins at 08:26:00.275558\n",
            "Training: batch 879 begins at 08:26:00.281697\n",
            "Training: batch 880 begins at 08:26:00.288766\n",
            "Training: batch 881 begins at 08:26:00.296630\n",
            "Training: batch 882 begins at 08:26:00.304226\n",
            "Training: batch 883 begins at 08:26:00.309709\n",
            "Training: batch 884 begins at 08:26:00.317398\n",
            " 885/1875 [=============>................] - ETA: 7s - loss: 0.2615 - accuracy: 0.9023Training: batch 885 begins at 08:26:00.325984\n",
            "Training: batch 886 begins at 08:26:00.333299\n",
            "Training: batch 887 begins at 08:26:00.341054\n",
            "Training: batch 888 begins at 08:26:00.348888\n",
            "Training: batch 889 begins at 08:26:00.354446\n",
            "Training: batch 890 begins at 08:26:00.361337\n",
            "Training: batch 891 begins at 08:26:00.368640\n",
            " 892/1875 [=============>................] - ETA: 7s - loss: 0.2619 - accuracy: 0.9023Training: batch 892 begins at 08:26:00.378732\n",
            "Training: batch 893 begins at 08:26:00.384397\n",
            "Training: batch 894 begins at 08:26:00.390944\n",
            "Training: batch 895 begins at 08:26:00.398457\n",
            "Training: batch 896 begins at 08:26:00.405408\n",
            "Training: batch 897 begins at 08:26:00.412527\n",
            "Training: batch 898 begins at 08:26:00.424097\n",
            " 899/1875 [=============>................] - ETA: 7s - loss: 0.2617 - accuracy: 0.9024Training: batch 899 begins at 08:26:00.432978\n",
            "Training: batch 900 begins at 08:26:00.438842\n",
            "Training: batch 901 begins at 08:26:00.446331\n",
            "Training: batch 902 begins at 08:26:00.453439\n",
            "Training: batch 903 begins at 08:26:00.460779\n",
            "Training: batch 904 begins at 08:26:00.467426\n",
            "Training: batch 905 begins at 08:26:00.474909\n",
            " 906/1875 [=============>................] - ETA: 7s - loss: 0.2626 - accuracy: 0.9019Training: batch 906 begins at 08:26:00.482822\n",
            "Training: batch 907 begins at 08:26:00.490100\n",
            "Training: batch 908 begins at 08:26:00.497621\n",
            "Training: batch 909 begins at 08:26:00.503367\n",
            "Training: batch 910 begins at 08:26:00.510915\n",
            "Training: batch 911 begins at 08:26:00.518286\n",
            "Training: batch 912 begins at 08:26:00.524943\n",
            " 913/1875 [=============>................] - ETA: 7s - loss: 0.2633 - accuracy: 0.9017Training: batch 913 begins at 08:26:00.533295\n",
            "Training: batch 914 begins at 08:26:00.539012\n",
            "Training: batch 915 begins at 08:26:00.545799\n",
            "Training: batch 916 begins at 08:26:00.553234\n",
            "Training: batch 917 begins at 08:26:00.560301\n",
            "Training: batch 918 begins at 08:26:00.565797\n",
            "Training: batch 919 begins at 08:26:00.572984\n",
            "Training: batch 920 begins at 08:26:00.579693\n",
            " 921/1875 [=============>................] - ETA: 7s - loss: 0.2639 - accuracy: 0.9016Training: batch 921 begins at 08:26:00.587541\n",
            "Training: batch 922 begins at 08:26:00.594627\n",
            "Training: batch 923 begins at 08:26:00.601366\n",
            "Training: batch 924 begins at 08:26:00.608745\n",
            "Training: batch 925 begins at 08:26:00.615331\n",
            "Training: batch 926 begins at 08:26:00.622562\n",
            "Training: batch 927 begins at 08:26:00.629125\n",
            "Training: batch 928 begins at 08:26:00.635871\n",
            " 929/1875 [=============>................] - ETA: 7s - loss: 0.2642 - accuracy: 0.9015Training: batch 929 begins at 08:26:00.643868\n",
            "Training: batch 930 begins at 08:26:00.650587\n",
            "Training: batch 931 begins at 08:26:00.657632\n",
            "Training: batch 932 begins at 08:26:00.664590\n",
            "Training: batch 933 begins at 08:26:00.671633\n",
            "Training: batch 934 begins at 08:26:00.678093\n",
            "Training: batch 935 begins at 08:26:00.685421\n",
            " 936/1875 [=============>................] - ETA: 7s - loss: 0.2644 - accuracy: 0.9014Training: batch 936 begins at 08:26:00.694828\n",
            "Training: batch 937 begins at 08:26:00.701834\n",
            "Training: batch 938 begins at 08:26:00.708727\n",
            "Training: batch 939 begins at 08:26:00.715606\n",
            "Training: batch 940 begins at 08:26:00.722702\n",
            "Training: batch 941 begins at 08:26:00.730277\n",
            "Training: batch 942 begins at 08:26:00.737957\n",
            " 943/1875 [==============>...............] - ETA: 7s - loss: 0.2643 - accuracy: 0.9016Training: batch 943 begins at 08:26:00.746074\n",
            "Training: batch 944 begins at 08:26:00.753486\n",
            "Training: batch 945 begins at 08:26:00.761719\n",
            "Training: batch 946 begins at 08:26:00.768322\n",
            "Training: batch 947 begins at 08:26:00.774622\n",
            "Training: batch 948 begins at 08:26:00.781836\n",
            "Training: batch 949 begins at 08:26:00.793833\n",
            " 950/1875 [==============>...............] - ETA: 7s - loss: 0.2638 - accuracy: 0.9017Training: batch 950 begins at 08:26:00.808463\n",
            "Training: batch 951 begins at 08:26:00.814651\n",
            "Training: batch 952 begins at 08:26:00.820939\n",
            "Training: batch 953 begins at 08:26:00.830210\n",
            "Training: batch 954 begins at 08:26:00.836567\n",
            "Training: batch 955 begins at 08:26:00.844932\n",
            "Training: batch 956 begins at 08:26:00.852393\n",
            " 957/1875 [==============>...............] - ETA: 7s - loss: 0.2636 - accuracy: 0.9018Training: batch 957 begins at 08:26:00.861629\n",
            "Training: batch 958 begins at 08:26:00.868981\n",
            "Training: batch 959 begins at 08:26:00.875196\n",
            "Training: batch 960 begins at 08:26:00.881900\n",
            "Training: batch 961 begins at 08:26:00.888380\n",
            "Training: batch 962 begins at 08:26:00.895510\n",
            "Training: batch 963 begins at 08:26:00.902785\n",
            "Training: batch 964 begins at 08:26:00.909741\n",
            " 965/1875 [==============>...............] - ETA: 7s - loss: 0.2638 - accuracy: 0.9018Training: batch 965 begins at 08:26:00.917626\n",
            "Training: batch 966 begins at 08:26:00.924586\n",
            "Training: batch 967 begins at 08:26:00.931531\n",
            "Training: batch 968 begins at 08:26:00.938932\n",
            "Training: batch 969 begins at 08:26:00.946611\n",
            "Training: batch 970 begins at 08:26:00.953796\n",
            "Training: batch 971 begins at 08:26:00.961419\n",
            " 972/1875 [==============>...............] - ETA: 7s - loss: 0.2649 - accuracy: 0.9015Training: batch 972 begins at 08:26:00.970111\n",
            "Training: batch 973 begins at 08:26:00.977842\n",
            "Training: batch 974 begins at 08:26:00.984600\n",
            "Training: batch 975 begins at 08:26:00.990666\n",
            "Training: batch 976 begins at 08:26:00.996478\n",
            "Training: batch 977 begins at 08:26:01.002505\n",
            "Training: batch 978 begins at 08:26:01.009564\n",
            "Training: batch 979 begins at 08:26:01.017246\n",
            " 980/1875 [==============>...............] - ETA: 7s - loss: 0.2651 - accuracy: 0.9013Training: batch 980 begins at 08:26:01.025230\n",
            "Training: batch 981 begins at 08:26:01.031377\n",
            "Training: batch 982 begins at 08:26:01.038182\n",
            "Training: batch 983 begins at 08:26:01.044384\n",
            "Training: batch 984 begins at 08:26:01.051076\n",
            "Training: batch 985 begins at 08:26:01.058661\n",
            "Training: batch 986 begins at 08:26:01.065721\n",
            "Training: batch 987 begins at 08:26:01.072987\n",
            " 988/1875 [==============>...............] - ETA: 7s - loss: 0.2651 - accuracy: 0.9014Training: batch 988 begins at 08:26:01.082850\n",
            "Training: batch 989 begins at 08:26:01.090540\n",
            "Training: batch 990 begins at 08:26:01.099018\n",
            "Training: batch 991 begins at 08:26:01.108447\n",
            "Training: batch 992 begins at 08:26:01.120278\n",
            "Training: batch 993 begins at 08:26:01.127574\n",
            " 994/1875 [==============>...............] - ETA: 7s - loss: 0.2649 - accuracy: 0.9014Training: batch 994 begins at 08:26:01.135575\n",
            "Training: batch 995 begins at 08:26:01.144514\n",
            "Training: batch 996 begins at 08:26:01.152073\n",
            "Training: batch 997 begins at 08:26:01.159560\n",
            "Training: batch 998 begins at 08:26:01.167107\n",
            "Training: batch 999 begins at 08:26:01.175763\n",
            "Training: batch 1000 begins at 08:26:01.183413\n",
            "1001/1875 [===============>..............] - ETA: 6s - loss: 0.2645 - accuracy: 0.9015Training: batch 1001 begins at 08:26:01.192191\n",
            "Training: batch 1002 begins at 08:26:01.199750\n",
            "Training: batch 1003 begins at 08:26:01.206397\n",
            "Training: batch 1004 begins at 08:26:01.215098\n",
            "Training: batch 1005 begins at 08:26:01.225816\n",
            "Training: batch 1006 begins at 08:26:01.235482\n",
            "1007/1875 [===============>..............] - ETA: 6s - loss: 0.2644 - accuracy: 0.9015Training: batch 1007 begins at 08:26:01.247296\n",
            "Training: batch 1008 begins at 08:26:01.255160\n",
            "Training: batch 1009 begins at 08:26:01.262482\n",
            "Training: batch 1010 begins at 08:26:01.270124\n",
            "Training: batch 1011 begins at 08:26:01.277209\n",
            "Training: batch 1012 begins at 08:26:01.288335\n",
            "1013/1875 [===============>..............] - ETA: 6s - loss: 0.2645 - accuracy: 0.9014Training: batch 1013 begins at 08:26:01.296857\n",
            "Training: batch 1014 begins at 08:26:01.305860\n",
            "Training: batch 1015 begins at 08:26:01.315774\n",
            "Training: batch 1016 begins at 08:26:01.322659\n",
            "Training: batch 1017 begins at 08:26:01.329644\n",
            "Training: batch 1018 begins at 08:26:01.336222\n",
            "Training: batch 1019 begins at 08:26:01.343232\n",
            "1020/1875 [===============>..............] - ETA: 6s - loss: 0.2647 - accuracy: 0.9014Training: batch 1020 begins at 08:26:01.352033\n",
            "Training: batch 1021 begins at 08:26:01.359106\n",
            "Training: batch 1022 begins at 08:26:01.365937\n",
            "Training: batch 1023 begins at 08:26:01.373083\n",
            "Training: batch 1024 begins at 08:26:01.380667\n",
            "Training: batch 1025 begins at 08:26:01.387725\n",
            "Training: batch 1026 begins at 08:26:01.394755\n",
            "1027/1875 [===============>..............] - ETA: 6s - loss: 0.2647 - accuracy: 0.9014Training: batch 1027 begins at 08:26:01.402984\n",
            "Training: batch 1028 begins at 08:26:01.410533\n",
            "Training: batch 1029 begins at 08:26:01.416158\n",
            "Training: batch 1030 begins at 08:26:01.423612\n",
            "Training: batch 1031 begins at 08:26:01.430053\n",
            "Training: batch 1032 begins at 08:26:01.437274\n",
            "Training: batch 1033 begins at 08:26:01.443791\n",
            "Training: batch 1034 begins at 08:26:01.451001\n",
            "1035/1875 [===============>..............] - ETA: 6s - loss: 0.2645 - accuracy: 0.9014Training: batch 1035 begins at 08:26:01.460235\n",
            "Training: batch 1036 begins at 08:26:01.467300\n",
            "Training: batch 1037 begins at 08:26:01.474188\n",
            "Training: batch 1038 begins at 08:26:01.481320\n",
            "Training: batch 1039 begins at 08:26:01.488600\n",
            "Training: batch 1040 begins at 08:26:01.496395\n",
            "Training: batch 1041 begins at 08:26:01.503321\n",
            "1042/1875 [===============>..............] - ETA: 6s - loss: 0.2651 - accuracy: 0.9012Training: batch 1042 begins at 08:26:01.511315\n",
            "Training: batch 1043 begins at 08:26:01.518655\n",
            "Training: batch 1044 begins at 08:26:01.526067\n",
            "Training: batch 1045 begins at 08:26:01.533233\n",
            "Training: batch 1046 begins at 08:26:01.538665\n",
            "Training: batch 1047 begins at 08:26:01.545857\n",
            "Training: batch 1048 begins at 08:26:01.553106\n",
            "Training: batch 1049 begins at 08:26:01.558676\n",
            "1050/1875 [===============>..............] - ETA: 6s - loss: 0.2652 - accuracy: 0.9011Training: batch 1050 begins at 08:26:01.567430\n",
            "Training: batch 1051 begins at 08:26:01.573227\n",
            "Training: batch 1052 begins at 08:26:01.582932\n",
            "Training: batch 1053 begins at 08:26:01.589295\n",
            "Training: batch 1054 begins at 08:26:01.595896\n",
            "Training: batch 1055 begins at 08:26:01.603431\n",
            "Training: batch 1056 begins at 08:26:01.610640\n",
            "1057/1875 [===============>..............] - ETA: 6s - loss: 0.2657 - accuracy: 0.9008Training: batch 1057 begins at 08:26:01.619064\n",
            "Training: batch 1058 begins at 08:26:01.629319\n",
            "Training: batch 1059 begins at 08:26:01.635174\n",
            "Training: batch 1060 begins at 08:26:01.642791\n",
            "Training: batch 1061 begins at 08:26:01.649619\n",
            "Training: batch 1062 begins at 08:26:01.656449\n",
            "Training: batch 1063 begins at 08:26:01.663582\n",
            "1064/1875 [================>.............] - ETA: 6s - loss: 0.2655 - accuracy: 0.9010Training: batch 1064 begins at 08:26:01.672324\n",
            "Training: batch 1065 begins at 08:26:01.679486\n",
            "Training: batch 1066 begins at 08:26:01.686942\n",
            "Training: batch 1067 begins at 08:26:01.693551\n",
            "Training: batch 1068 begins at 08:26:01.700647\n",
            "Training: batch 1069 begins at 08:26:01.707832\n",
            "Training: batch 1070 begins at 08:26:01.713532\n",
            "Training: batch 1071 begins at 08:26:01.720682\n",
            "1072/1875 [================>.............] - ETA: 6s - loss: 0.2664 - accuracy: 0.9007Training: batch 1072 begins at 08:26:01.729540\n",
            "Training: batch 1073 begins at 08:26:01.736759\n",
            "Training: batch 1074 begins at 08:26:01.742375\n",
            "Training: batch 1075 begins at 08:26:01.750526\n",
            "Training: batch 1076 begins at 08:26:01.758746\n",
            "Training: batch 1077 begins at 08:26:01.766345\n",
            "Training: batch 1078 begins at 08:26:01.774082\n",
            "1079/1875 [================>.............] - ETA: 6s - loss: 0.2660 - accuracy: 0.9009Training: batch 1079 begins at 08:26:01.783687\n",
            "Training: batch 1080 begins at 08:26:01.792496\n",
            "Training: batch 1081 begins at 08:26:01.798889\n",
            "Training: batch 1082 begins at 08:26:01.806266\n",
            "Training: batch 1083 begins at 08:26:01.813294\n",
            "Training: batch 1084 begins at 08:26:01.822471\n",
            "Training: batch 1085 begins at 08:26:01.828115\n",
            "1086/1875 [================>.............] - ETA: 6s - loss: 0.2658 - accuracy: 0.9011Training: batch 1086 begins at 08:26:01.839343\n",
            "Training: batch 1087 begins at 08:26:01.850468\n",
            "Training: batch 1088 begins at 08:26:01.858739\n",
            "Training: batch 1089 begins at 08:26:01.864661\n",
            "Training: batch 1090 begins at 08:26:01.871944\n",
            "Training: batch 1091 begins at 08:26:01.878910\n",
            "Training: batch 1092 begins at 08:26:01.887316\n",
            "1093/1875 [================>.............] - ETA: 6s - loss: 0.2657 - accuracy: 0.9011Training: batch 1093 begins at 08:26:01.895677\n",
            "Training: batch 1094 begins at 08:26:01.902731\n",
            "Training: batch 1095 begins at 08:26:01.910050\n",
            "Training: batch 1096 begins at 08:26:01.917794\n",
            "Training: batch 1097 begins at 08:26:01.924928\n",
            "Training: batch 1098 begins at 08:26:01.932357\n",
            "Training: batch 1099 begins at 08:26:01.940059\n",
            "1100/1875 [================>.............] - ETA: 6s - loss: 0.2656 - accuracy: 0.9011Training: batch 1100 begins at 08:26:01.948263\n",
            "Training: batch 1101 begins at 08:26:01.955602\n",
            "Training: batch 1102 begins at 08:26:01.962988\n",
            "Training: batch 1103 begins at 08:26:01.972113\n",
            "Training: batch 1104 begins at 08:26:01.979793\n",
            "Training: batch 1105 begins at 08:26:01.987744\n",
            "Training: batch 1106 begins at 08:26:01.995761\n",
            "1107/1875 [================>.............] - ETA: 6s - loss: 0.2659 - accuracy: 0.9010Training: batch 1107 begins at 08:26:02.006217\n",
            "Training: batch 1108 begins at 08:26:02.013919\n",
            "Training: batch 1109 begins at 08:26:02.023421\n",
            "Training: batch 1110 begins at 08:26:02.035023\n",
            "Training: batch 1111 begins at 08:26:02.041767\n",
            "Training: batch 1112 begins at 08:26:02.052073\n",
            "1113/1875 [================>.............] - ETA: 6s - loss: 0.2656 - accuracy: 0.9011Training: batch 1113 begins at 08:26:02.065821\n",
            "Training: batch 1114 begins at 08:26:02.072822\n",
            "Training: batch 1115 begins at 08:26:02.079305\n",
            "Training: batch 1116 begins at 08:26:02.085578\n",
            "Training: batch 1117 begins at 08:26:02.091763\n",
            "Training: batch 1118 begins at 08:26:02.099308\n",
            "Training: batch 1119 begins at 08:26:02.105929\n",
            "1120/1875 [================>.............] - ETA: 6s - loss: 0.2660 - accuracy: 0.9009Training: batch 1120 begins at 08:26:02.118542\n",
            "Training: batch 1121 begins at 08:26:02.125848\n",
            "Training: batch 1122 begins at 08:26:02.133937\n",
            "Training: batch 1123 begins at 08:26:02.140514\n",
            "Training: batch 1124 begins at 08:26:02.146238\n",
            "Training: batch 1125 begins at 08:26:02.154484\n",
            "Training: batch 1126 begins at 08:26:02.160695\n",
            "1127/1875 [=================>............] - ETA: 5s - loss: 0.2659 - accuracy: 0.9009Training: batch 1127 begins at 08:26:02.171285\n",
            "Training: batch 1128 begins at 08:26:02.181031\n",
            "Training: batch 1129 begins at 08:26:02.188417\n",
            "Training: batch 1130 begins at 08:26:02.196494\n",
            "Training: batch 1131 begins at 08:26:02.203200\n",
            "Training: batch 1132 begins at 08:26:02.211451\n",
            "1133/1875 [=================>............] - ETA: 5s - loss: 0.2661 - accuracy: 0.9009Training: batch 1133 begins at 08:26:02.219940\n",
            "Training: batch 1134 begins at 08:26:02.228113\n",
            "Training: batch 1135 begins at 08:26:02.234353\n",
            "Training: batch 1136 begins at 08:26:02.240894\n",
            "Training: batch 1137 begins at 08:26:02.253393\n",
            "Training: batch 1138 begins at 08:26:02.260986\n",
            "1139/1875 [=================>............] - ETA: 5s - loss: 0.2659 - accuracy: 0.9008Training: batch 1139 begins at 08:26:02.272034\n",
            "Training: batch 1140 begins at 08:26:02.278107\n",
            "Training: batch 1141 begins at 08:26:02.287575\n",
            "Training: batch 1142 begins at 08:26:02.293823\n",
            "Training: batch 1143 begins at 08:26:02.301896\n",
            "Training: batch 1144 begins at 08:26:02.309290\n",
            "1145/1875 [=================>............] - ETA: 5s - loss: 0.2666 - accuracy: 0.9007Training: batch 1145 begins at 08:26:02.322573\n",
            "Training: batch 1146 begins at 08:26:02.330096\n",
            "Training: batch 1147 begins at 08:26:02.338741\n",
            "Training: batch 1148 begins at 08:26:02.347727\n",
            "Training: batch 1149 begins at 08:26:02.354882\n",
            "Training: batch 1150 begins at 08:26:02.364055\n",
            "1151/1875 [=================>............] - ETA: 5s - loss: 0.2666 - accuracy: 0.9007Training: batch 1151 begins at 08:26:02.374303\n",
            "Training: batch 1152 begins at 08:26:02.381880\n",
            "Training: batch 1153 begins at 08:26:02.388919\n",
            "Training: batch 1154 begins at 08:26:02.395876\n",
            "Training: batch 1155 begins at 08:26:02.403120\n",
            "Training: batch 1156 begins at 08:26:02.410824\n",
            "Training: batch 1157 begins at 08:26:02.416698\n",
            "1158/1875 [=================>............] - ETA: 5s - loss: 0.2671 - accuracy: 0.9005Training: batch 1158 begins at 08:26:02.426425\n",
            "Training: batch 1159 begins at 08:26:02.432686\n",
            "Training: batch 1160 begins at 08:26:02.439818\n",
            "Training: batch 1161 begins at 08:26:02.447873\n",
            "Training: batch 1162 begins at 08:26:02.455185\n",
            "Training: batch 1163 begins at 08:26:02.461969\n",
            "Training: batch 1164 begins at 08:26:02.468475\n",
            "1165/1875 [=================>............] - ETA: 5s - loss: 0.2673 - accuracy: 0.9005Training: batch 1165 begins at 08:26:02.482902\n",
            "Training: batch 1166 begins at 08:26:02.489662\n",
            "Training: batch 1167 begins at 08:26:02.498535\n",
            "Training: batch 1168 begins at 08:26:02.507831\n",
            "Training: batch 1169 begins at 08:26:02.513997\n",
            "Training: batch 1170 begins at 08:26:02.523740\n",
            "1171/1875 [=================>............] - ETA: 5s - loss: 0.2674 - accuracy: 0.9002Training: batch 1171 begins at 08:26:02.535294\n",
            "Training: batch 1172 begins at 08:26:02.541452\n",
            "Training: batch 1173 begins at 08:26:02.547475\n",
            "Training: batch 1174 begins at 08:26:02.553427\n",
            "Training: batch 1175 begins at 08:26:02.559520\n",
            "Training: batch 1176 begins at 08:26:02.565607\n",
            "Training: batch 1177 begins at 08:26:02.571638\n",
            "Training: batch 1178 begins at 08:26:02.577494\n",
            "1179/1875 [=================>............] - ETA: 5s - loss: 0.2675 - accuracy: 0.9002Training: batch 1179 begins at 08:26:02.589487\n",
            "Training: batch 1180 begins at 08:26:02.595512\n",
            "Training: batch 1181 begins at 08:26:02.607283\n",
            "Training: batch 1182 begins at 08:26:02.612389\n",
            "Training: batch 1183 begins at 08:26:02.625435\n",
            "Training: batch 1184 begins at 08:26:02.631398\n",
            "1185/1875 [=================>............] - ETA: 5s - loss: 0.2673 - accuracy: 0.9003Training: batch 1185 begins at 08:26:02.642164\n",
            "Training: batch 1186 begins at 08:26:02.648406\n",
            "Training: batch 1187 begins at 08:26:02.657868\n",
            "Training: batch 1188 begins at 08:26:02.666933\n",
            "Training: batch 1189 begins at 08:26:02.677206\n",
            "Training: batch 1190 begins at 08:26:02.686252\n",
            "1191/1875 [==================>...........] - ETA: 5s - loss: 0.2672 - accuracy: 0.9003Training: batch 1191 begins at 08:26:02.698555\n",
            "Training: batch 1192 begins at 08:26:02.704822\n",
            "Training: batch 1193 begins at 08:26:02.713125\n",
            "Training: batch 1194 begins at 08:26:02.723410\n",
            "Training: batch 1195 begins at 08:26:02.733262\n",
            "Training: batch 1196 begins at 08:26:02.739552\n",
            "1197/1875 [==================>...........] - ETA: 5s - loss: 0.2673 - accuracy: 0.9004Training: batch 1197 begins at 08:26:02.752556\n",
            "Training: batch 1198 begins at 08:26:02.758789\n",
            "Training: batch 1199 begins at 08:26:02.766719\n",
            "Training: batch 1200 begins at 08:26:02.774357\n",
            "Training: batch 1201 begins at 08:26:02.783688\n",
            "Training: batch 1202 begins at 08:26:02.794139\n",
            "1203/1875 [==================>...........] - ETA: 5s - loss: 0.2669 - accuracy: 0.9005Training: batch 1203 begins at 08:26:02.805950\n",
            "Training: batch 1204 begins at 08:26:02.812406\n",
            "Training: batch 1205 begins at 08:26:02.821934\n",
            "Training: batch 1206 begins at 08:26:02.830530\n",
            "Training: batch 1207 begins at 08:26:02.840164\n",
            "Training: batch 1208 begins at 08:26:02.846465\n",
            "1209/1875 [==================>...........] - ETA: 5s - loss: 0.2668 - accuracy: 0.9006Training: batch 1209 begins at 08:26:02.857738\n",
            "Training: batch 1210 begins at 08:26:02.865831\n",
            "Training: batch 1211 begins at 08:26:02.871817\n",
            "Training: batch 1212 begins at 08:26:02.879823\n",
            "Training: batch 1213 begins at 08:26:02.885774\n",
            "Training: batch 1214 begins at 08:26:02.894454\n",
            "Training: batch 1215 begins at 08:26:02.900246\n",
            "1216/1875 [==================>...........] - ETA: 5s - loss: 0.2671 - accuracy: 0.9006Training: batch 1216 begins at 08:26:02.910174\n",
            "Training: batch 1217 begins at 08:26:02.916160\n",
            "Training: batch 1218 begins at 08:26:02.923987\n",
            "Training: batch 1219 begins at 08:26:02.929936\n",
            "Training: batch 1220 begins at 08:26:02.938087\n",
            "Training: batch 1221 begins at 08:26:02.945997\n",
            "Training: batch 1222 begins at 08:26:02.953761\n",
            "1223/1875 [==================>...........] - ETA: 5s - loss: 0.2668 - accuracy: 0.9007Training: batch 1223 begins at 08:26:02.963458\n",
            "Training: batch 1224 begins at 08:26:02.969755\n",
            "Training: batch 1225 begins at 08:26:02.975692\n",
            "Training: batch 1226 begins at 08:26:02.986891\n",
            "Training: batch 1227 begins at 08:26:02.993024\n",
            "Training: batch 1228 begins at 08:26:02.999084\n",
            "Training: batch 1229 begins at 08:26:03.009785\n",
            "1230/1875 [==================>...........] - ETA: 5s - loss: 0.2669 - accuracy: 0.9006Training: batch 1230 begins at 08:26:03.022827\n",
            "Training: batch 1231 begins at 08:26:03.028934\n",
            "Training: batch 1232 begins at 08:26:03.039492\n",
            "Training: batch 1233 begins at 08:26:03.047758\n",
            "Training: batch 1234 begins at 08:26:03.053602\n",
            "Training: batch 1235 begins at 08:26:03.061714\n",
            "1236/1875 [==================>...........] - ETA: 5s - loss: 0.2667 - accuracy: 0.9007Training: batch 1236 begins at 08:26:03.072465\n",
            "Training: batch 1237 begins at 08:26:03.078483\n",
            "Training: batch 1238 begins at 08:26:03.086532\n",
            "Training: batch 1239 begins at 08:26:03.095478\n",
            "Training: batch 1240 begins at 08:26:03.101446\n",
            "Training: batch 1241 begins at 08:26:03.109430\n",
            "Training: batch 1242 begins at 08:26:03.118187\n",
            "1243/1875 [==================>...........] - ETA: 5s - loss: 0.2667 - accuracy: 0.9007Training: batch 1243 begins at 08:26:03.126398\n",
            "Training: batch 1244 begins at 08:26:03.132454\n",
            "Training: batch 1245 begins at 08:26:03.140345\n",
            "Training: batch 1246 begins at 08:26:03.146250\n",
            "Training: batch 1247 begins at 08:26:03.152055\n",
            "Training: batch 1248 begins at 08:26:03.157804\n",
            "Training: batch 1249 begins at 08:26:03.167083\n",
            "Training: batch 1250 begins at 08:26:03.172800\n",
            "1251/1875 [===================>..........] - ETA: 4s - loss: 0.2666 - accuracy: 0.9009Training: batch 1251 begins at 08:26:03.182753\n",
            "Training: batch 1252 begins at 08:26:03.188821\n",
            "Training: batch 1253 begins at 08:26:03.196979\n",
            "Training: batch 1254 begins at 08:26:03.202984\n",
            "Training: batch 1255 begins at 08:26:03.210957\n",
            "Training: batch 1256 begins at 08:26:03.219848\n",
            "Training: batch 1257 begins at 08:26:03.226084\n",
            "1258/1875 [===================>..........] - ETA: 4s - loss: 0.2668 - accuracy: 0.9008Training: batch 1258 begins at 08:26:03.237426\n",
            "Training: batch 1259 begins at 08:26:03.243661\n",
            "Training: batch 1260 begins at 08:26:03.253882\n",
            "Training: batch 1261 begins at 08:26:03.260086\n",
            "Training: batch 1262 begins at 08:26:03.269235\n",
            "Training: batch 1263 begins at 08:26:03.275126\n",
            "Training: batch 1264 begins at 08:26:03.284065\n",
            "1265/1875 [===================>..........] - ETA: 4s - loss: 0.2665 - accuracy: 0.9009Training: batch 1265 begins at 08:26:03.294404\n",
            "Training: batch 1266 begins at 08:26:03.303138\n",
            "Training: batch 1267 begins at 08:26:03.308285\n",
            "Training: batch 1268 begins at 08:26:03.317937\n",
            "Training: batch 1269 begins at 08:26:03.325824\n",
            "Training: batch 1270 begins at 08:26:03.335365\n",
            "1271/1875 [===================>..........] - ETA: 4s - loss: 0.2665 - accuracy: 0.9008Training: batch 1271 begins at 08:26:03.344778\n",
            "Training: batch 1272 begins at 08:26:03.351470\n",
            "Training: batch 1273 begins at 08:26:03.357942\n",
            "Training: batch 1274 begins at 08:26:03.363202\n",
            "Training: batch 1275 begins at 08:26:03.372925\n",
            "Training: batch 1276 begins at 08:26:03.379707\n",
            "Training: batch 1277 begins at 08:26:03.387342\n",
            "1278/1875 [===================>..........] - ETA: 4s - loss: 0.2663 - accuracy: 0.9009Training: batch 1278 begins at 08:26:03.397696\n",
            "Training: batch 1279 begins at 08:26:03.404954\n",
            "Training: batch 1280 begins at 08:26:03.410756\n",
            "Training: batch 1281 begins at 08:26:03.419791\n",
            "Training: batch 1282 begins at 08:26:03.429040\n",
            "Training: batch 1283 begins at 08:26:03.435180\n",
            "Training: batch 1284 begins at 08:26:03.443689\n",
            "1285/1875 [===================>..........] - ETA: 4s - loss: 0.2660 - accuracy: 0.9010Training: batch 1285 begins at 08:26:03.456520\n",
            "Training: batch 1286 begins at 08:26:03.462684\n",
            "Training: batch 1287 begins at 08:26:03.468886\n",
            "Training: batch 1288 begins at 08:26:03.479434\n",
            "Training: batch 1289 begins at 08:26:03.488197\n",
            "Training: batch 1290 begins at 08:26:03.494483\n",
            "1291/1875 [===================>..........] - ETA: 4s - loss: 0.2662 - accuracy: 0.9007Training: batch 1291 begins at 08:26:03.506351\n",
            "Training: batch 1292 begins at 08:26:03.512276\n",
            "Training: batch 1293 begins at 08:26:03.520835\n",
            "Training: batch 1294 begins at 08:26:03.527929\n",
            "Training: batch 1295 begins at 08:26:03.533946\n",
            "Training: batch 1296 begins at 08:26:03.539232\n",
            "Training: batch 1297 begins at 08:26:03.550898\n",
            "1298/1875 [===================>..........] - ETA: 4s - loss: 0.2666 - accuracy: 0.9007Training: batch 1298 begins at 08:26:03.559450\n",
            "Training: batch 1299 begins at 08:26:03.566784\n",
            "Training: batch 1300 begins at 08:26:03.574434\n",
            "Training: batch 1301 begins at 08:26:03.583252\n",
            "Training: batch 1302 begins at 08:26:03.589597\n",
            "Training: batch 1303 begins at 08:26:03.596271\n",
            "Training: batch 1304 begins at 08:26:03.603346\n",
            "1305/1875 [===================>..........] - ETA: 4s - loss: 0.2667 - accuracy: 0.9007Training: batch 1305 begins at 08:26:03.611816\n",
            "Training: batch 1306 begins at 08:26:03.619381\n",
            "Training: batch 1307 begins at 08:26:03.627007\n",
            "Training: batch 1308 begins at 08:26:03.634633\n",
            "Training: batch 1309 begins at 08:26:03.641006\n",
            "Training: batch 1310 begins at 08:26:03.646811\n",
            "Training: batch 1311 begins at 08:26:03.653341\n",
            "1312/1875 [===================>..........] - ETA: 4s - loss: 0.2666 - accuracy: 0.9007Training: batch 1312 begins at 08:26:03.661910\n",
            "Training: batch 1313 begins at 08:26:03.669298\n",
            "Training: batch 1314 begins at 08:26:03.674816\n",
            "Training: batch 1315 begins at 08:26:03.683312\n",
            "Training: batch 1316 begins at 08:26:03.692608\n",
            "Training: batch 1317 begins at 08:26:03.698128\n",
            "Training: batch 1318 begins at 08:26:03.704491\n",
            "Training: batch 1319 begins at 08:26:03.710555\n",
            "1320/1875 [====================>.........] - ETA: 4s - loss: 0.2669 - accuracy: 0.9005Training: batch 1320 begins at 08:26:03.722675\n",
            "Training: batch 1321 begins at 08:26:03.729391\n",
            "Training: batch 1322 begins at 08:26:03.737322\n",
            "Training: batch 1323 begins at 08:26:03.746585\n",
            "Training: batch 1324 begins at 08:26:03.752649\n",
            "Training: batch 1325 begins at 08:26:03.760735\n",
            "1326/1875 [====================>.........] - ETA: 4s - loss: 0.2670 - accuracy: 0.9004Training: batch 1326 begins at 08:26:03.771630\n",
            "Training: batch 1327 begins at 08:26:03.777749\n",
            "Training: batch 1328 begins at 08:26:03.785851\n",
            "Training: batch 1329 begins at 08:26:03.794300\n",
            "Training: batch 1330 begins at 08:26:03.801903\n",
            "Training: batch 1331 begins at 08:26:03.811087\n",
            "Training: batch 1332 begins at 08:26:03.818115\n",
            "1333/1875 [====================>.........] - ETA: 4s - loss: 0.2667 - accuracy: 0.9006Training: batch 1333 begins at 08:26:03.829619\n",
            "Training: batch 1334 begins at 08:26:03.835770\n",
            "Training: batch 1335 begins at 08:26:03.844486\n",
            "Training: batch 1336 begins at 08:26:03.852775\n",
            "Training: batch 1337 begins at 08:26:03.859278\n",
            "Training: batch 1338 begins at 08:26:03.865530\n",
            "Training: batch 1339 begins at 08:26:03.871941\n",
            "1340/1875 [====================>.........] - ETA: 4s - loss: 0.2668 - accuracy: 0.9005Training: batch 1340 begins at 08:26:03.882620\n",
            "Training: batch 1341 begins at 08:26:03.888885\n",
            "Training: batch 1342 begins at 08:26:03.898008\n",
            "Training: batch 1343 begins at 08:26:03.906746\n",
            "Training: batch 1344 begins at 08:26:03.913722\n",
            "Training: batch 1345 begins at 08:26:03.921698\n",
            "1346/1875 [====================>.........] - ETA: 4s - loss: 0.2665 - accuracy: 0.9006Training: batch 1346 begins at 08:26:03.933371\n",
            "Training: batch 1347 begins at 08:26:03.942667\n",
            "Training: batch 1348 begins at 08:26:03.949320\n",
            "Training: batch 1349 begins at 08:26:03.959688\n",
            "Training: batch 1350 begins at 08:26:03.967277\n",
            "Training: batch 1351 begins at 08:26:03.973744\n",
            "1352/1875 [====================>.........] - ETA: 4s - loss: 0.2666 - accuracy: 0.9006Training: batch 1352 begins at 08:26:03.983890\n",
            "Training: batch 1353 begins at 08:26:03.990546\n",
            "Training: batch 1354 begins at 08:26:03.998020\n",
            "Training: batch 1355 begins at 08:26:04.004805\n",
            "Training: batch 1356 begins at 08:26:04.011613\n",
            "Training: batch 1357 begins at 08:26:04.020452\n",
            "Training: batch 1358 begins at 08:26:04.026833\n",
            "1359/1875 [====================>.........] - ETA: 4s - loss: 0.2666 - accuracy: 0.9006Training: batch 1359 begins at 08:26:04.036581\n",
            "Training: batch 1360 begins at 08:26:04.044074\n",
            "Training: batch 1361 begins at 08:26:04.050452\n",
            "Training: batch 1362 begins at 08:26:04.058193\n",
            "Training: batch 1363 begins at 08:26:04.064951\n",
            "Training: batch 1364 begins at 08:26:04.070858\n",
            "Training: batch 1365 begins at 08:26:04.078450\n",
            "1366/1875 [====================>.........] - ETA: 4s - loss: 0.2661 - accuracy: 0.9007Training: batch 1366 begins at 08:26:04.086895\n",
            "Training: batch 1367 begins at 08:26:04.098942\n",
            "Training: batch 1368 begins at 08:26:04.106863\n",
            "Training: batch 1369 begins at 08:26:04.113047\n",
            "Training: batch 1370 begins at 08:26:04.119816\n",
            "Training: batch 1371 begins at 08:26:04.126853\n",
            "Training: batch 1372 begins at 08:26:04.133213\n",
            "1373/1875 [====================>.........] - ETA: 4s - loss: 0.2655 - accuracy: 0.9009Training: batch 1373 begins at 08:26:04.143353\n",
            "Training: batch 1374 begins at 08:26:04.149767\n",
            "Training: batch 1375 begins at 08:26:04.155828\n",
            "Training: batch 1376 begins at 08:26:04.162023\n",
            "Training: batch 1377 begins at 08:26:04.170210\n",
            "Training: batch 1378 begins at 08:26:04.177016\n",
            "Training: batch 1379 begins at 08:26:04.183723\n",
            "1380/1875 [=====================>........] - ETA: 3s - loss: 0.2660 - accuracy: 0.9007Training: batch 1380 begins at 08:26:04.194209\n",
            "Training: batch 1381 begins at 08:26:04.200325\n",
            "Training: batch 1382 begins at 08:26:04.208162\n",
            "Training: batch 1383 begins at 08:26:04.214917\n",
            "Training: batch 1384 begins at 08:26:04.220622\n",
            "Training: batch 1385 begins at 08:26:04.227893\n",
            "Training: batch 1386 begins at 08:26:04.235827\n",
            "1387/1875 [=====================>........] - ETA: 3s - loss: 0.2656 - accuracy: 0.9008Training: batch 1387 begins at 08:26:04.246170\n",
            "Training: batch 1388 begins at 08:26:04.252829\n",
            "Training: batch 1389 begins at 08:26:04.258922\n",
            "Training: batch 1390 begins at 08:26:04.268054\n",
            "Training: batch 1391 begins at 08:26:04.275537\n",
            "Training: batch 1392 begins at 08:26:04.281676\n",
            "Training: batch 1393 begins at 08:26:04.288015\n",
            "1394/1875 [=====================>........] - ETA: 3s - loss: 0.2658 - accuracy: 0.9007Training: batch 1394 begins at 08:26:04.297832\n",
            "Training: batch 1395 begins at 08:26:04.304377\n",
            "Training: batch 1396 begins at 08:26:04.310601\n",
            "Training: batch 1397 begins at 08:26:04.318070\n",
            "Training: batch 1398 begins at 08:26:04.326890\n",
            "Training: batch 1399 begins at 08:26:04.332890\n",
            "Training: batch 1400 begins at 08:26:04.343888\n",
            "1401/1875 [=====================>........] - ETA: 3s - loss: 0.2657 - accuracy: 0.9008Training: batch 1401 begins at 08:26:04.352931\n",
            "Training: batch 1402 begins at 08:26:04.359235\n",
            "Training: batch 1403 begins at 08:26:04.367215\n",
            "Training: batch 1404 begins at 08:26:04.373545\n",
            "Training: batch 1405 begins at 08:26:04.382360\n",
            "Training: batch 1406 begins at 08:26:04.389969\n",
            "Training: batch 1407 begins at 08:26:04.395826\n",
            "1408/1875 [=====================>........] - ETA: 3s - loss: 0.2653 - accuracy: 0.9008Training: batch 1408 begins at 08:26:04.407749\n",
            "Training: batch 1409 begins at 08:26:04.417984\n",
            "Training: batch 1410 begins at 08:26:04.424195\n",
            "Training: batch 1411 begins at 08:26:04.433896\n",
            "Training: batch 1412 begins at 08:26:04.440105\n",
            "Training: batch 1413 begins at 08:26:04.446362\n",
            "Training: batch 1414 begins at 08:26:04.455034\n",
            "1415/1875 [=====================>........] - ETA: 3s - loss: 0.2652 - accuracy: 0.9009Training: batch 1415 begins at 08:26:04.462433\n",
            "Training: batch 1416 begins at 08:26:04.469245\n",
            "Training: batch 1417 begins at 08:26:04.475803\n",
            "Training: batch 1418 begins at 08:26:04.484769\n",
            "Training: batch 1419 begins at 08:26:04.490904\n",
            "Training: batch 1420 begins at 08:26:04.501967\n",
            "Training: batch 1421 begins at 08:26:04.508181\n",
            "1422/1875 [=====================>........] - ETA: 3s - loss: 0.2654 - accuracy: 0.9007Training: batch 1422 begins at 08:26:04.515325\n",
            "Training: batch 1423 begins at 08:26:04.522077\n",
            "Training: batch 1424 begins at 08:26:04.533225\n",
            "Training: batch 1425 begins at 08:26:04.537818\n",
            "Training: batch 1426 begins at 08:26:04.549240\n",
            "Training: batch 1427 begins at 08:26:04.552771\n",
            "Training: batch 1428 begins at 08:26:04.562795\n",
            "1429/1875 [=====================>........] - ETA: 3s - loss: 0.2654 - accuracy: 0.9008Training: batch 1429 begins at 08:26:04.570411\n",
            "Training: batch 1430 begins at 08:26:04.579840\n",
            "Training: batch 1431 begins at 08:26:04.585728\n",
            "Training: batch 1432 begins at 08:26:04.593190\n",
            "Training: batch 1433 begins at 08:26:04.600101\n",
            "Training: batch 1434 begins at 08:26:04.606748\n",
            "Training: batch 1435 begins at 08:26:04.613788\n",
            "1436/1875 [=====================>........] - ETA: 3s - loss: 0.2659 - accuracy: 0.9006Training: batch 1436 begins at 08:26:04.622095\n",
            "Training: batch 1437 begins at 08:26:04.629543\n",
            "Training: batch 1438 begins at 08:26:04.639502\n",
            "Training: batch 1439 begins at 08:26:04.644658\n",
            "Training: batch 1440 begins at 08:26:04.653398\n",
            "Training: batch 1441 begins at 08:26:04.659738\n",
            "Training: batch 1442 begins at 08:26:04.666065\n",
            "1443/1875 [======================>.......] - ETA: 3s - loss: 0.2656 - accuracy: 0.9006Training: batch 1443 begins at 08:26:04.676058\n",
            "Training: batch 1444 begins at 08:26:04.681762\n",
            "Training: batch 1445 begins at 08:26:04.690343\n",
            "Training: batch 1446 begins at 08:26:04.699352\n",
            "Training: batch 1447 begins at 08:26:04.703487\n",
            "Training: batch 1448 begins at 08:26:04.711775\n",
            "Training: batch 1449 begins at 08:26:04.720570\n",
            "1450/1875 [======================>.......] - ETA: 3s - loss: 0.2656 - accuracy: 0.9006Training: batch 1450 begins at 08:26:04.731565\n",
            "Training: batch 1451 begins at 08:26:04.737774\n",
            "Training: batch 1452 begins at 08:26:04.746851\n",
            "Training: batch 1453 begins at 08:26:04.756962\n",
            "Training: batch 1454 begins at 08:26:04.765597\n",
            "Training: batch 1455 begins at 08:26:04.771940\n",
            "1456/1875 [======================>.......] - ETA: 3s - loss: 0.2655 - accuracy: 0.9006Training: batch 1456 begins at 08:26:04.783833\n",
            "Training: batch 1457 begins at 08:26:04.794086\n",
            "Training: batch 1458 begins at 08:26:04.800724\n",
            "Training: batch 1459 begins at 08:26:04.812308\n",
            "Training: batch 1460 begins at 08:26:04.821960\n",
            "Training: batch 1461 begins at 08:26:04.829992\n",
            "1462/1875 [======================>.......] - ETA: 3s - loss: 0.2662 - accuracy: 0.9005Training: batch 1462 begins at 08:26:04.839040\n",
            "Training: batch 1463 begins at 08:26:04.845923\n",
            "Training: batch 1464 begins at 08:26:04.854221\n",
            "Training: batch 1465 begins at 08:26:04.862929\n",
            "Training: batch 1466 begins at 08:26:04.871395\n",
            "Training: batch 1467 begins at 08:26:04.878912\n",
            "Training: batch 1468 begins at 08:26:04.886856\n",
            "1469/1875 [======================>.......] - ETA: 3s - loss: 0.2664 - accuracy: 0.9004Training: batch 1469 begins at 08:26:04.901417\n",
            "Training: batch 1470 begins at 08:26:04.910994\n",
            "Training: batch 1471 begins at 08:26:04.921911\n",
            "Training: batch 1472 begins at 08:26:04.932710\n",
            "Training: batch 1473 begins at 08:26:04.942891\n",
            "1474/1875 [======================>.......] - ETA: 3s - loss: 0.2665 - accuracy: 0.9002Training: batch 1474 begins at 08:26:04.953563\n",
            "Training: batch 1475 begins at 08:26:04.959547\n",
            "Training: batch 1476 begins at 08:26:04.968594\n",
            "Training: batch 1477 begins at 08:26:04.976165\n",
            "Training: batch 1478 begins at 08:26:04.985950\n",
            "Training: batch 1479 begins at 08:26:04.991825\n",
            "Training: batch 1480 begins at 08:26:04.995607\n",
            "1481/1875 [======================>.......] - ETA: 3s - loss: 0.2665 - accuracy: 0.9001Training: batch 1481 begins at 08:26:05.005643\n",
            "Training: batch 1482 begins at 08:26:05.013752\n",
            "Training: batch 1483 begins at 08:26:05.020831\n",
            "Training: batch 1484 begins at 08:26:05.026223\n",
            "Training: batch 1485 begins at 08:26:05.033855\n",
            "Training: batch 1486 begins at 08:26:05.042124\n",
            "Training: batch 1487 begins at 08:26:05.050105\n",
            "1488/1875 [======================>.......] - ETA: 3s - loss: 0.2665 - accuracy: 0.9001Training: batch 1488 begins at 08:26:05.059548\n",
            "Training: batch 1489 begins at 08:26:05.065484\n",
            "Training: batch 1490 begins at 08:26:05.073307\n",
            "Training: batch 1491 begins at 08:26:05.082577\n",
            "Training: batch 1492 begins at 08:26:05.088781\n",
            "Training: batch 1493 begins at 08:26:05.098865\n",
            "1494/1875 [======================>.......] - ETA: 3s - loss: 0.2663 - accuracy: 0.9001Training: batch 1494 begins at 08:26:05.111167\n",
            "Training: batch 1495 begins at 08:26:05.117203\n",
            "Training: batch 1496 begins at 08:26:05.126190\n",
            "Training: batch 1497 begins at 08:26:05.133490\n",
            "Training: batch 1498 begins at 08:26:05.139460\n",
            "Training: batch 1499 begins at 08:26:05.149200\n",
            "Training: batch 1500 begins at 08:26:05.158597\n",
            "1501/1875 [=======================>......] - ETA: 2s - loss: 0.2666 - accuracy: 0.9000Training: batch 1501 begins at 08:26:05.175920\n",
            "Training: batch 1502 begins at 08:26:05.181908\n",
            "Training: batch 1503 begins at 08:26:05.192823\n",
            "Training: batch 1504 begins at 08:26:05.198928\n",
            "Training: batch 1505 begins at 08:26:05.203912\n",
            "Training: batch 1506 begins at 08:26:05.212341\n",
            "Training: batch 1507 begins at 08:26:05.220387\n",
            "1508/1875 [=======================>......] - ETA: 2s - loss: 0.2668 - accuracy: 0.9000Training: batch 1508 begins at 08:26:05.229067\n",
            "Training: batch 1509 begins at 08:26:05.235329\n",
            "Training: batch 1510 begins at 08:26:05.243453\n",
            "Training: batch 1511 begins at 08:26:05.251957\n",
            "Training: batch 1512 begins at 08:26:05.258275\n",
            "Training: batch 1513 begins at 08:26:05.267635\n",
            "Training: batch 1514 begins at 08:26:05.277227\n",
            "1515/1875 [=======================>......] - ETA: 2s - loss: 0.2665 - accuracy: 0.9002Training: batch 1515 begins at 08:26:05.287420\n",
            "Training: batch 1516 begins at 08:26:05.293616\n",
            "Training: batch 1517 begins at 08:26:05.303296\n",
            "Training: batch 1518 begins at 08:26:05.309219\n",
            "Training: batch 1519 begins at 08:26:05.315637\n",
            "Training: batch 1520 begins at 08:26:05.322982\n",
            "Training: batch 1521 begins at 08:26:05.330651\n",
            "1522/1875 [=======================>......] - ETA: 2s - loss: 0.2665 - accuracy: 0.9001Training: batch 1522 begins at 08:26:05.338787\n",
            "Training: batch 1523 begins at 08:26:05.344873\n",
            "Training: batch 1524 begins at 08:26:05.352650\n",
            "Training: batch 1525 begins at 08:26:05.359232\n",
            "Training: batch 1526 begins at 08:26:05.366469\n",
            "Training: batch 1527 begins at 08:26:05.372945\n",
            "Training: batch 1528 begins at 08:26:05.380357\n",
            "1529/1875 [=======================>......] - ETA: 2s - loss: 0.2667 - accuracy: 0.9000Training: batch 1529 begins at 08:26:05.389509\n",
            "Training: batch 1530 begins at 08:26:05.395818\n",
            "Training: batch 1531 begins at 08:26:05.403594\n",
            "Training: batch 1532 begins at 08:26:05.409773\n",
            "Training: batch 1533 begins at 08:26:05.416802\n",
            "Training: batch 1534 begins at 08:26:05.423310\n",
            "Training: batch 1535 begins at 08:26:05.433044\n",
            "1536/1875 [=======================>......] - ETA: 2s - loss: 0.2668 - accuracy: 0.9001Training: batch 1536 begins at 08:26:05.445520\n",
            "Training: batch 1537 begins at 08:26:05.453801\n",
            "Training: batch 1538 begins at 08:26:05.464948\n",
            "Training: batch 1539 begins at 08:26:05.475123\n",
            "Training: batch 1540 begins at 08:26:05.485174\n",
            "1541/1875 [=======================>......] - ETA: 2s - loss: 0.2667 - accuracy: 0.9001Training: batch 1541 begins at 08:26:05.495354\n",
            "Training: batch 1542 begins at 08:26:05.503856\n",
            "Training: batch 1543 begins at 08:26:05.511883\n",
            "Training: batch 1544 begins at 08:26:05.520015\n",
            "Training: batch 1545 begins at 08:26:05.528204\n",
            "Training: batch 1546 begins at 08:26:05.536514\n",
            "1547/1875 [=======================>......] - ETA: 2s - loss: 0.2672 - accuracy: 0.9000Training: batch 1547 begins at 08:26:05.547892\n",
            "Training: batch 1548 begins at 08:26:05.554123\n",
            "Training: batch 1549 begins at 08:26:05.564017\n",
            "Training: batch 1550 begins at 08:26:05.573619\n",
            "Training: batch 1551 begins at 08:26:05.580132\n",
            "Training: batch 1552 begins at 08:26:05.589510\n",
            "1553/1875 [=======================>......] - ETA: 2s - loss: 0.2669 - accuracy: 0.9001Training: batch 1553 begins at 08:26:05.599700\n",
            "Training: batch 1554 begins at 08:26:05.607288\n",
            "Training: batch 1555 begins at 08:26:05.616712\n",
            "Training: batch 1556 begins at 08:26:05.626511\n",
            "Training: batch 1557 begins at 08:26:05.633277\n",
            "Training: batch 1558 begins at 08:26:05.642384\n",
            "1559/1875 [=======================>......] - ETA: 2s - loss: 0.2672 - accuracy: 0.9001Training: batch 1559 begins at 08:26:05.653133\n",
            "Training: batch 1560 begins at 08:26:05.659953\n",
            "Training: batch 1561 begins at 08:26:05.669483\n",
            "Training: batch 1562 begins at 08:26:05.683104\n",
            "Training: batch 1563 begins at 08:26:05.691053\n",
            "Training: batch 1564 begins at 08:26:05.700965\n",
            "1565/1875 [========================>.....] - ETA: 2s - loss: 0.2671 - accuracy: 0.9000Training: batch 1565 begins at 08:26:05.709618\n",
            "Training: batch 1566 begins at 08:26:05.719262\n",
            "Training: batch 1567 begins at 08:26:05.725928\n",
            "Training: batch 1568 begins at 08:26:05.736458\n",
            "Training: batch 1569 begins at 08:26:05.746312\n",
            "Training: batch 1570 begins at 08:26:05.757463\n",
            "1571/1875 [========================>.....] - ETA: 2s - loss: 0.2671 - accuracy: 0.9001Training: batch 1571 begins at 08:26:05.769241\n",
            "Training: batch 1572 begins at 08:26:05.778125\n",
            "Training: batch 1573 begins at 08:26:05.789733\n",
            "Training: batch 1574 begins at 08:26:05.797238\n",
            "Training: batch 1575 begins at 08:26:05.807329\n",
            "Training: batch 1576 begins at 08:26:05.814595\n",
            "1577/1875 [========================>.....] - ETA: 2s - loss: 0.2672 - accuracy: 0.9000Training: batch 1577 begins at 08:26:05.826355\n",
            "Training: batch 1578 begins at 08:26:05.836743\n",
            "Training: batch 1579 begins at 08:26:05.843842\n",
            "Training: batch 1580 begins at 08:26:05.853686\n",
            "Training: batch 1581 begins at 08:26:05.863378\n",
            "Training: batch 1582 begins at 08:26:05.870119\n",
            "1583/1875 [========================>.....] - ETA: 2s - loss: 0.2670 - accuracy: 0.9001Training: batch 1583 begins at 08:26:05.881635\n",
            "Training: batch 1584 begins at 08:26:05.891336\n",
            "Training: batch 1585 begins at 08:26:05.901027\n",
            "Training: batch 1586 begins at 08:26:05.912309\n",
            "Training: batch 1587 begins at 08:26:05.922954\n",
            "1588/1875 [========================>.....] - ETA: 2s - loss: 0.2670 - accuracy: 0.9001Training: batch 1588 begins at 08:26:05.936256\n",
            "Training: batch 1589 begins at 08:26:05.944686\n",
            "Training: batch 1590 begins at 08:26:05.952911\n",
            "Training: batch 1591 begins at 08:26:05.963486\n",
            "Training: batch 1592 begins at 08:26:05.969442\n",
            "Training: batch 1593 begins at 08:26:05.978758\n",
            "1594/1875 [========================>.....] - ETA: 2s - loss: 0.2667 - accuracy: 0.9002Training: batch 1594 begins at 08:26:05.992018\n",
            "Training: batch 1595 begins at 08:26:05.998099\n",
            "Training: batch 1596 begins at 08:26:06.004593\n",
            "Training: batch 1597 begins at 08:26:06.019212\n",
            "Training: batch 1598 begins at 08:26:06.027593\n",
            "Training: batch 1599 begins at 08:26:06.036368\n",
            "1600/1875 [========================>.....] - ETA: 2s - loss: 0.2668 - accuracy: 0.9002Training: batch 1600 begins at 08:26:06.045534\n",
            "Training: batch 1601 begins at 08:26:06.051138\n",
            "Training: batch 1602 begins at 08:26:06.059885\n",
            "Training: batch 1603 begins at 08:26:06.068538\n",
            "Training: batch 1604 begins at 08:26:06.077446\n",
            "Training: batch 1605 begins at 08:26:06.085242\n",
            "1606/1875 [========================>.....] - ETA: 2s - loss: 0.2665 - accuracy: 0.9003Training: batch 1606 begins at 08:26:06.096637\n",
            "Training: batch 1607 begins at 08:26:06.101434\n",
            "Training: batch 1608 begins at 08:26:06.109453\n",
            "Training: batch 1609 begins at 08:26:06.116395\n",
            "Training: batch 1610 begins at 08:26:06.123809\n",
            "Training: batch 1611 begins at 08:26:06.132548\n",
            "Training: batch 1612 begins at 08:26:06.138920\n",
            "1613/1875 [========================>.....] - ETA: 2s - loss: 0.2661 - accuracy: 0.9003Training: batch 1613 begins at 08:26:06.146242\n",
            "Training: batch 1614 begins at 08:26:06.153807\n",
            "Training: batch 1615 begins at 08:26:06.157951\n",
            "Training: batch 1616 begins at 08:26:06.169878\n",
            "Training: batch 1617 begins at 08:26:06.175415\n",
            "Training: batch 1618 begins at 08:26:06.186405\n",
            "Training: batch 1619 begins at 08:26:06.191741\n",
            "1620/1875 [========================>.....] - ETA: 2s - loss: 0.2661 - accuracy: 0.9003Training: batch 1620 begins at 08:26:06.204480\n",
            "Training: batch 1621 begins at 08:26:06.213803\n",
            "Training: batch 1622 begins at 08:26:06.219330\n",
            "Training: batch 1623 begins at 08:26:06.228922\n",
            "Training: batch 1624 begins at 08:26:06.238745\n",
            "Training: batch 1625 begins at 08:26:06.244621\n",
            "1626/1875 [=========================>....] - ETA: 1s - loss: 0.2661 - accuracy: 0.9004Training: batch 1626 begins at 08:26:06.257578\n",
            "Training: batch 1627 begins at 08:26:06.263328\n",
            "Training: batch 1628 begins at 08:26:06.275872\n",
            "Training: batch 1629 begins at 08:26:06.281537\n",
            "Training: batch 1630 begins at 08:26:06.287022\n",
            "Training: batch 1631 begins at 08:26:06.294138\n",
            "Training: batch 1632 begins at 08:26:06.301270\n",
            "1633/1875 [=========================>....] - ETA: 1s - loss: 0.2661 - accuracy: 0.9003Training: batch 1633 begins at 08:26:06.309438\n",
            "Training: batch 1634 begins at 08:26:06.315759\n",
            "Training: batch 1635 begins at 08:26:06.327787\n",
            "Training: batch 1636 begins at 08:26:06.340709\n",
            "Training: batch 1637 begins at 08:26:06.354306\n",
            "1638/1875 [=========================>....] - ETA: 1s - loss: 0.2662 - accuracy: 0.9002Training: batch 1638 begins at 08:26:06.364778\n",
            "Training: batch 1639 begins at 08:26:06.374010\n",
            "Training: batch 1640 begins at 08:26:06.381660\n",
            "Training: batch 1641 begins at 08:26:06.387383\n",
            "Training: batch 1642 begins at 08:26:06.396170\n",
            "Training: batch 1643 begins at 08:26:06.403986\n",
            "Training: batch 1644 begins at 08:26:06.411925\n",
            "1645/1875 [=========================>....] - ETA: 1s - loss: 0.2666 - accuracy: 0.9000Training: batch 1645 begins at 08:26:06.422627\n",
            "Training: batch 1646 begins at 08:26:06.434486\n",
            "Training: batch 1647 begins at 08:26:06.442065\n",
            "Training: batch 1648 begins at 08:26:06.448313\n",
            "Training: batch 1649 begins at 08:26:06.455759\n",
            "Training: batch 1650 begins at 08:26:06.467118\n",
            "1651/1875 [=========================>....] - ETA: 1s - loss: 0.2668 - accuracy: 0.9000Training: batch 1651 begins at 08:26:06.479274\n",
            "Training: batch 1652 begins at 08:26:06.489202\n",
            "Training: batch 1653 begins at 08:26:06.500993\n",
            "Training: batch 1654 begins at 08:26:06.509732\n",
            "Training: batch 1655 begins at 08:26:06.520526\n",
            "1656/1875 [=========================>....] - ETA: 1s - loss: 0.2668 - accuracy: 0.8999Training: batch 1656 begins at 08:26:06.531526\n",
            "Training: batch 1657 begins at 08:26:06.538868\n",
            "Training: batch 1658 begins at 08:26:06.545872\n",
            "Training: batch 1659 begins at 08:26:06.553022\n",
            "Training: batch 1660 begins at 08:26:06.561009\n",
            "Training: batch 1661 begins at 08:26:06.570399\n",
            "1662/1875 [=========================>....] - ETA: 1s - loss: 0.2669 - accuracy: 0.8998Training: batch 1662 begins at 08:26:06.582998\n",
            "Training: batch 1663 begins at 08:26:06.593687\n",
            "Training: batch 1664 begins at 08:26:06.602225\n",
            "Training: batch 1665 begins at 08:26:06.611713\n",
            "Training: batch 1666 begins at 08:26:06.619013\n",
            "Training: batch 1667 begins at 08:26:06.627024\n",
            "1668/1875 [=========================>....] - ETA: 1s - loss: 0.2670 - accuracy: 0.8999Training: batch 1668 begins at 08:26:06.636033\n",
            "Training: batch 1669 begins at 08:26:06.643898\n",
            "Training: batch 1670 begins at 08:26:06.651583\n",
            "Training: batch 1671 begins at 08:26:06.660406\n",
            "Training: batch 1672 begins at 08:26:06.670853\n",
            "Training: batch 1673 begins at 08:26:06.679055\n",
            "1674/1875 [=========================>....] - ETA: 1s - loss: 0.2672 - accuracy: 0.8997Training: batch 1674 begins at 08:26:06.690330\n",
            "Training: batch 1675 begins at 08:26:06.698497\n",
            "Training: batch 1676 begins at 08:26:06.706947\n",
            "Training: batch 1677 begins at 08:26:06.715243\n",
            "Training: batch 1678 begins at 08:26:06.723467\n",
            "Training: batch 1679 begins at 08:26:06.730996\n",
            "1680/1875 [=========================>....] - ETA: 1s - loss: 0.2672 - accuracy: 0.8997Training: batch 1680 begins at 08:26:06.742530\n",
            "Training: batch 1681 begins at 08:26:06.753583\n",
            "Training: batch 1682 begins at 08:26:06.763721\n",
            "Training: batch 1683 begins at 08:26:06.771539\n",
            "Training: batch 1684 begins at 08:26:06.783692\n",
            "1685/1875 [=========================>....] - ETA: 1s - loss: 0.2672 - accuracy: 0.8997Training: batch 1685 begins at 08:26:06.792800\n",
            "Training: batch 1686 begins at 08:26:06.802497\n",
            "Training: batch 1687 begins at 08:26:06.810405\n",
            "Training: batch 1688 begins at 08:26:06.822635\n",
            "Training: batch 1689 begins at 08:26:06.829851\n",
            "Training: batch 1690 begins at 08:26:06.840856\n",
            "1691/1875 [==========================>...] - ETA: 1s - loss: 0.2673 - accuracy: 0.8997Training: batch 1691 begins at 08:26:06.853841\n",
            "Training: batch 1692 begins at 08:26:06.860806\n",
            "Training: batch 1693 begins at 08:26:06.869578\n",
            "Training: batch 1694 begins at 08:26:06.879279\n",
            "Training: batch 1695 begins at 08:26:06.886137\n",
            "Training: batch 1696 begins at 08:26:06.894689\n",
            "1697/1875 [==========================>...] - ETA: 1s - loss: 0.2670 - accuracy: 0.8997Training: batch 1697 begins at 08:26:06.904481\n",
            "Training: batch 1698 begins at 08:26:06.911355\n",
            "Training: batch 1699 begins at 08:26:06.917912\n",
            "Training: batch 1700 begins at 08:26:06.925244\n",
            "Training: batch 1701 begins at 08:26:06.932109\n",
            "Training: batch 1702 begins at 08:26:06.938509\n",
            "Training: batch 1703 begins at 08:26:06.946169\n",
            "1704/1875 [==========================>...] - ETA: 1s - loss: 0.2669 - accuracy: 0.8998Training: batch 1704 begins at 08:26:06.956171\n",
            "Training: batch 1705 begins at 08:26:06.964476\n",
            "Training: batch 1706 begins at 08:26:06.972406\n",
            "Training: batch 1707 begins at 08:26:06.979214\n",
            "Training: batch 1708 begins at 08:26:06.988299\n",
            "Training: batch 1709 begins at 08:26:06.996803\n",
            "1710/1875 [==========================>...] - ETA: 1s - loss: 0.2667 - accuracy: 0.8999Training: batch 1710 begins at 08:26:07.010191\n",
            "Training: batch 1711 begins at 08:26:07.017870\n",
            "Training: batch 1712 begins at 08:26:07.025161\n",
            "Training: batch 1713 begins at 08:26:07.032767\n",
            "Training: batch 1714 begins at 08:26:07.039493\n",
            "Training: batch 1715 begins at 08:26:07.047108\n",
            "Training: batch 1716 begins at 08:26:07.054462\n",
            "1717/1875 [==========================>...] - ETA: 1s - loss: 0.2669 - accuracy: 0.8997Training: batch 1717 begins at 08:26:07.064134\n",
            "Training: batch 1718 begins at 08:26:07.071105\n",
            "Training: batch 1719 begins at 08:26:07.077745\n",
            "Training: batch 1720 begins at 08:26:07.085220\n",
            "Training: batch 1721 begins at 08:26:07.093039\n",
            "Training: batch 1722 begins at 08:26:07.101131\n",
            "Training: batch 1723 begins at 08:26:07.109061\n",
            "1724/1875 [==========================>...] - ETA: 1s - loss: 0.2668 - accuracy: 0.8997Training: batch 1724 begins at 08:26:07.119090\n",
            "Training: batch 1725 begins at 08:26:07.126958\n",
            "Training: batch 1726 begins at 08:26:07.133581\n",
            "Training: batch 1727 begins at 08:26:07.140174\n",
            "Training: batch 1728 begins at 08:26:07.146714\n",
            "Training: batch 1729 begins at 08:26:07.154528\n",
            "Training: batch 1730 begins at 08:26:07.162789\n",
            "1731/1875 [==========================>...] - ETA: 1s - loss: 0.2672 - accuracy: 0.8995Training: batch 1731 begins at 08:26:07.173805\n",
            "Training: batch 1732 begins at 08:26:07.181129\n",
            "Training: batch 1733 begins at 08:26:07.191276\n",
            "Training: batch 1734 begins at 08:26:07.200195\n",
            "Training: batch 1735 begins at 08:26:07.207567\n",
            "Training: batch 1736 begins at 08:26:07.216504\n",
            "1737/1875 [==========================>...] - ETA: 1s - loss: 0.2670 - accuracy: 0.8996Training: batch 1737 begins at 08:26:07.225341\n",
            "Training: batch 1738 begins at 08:26:07.232096\n",
            "Training: batch 1739 begins at 08:26:07.239671\n",
            "Training: batch 1740 begins at 08:26:07.246370\n",
            "Training: batch 1741 begins at 08:26:07.253907\n",
            "Training: batch 1742 begins at 08:26:07.262178\n",
            "Training: batch 1743 begins at 08:26:07.271293\n",
            "1744/1875 [==========================>...] - ETA: 1s - loss: 0.2670 - accuracy: 0.8996Training: batch 1744 begins at 08:26:07.280162\n",
            "Training: batch 1745 begins at 08:26:07.288180\n",
            "Training: batch 1746 begins at 08:26:07.295801\n",
            "Training: batch 1747 begins at 08:26:07.303628\n",
            "Training: batch 1748 begins at 08:26:07.312999\n",
            "Training: batch 1749 begins at 08:26:07.321608\n",
            "1750/1875 [===========================>..] - ETA: 1s - loss: 0.2670 - accuracy: 0.8997Training: batch 1750 begins at 08:26:07.331833\n",
            "Training: batch 1751 begins at 08:26:07.338825\n",
            "Training: batch 1752 begins at 08:26:07.345613\n",
            "Training: batch 1753 begins at 08:26:07.352973\n",
            "Training: batch 1754 begins at 08:26:07.362956\n",
            "Training: batch 1755 begins at 08:26:07.371303\n",
            "1756/1875 [===========================>..] - ETA: 0s - loss: 0.2670 - accuracy: 0.8997Training: batch 1756 begins at 08:26:07.382962\n",
            "Training: batch 1757 begins at 08:26:07.390016\n",
            "Training: batch 1758 begins at 08:26:07.397837\n",
            "Training: batch 1759 begins at 08:26:07.407899\n",
            "Training: batch 1760 begins at 08:26:07.417424\n",
            "Training: batch 1761 begins at 08:26:07.425450\n",
            "1762/1875 [===========================>..] - ETA: 0s - loss: 0.2669 - accuracy: 0.8997Training: batch 1762 begins at 08:26:07.439751\n",
            "Training: batch 1763 begins at 08:26:07.446365\n",
            "Training: batch 1764 begins at 08:26:07.455431\n",
            "Training: batch 1765 begins at 08:26:07.465233\n",
            "Training: batch 1766 begins at 08:26:07.471125\n",
            "Training: batch 1767 begins at 08:26:07.478997\n",
            "Training: batch 1768 begins at 08:26:07.484767\n",
            "1769/1875 [===========================>..] - ETA: 0s - loss: 0.2669 - accuracy: 0.8997Training: batch 1769 begins at 08:26:07.494259\n",
            "Training: batch 1770 begins at 08:26:07.499891\n",
            "Training: batch 1771 begins at 08:26:07.512949\n",
            "Training: batch 1772 begins at 08:26:07.520088\n",
            "Training: batch 1773 begins at 08:26:07.527243\n",
            "Training: batch 1774 begins at 08:26:07.535389\n",
            "Training: batch 1775 begins at 08:26:07.541092\n",
            "1776/1875 [===========================>..] - ETA: 0s - loss: 0.2666 - accuracy: 0.8997Training: batch 1776 begins at 08:26:07.553873\n",
            "Training: batch 1777 begins at 08:26:07.560192\n",
            "Training: batch 1778 begins at 08:26:07.568803\n",
            "Training: batch 1779 begins at 08:26:07.578293\n",
            "Training: batch 1780 begins at 08:26:07.587408\n",
            "Training: batch 1781 begins at 08:26:07.597162\n",
            "1782/1875 [===========================>..] - ETA: 0s - loss: 0.2666 - accuracy: 0.8997Training: batch 1782 begins at 08:26:07.605869\n",
            "Training: batch 1783 begins at 08:26:07.611455\n",
            "Training: batch 1784 begins at 08:26:07.619531\n",
            "Training: batch 1785 begins at 08:26:07.625131\n",
            "Training: batch 1786 begins at 08:26:07.635798\n",
            "Training: batch 1787 begins at 08:26:07.641797\n",
            "Training: batch 1788 begins at 08:26:07.648849\n",
            "1789/1875 [===========================>..] - ETA: 0s - loss: 0.2664 - accuracy: 0.8997Training: batch 1789 begins at 08:26:07.660015\n",
            "Training: batch 1790 begins at 08:26:07.667004\n",
            "Training: batch 1791 begins at 08:26:07.673269\n",
            "Training: batch 1792 begins at 08:26:07.680910\n",
            "Training: batch 1793 begins at 08:26:07.687746\n",
            "Training: batch 1794 begins at 08:26:07.696054\n",
            "1795/1875 [===========================>..] - ETA: 0s - loss: 0.2664 - accuracy: 0.8997Training: batch 1795 begins at 08:26:07.708744\n",
            "Training: batch 1796 begins at 08:26:07.717870\n",
            "Training: batch 1797 begins at 08:26:07.727106\n",
            "Training: batch 1798 begins at 08:26:07.734713\n",
            "Training: batch 1799 begins at 08:26:07.745618\n",
            "Training: batch 1800 begins at 08:26:07.752693\n",
            "1801/1875 [===========================>..] - ETA: 0s - loss: 0.2664 - accuracy: 0.8998Training: batch 1801 begins at 08:26:07.763053\n",
            "Training: batch 1802 begins at 08:26:07.772533\n",
            "Training: batch 1803 begins at 08:26:07.779755\n",
            "Training: batch 1804 begins at 08:26:07.790950\n",
            "Training: batch 1805 begins at 08:26:07.801027\n",
            "Training: batch 1806 begins at 08:26:07.808687\n",
            "1807/1875 [===========================>..] - ETA: 0s - loss: 0.2664 - accuracy: 0.8997Training: batch 1807 begins at 08:26:07.819165\n",
            "Training: batch 1808 begins at 08:26:07.825453\n",
            "Training: batch 1809 begins at 08:26:07.834023\n",
            "Training: batch 1810 begins at 08:26:07.845248\n",
            "Training: batch 1811 begins at 08:26:07.852031\n",
            "Training: batch 1812 begins at 08:26:07.859167\n",
            "Training: batch 1813 begins at 08:26:07.865237\n",
            "1814/1875 [============================>.] - ETA: 0s - loss: 0.2665 - accuracy: 0.8996Training: batch 1814 begins at 08:26:07.873917\n",
            "Training: batch 1815 begins at 08:26:07.881253\n",
            "Training: batch 1816 begins at 08:26:07.890939\n",
            "Training: batch 1817 begins at 08:26:07.899193\n",
            "Training: batch 1818 begins at 08:26:07.913591\n",
            "Training: batch 1819 begins at 08:26:07.919785\n",
            "1820/1875 [============================>.] - ETA: 0s - loss: 0.2665 - accuracy: 0.8996Training: batch 1820 begins at 08:26:07.929541\n",
            "Training: batch 1821 begins at 08:26:07.939373\n",
            "Training: batch 1822 begins at 08:26:07.949657\n",
            "Training: batch 1823 begins at 08:26:07.958891\n",
            "Training: batch 1824 begins at 08:26:07.966271\n",
            "Training: batch 1825 begins at 08:26:07.975468\n",
            "1826/1875 [============================>.] - ETA: 0s - loss: 0.2668 - accuracy: 0.8995Training: batch 1826 begins at 08:26:07.985201\n",
            "Training: batch 1827 begins at 08:26:07.993797\n",
            "Training: batch 1828 begins at 08:26:08.002601\n",
            "Training: batch 1829 begins at 08:26:08.012933\n",
            "Training: batch 1830 begins at 08:26:08.021746\n",
            "Training: batch 1831 begins at 08:26:08.028829\n",
            "1832/1875 [============================>.] - ETA: 0s - loss: 0.2668 - accuracy: 0.8995Training: batch 1832 begins at 08:26:08.037643\n",
            "Training: batch 1833 begins at 08:26:08.048870\n",
            "Training: batch 1834 begins at 08:26:08.056245\n",
            "Training: batch 1835 begins at 08:26:08.066523\n",
            "Training: batch 1836 begins at 08:26:08.076089\n",
            "Training: batch 1837 begins at 08:26:08.086201\n",
            "1838/1875 [============================>.] - ETA: 0s - loss: 0.2668 - accuracy: 0.8995Training: batch 1838 begins at 08:26:08.095998\n",
            "Training: batch 1839 begins at 08:26:08.105430\n",
            "Training: batch 1840 begins at 08:26:08.112737\n",
            "Training: batch 1841 begins at 08:26:08.120426\n",
            "Training: batch 1842 begins at 08:26:08.126063\n",
            "Training: batch 1843 begins at 08:26:08.133818\n",
            "Training: batch 1844 begins at 08:26:08.139265\n",
            "1845/1875 [============================>.] - ETA: 0s - loss: 0.2669 - accuracy: 0.8995Training: batch 1845 begins at 08:26:08.148031\n",
            "Training: batch 1846 begins at 08:26:08.156546\n",
            "Training: batch 1847 begins at 08:26:08.166761\n",
            "Training: batch 1848 begins at 08:26:08.172511\n",
            "Training: batch 1849 begins at 08:26:08.181531\n",
            "Training: batch 1850 begins at 08:26:08.189584\n",
            "Training: batch 1851 begins at 08:26:08.194934\n",
            "1852/1875 [============================>.] - ETA: 0s - loss: 0.2667 - accuracy: 0.8996Training: batch 1852 begins at 08:26:08.202492\n",
            "Training: batch 1853 begins at 08:26:08.209716\n",
            "Training: batch 1854 begins at 08:26:08.218773\n",
            "Training: batch 1855 begins at 08:26:08.227821\n",
            "Training: batch 1856 begins at 08:26:08.235833\n",
            "Training: batch 1857 begins at 08:26:08.243518\n",
            "1858/1875 [============================>.] - ETA: 0s - loss: 0.2665 - accuracy: 0.8997Training: batch 1858 begins at 08:26:08.253859\n",
            "Training: batch 1859 begins at 08:26:08.261455\n",
            "Training: batch 1860 begins at 08:26:08.269640\n",
            "Training: batch 1861 begins at 08:26:08.278073\n",
            "Training: batch 1862 begins at 08:26:08.286018\n",
            "Training: batch 1863 begins at 08:26:08.294394\n",
            "1864/1875 [============================>.] - ETA: 0s - loss: 0.2663 - accuracy: 0.8997Training: batch 1864 begins at 08:26:08.303814\n",
            "Training: batch 1865 begins at 08:26:08.311769\n",
            "Training: batch 1866 begins at 08:26:08.319356\n",
            "Training: batch 1867 begins at 08:26:08.326076\n",
            "Training: batch 1868 begins at 08:26:08.332424\n",
            "Training: batch 1869 begins at 08:26:08.339670\n",
            "Training: batch 1870 begins at 08:26:08.346473\n",
            "1871/1875 [============================>.] - ETA: 0s - loss: 0.2666 - accuracy: 0.8997Training: batch 1871 begins at 08:26:08.356376\n",
            "Training: batch 1872 begins at 08:26:08.363267\n",
            "Training: batch 1873 begins at 08:26:08.370279\n",
            "Training: batch 1874 begins at 08:26:08.379403\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2667 - accuracy: 0.8996\n",
            "Epoch 9/10\n",
            "Training: batch 0 begins at 08:26:08.395661\n",
            "   1/1875 [..............................] - ETA: 16s - loss: 0.2274 - accuracy: 0.8438Training: batch 1 begins at 08:26:08.404392\n",
            "Training: batch 2 begins at 08:26:08.411958\n",
            "Training: batch 3 begins at 08:26:08.418993\n",
            "Training: batch 4 begins at 08:26:08.426517\n",
            "Training: batch 5 begins at 08:26:08.434844\n",
            "Training: batch 6 begins at 08:26:08.444302\n",
            "   7/1875 [..............................] - ETA: 15s - loss: 0.2458 - accuracy: 0.8884Training: batch 7 begins at 08:26:08.455873\n",
            "Training: batch 8 begins at 08:26:08.464032\n",
            "Training: batch 9 begins at 08:26:08.472231\n",
            "Training: batch 10 begins at 08:26:08.478860\n",
            "Training: batch 11 begins at 08:26:08.485927\n",
            "Training: batch 12 begins at 08:26:08.492601\n",
            "Training: batch 13 begins at 08:26:08.500240\n",
            "  14/1875 [..............................] - ETA: 15s - loss: 0.2551 - accuracy: 0.9040Training: batch 14 begins at 08:26:08.510436\n",
            "Training: batch 15 begins at 08:26:08.517309\n",
            "Training: batch 16 begins at 08:26:08.524997\n",
            "Training: batch 17 begins at 08:26:08.534798\n",
            "Training: batch 18 begins at 08:26:08.540809\n",
            "Training: batch 19 begins at 08:26:08.547767\n",
            "Training: batch 20 begins at 08:26:08.556127\n",
            "  21/1875 [..............................] - ETA: 14s - loss: 0.3081 - accuracy: 0.8839Training: batch 21 begins at 08:26:08.565272\n",
            "Training: batch 22 begins at 08:26:08.573104\n",
            "Training: batch 23 begins at 08:26:08.580435\n",
            "Training: batch 24 begins at 08:26:08.588022\n",
            "Training: batch 25 begins at 08:26:08.599624\n",
            "Training: batch 26 begins at 08:26:08.606484\n",
            "  27/1875 [..............................] - ETA: 15s - loss: 0.3000 - accuracy: 0.8866Training: batch 27 begins at 08:26:08.617672\n",
            "Training: batch 28 begins at 08:26:08.628796\n",
            "Training: batch 29 begins at 08:26:08.637086\n",
            "Training: batch 30 begins at 08:26:08.648295\n",
            "Training: batch 31 begins at 08:26:08.652252\n",
            "Training: batch 32 begins at 08:26:08.657410\n",
            "Training: batch 33 begins at 08:26:08.662491\n",
            "  34/1875 [..............................] - ETA: 14s - loss: 0.2826 - accuracy: 0.8961Training: batch 34 begins at 08:26:08.672184\n",
            "Training: batch 35 begins at 08:26:08.678201\n",
            "Training: batch 36 begins at 08:26:08.684636\n",
            "Training: batch 37 begins at 08:26:08.690545\n",
            "Training: batch 38 begins at 08:26:08.696593\n",
            "Training: batch 39 begins at 08:26:08.702910\n",
            "Training: batch 40 begins at 08:26:08.709015\n",
            "Training: batch 41 begins at 08:26:08.716760\n",
            "  42/1875 [..............................] - ETA: 14s - loss: 0.2819 - accuracy: 0.8943Training: batch 42 begins at 08:26:08.726573\n",
            "Training: batch 43 begins at 08:26:08.732537\n",
            "Training: batch 44 begins at 08:26:08.739399\n",
            "Training: batch 45 begins at 08:26:08.745314\n",
            "Training: batch 46 begins at 08:26:08.751123\n",
            "Training: batch 47 begins at 08:26:08.756986\n",
            "Training: batch 48 begins at 08:26:08.762810\n",
            "Training: batch 49 begins at 08:26:08.768968\n",
            "  50/1875 [..............................] - ETA: 13s - loss: 0.2733 - accuracy: 0.8963Training: batch 50 begins at 08:26:08.777291\n",
            "Training: batch 51 begins at 08:26:08.785708\n",
            "Training: batch 52 begins at 08:26:08.791355\n",
            "Training: batch 53 begins at 08:26:08.798860\n",
            "Training: batch 54 begins at 08:26:08.804547\n",
            "Training: batch 55 begins at 08:26:08.812622\n",
            "Training: batch 56 begins at 08:26:08.820487\n",
            "  57/1875 [..............................] - ETA: 13s - loss: 0.2725 - accuracy: 0.8986Training: batch 57 begins at 08:26:08.828858\n",
            "Training: batch 58 begins at 08:26:08.839557\n",
            "Training: batch 59 begins at 08:26:08.846485\n",
            "Training: batch 60 begins at 08:26:08.852975\n",
            "Training: batch 61 begins at 08:26:08.860836\n",
            "Training: batch 62 begins at 08:26:08.866857\n",
            "Training: batch 63 begins at 08:26:08.874785\n",
            "  64/1875 [>.............................] - ETA: 13s - loss: 0.2694 - accuracy: 0.8984Training: batch 64 begins at 08:26:08.887129\n",
            "Training: batch 65 begins at 08:26:08.894510\n",
            "Training: batch 66 begins at 08:26:08.900428\n",
            "Training: batch 67 begins at 08:26:08.907423\n",
            "Training: batch 68 begins at 08:26:08.913099\n",
            "Training: batch 69 begins at 08:26:08.918945\n",
            "Training: batch 70 begins at 08:26:08.926064\n",
            "Training: batch 71 begins at 08:26:08.931841\n",
            "  72/1875 [>.............................] - ETA: 13s - loss: 0.2644 - accuracy: 0.8984Training: batch 72 begins at 08:26:08.939018\n",
            "Training: batch 73 begins at 08:26:08.946430\n",
            "Training: batch 74 begins at 08:26:08.953207\n",
            "Training: batch 75 begins at 08:26:08.958724\n",
            "Training: batch 76 begins at 08:26:08.964038\n",
            "Training: batch 77 begins at 08:26:08.969531\n",
            "Training: batch 78 begins at 08:26:08.975063\n",
            "Training: batch 79 begins at 08:26:08.980799\n",
            "Training: batch 80 begins at 08:26:08.986976\n",
            "  81/1875 [>.............................] - ETA: 13s - loss: 0.2687 - accuracy: 0.8981Training: batch 81 begins at 08:26:08.994739\n",
            "Training: batch 82 begins at 08:26:09.001950\n",
            "Training: batch 83 begins at 08:26:09.008524\n",
            "Training: batch 84 begins at 08:26:09.014649\n",
            "Training: batch 85 begins at 08:26:09.021670\n",
            "Training: batch 86 begins at 08:26:09.028877\n",
            "Training: batch 87 begins at 08:26:09.035944\n",
            "Training: batch 88 begins at 08:26:09.042310\n",
            "  89/1875 [>.............................] - ETA: 13s - loss: 0.2717 - accuracy: 0.8982Training: batch 89 begins at 08:26:09.051299\n",
            "Training: batch 90 begins at 08:26:09.057972\n",
            "Training: batch 91 begins at 08:26:09.065097\n",
            "Training: batch 92 begins at 08:26:09.072551\n",
            "Training: batch 93 begins at 08:26:09.080019\n",
            "Training: batch 94 begins at 08:26:09.086685\n",
            "Training: batch 95 begins at 08:26:09.093212\n",
            "  96/1875 [>.............................] - ETA: 13s - loss: 0.2709 - accuracy: 0.8994Training: batch 96 begins at 08:26:09.102610\n",
            "Training: batch 97 begins at 08:26:09.109099\n",
            "Training: batch 98 begins at 08:26:09.116193\n",
            "Training: batch 99 begins at 08:26:09.122388\n",
            "Training: batch 100 begins at 08:26:09.128072\n",
            "Training: batch 101 begins at 08:26:09.135321\n",
            "Training: batch 102 begins at 08:26:09.142499\n",
            "Training: batch 103 begins at 08:26:09.149810\n",
            " 104/1875 [>.............................] - ETA: 12s - loss: 0.2662 - accuracy: 0.9014Training: batch 104 begins at 08:26:09.159267\n",
            "Training: batch 105 begins at 08:26:09.165657\n",
            "Training: batch 106 begins at 08:26:09.171683\n",
            "Training: batch 107 begins at 08:26:09.178703\n",
            "Training: batch 108 begins at 08:26:09.184940\n",
            "Training: batch 109 begins at 08:26:09.192039\n",
            "Training: batch 110 begins at 08:26:09.198391\n",
            "Training: batch 111 begins at 08:26:09.205395\n",
            " 112/1875 [>.............................] - ETA: 12s - loss: 0.2642 - accuracy: 0.9021Training: batch 112 begins at 08:26:09.214555\n",
            "Training: batch 113 begins at 08:26:09.221248\n",
            "Training: batch 114 begins at 08:26:09.227409\n",
            "Training: batch 115 begins at 08:26:09.234672\n",
            "Training: batch 116 begins at 08:26:09.242980\n",
            "Training: batch 117 begins at 08:26:09.249635\n",
            "Training: batch 118 begins at 08:26:09.257040\n",
            " 119/1875 [>.............................] - ETA: 12s - loss: 0.2643 - accuracy: 0.9028Training: batch 119 begins at 08:26:09.266373\n",
            "Training: batch 120 begins at 08:26:09.273812\n",
            "Training: batch 121 begins at 08:26:09.281449\n",
            "Training: batch 122 begins at 08:26:09.288518\n",
            "Training: batch 123 begins at 08:26:09.295742\n",
            "Training: batch 124 begins at 08:26:09.302944\n",
            "Training: batch 125 begins at 08:26:09.310317\n",
            " 126/1875 [=>............................] - ETA: 12s - loss: 0.2635 - accuracy: 0.9040Training: batch 126 begins at 08:26:09.318360\n",
            "Training: batch 127 begins at 08:26:09.325336\n",
            "Training: batch 128 begins at 08:26:09.332180\n",
            "Training: batch 129 begins at 08:26:09.338511\n",
            "Training: batch 130 begins at 08:26:09.345387\n",
            "Training: batch 131 begins at 08:26:09.352819\n",
            "Training: batch 132 begins at 08:26:09.360332\n",
            " 133/1875 [=>............................] - ETA: 12s - loss: 0.2670 - accuracy: 0.9027Training: batch 133 begins at 08:26:09.369014\n",
            "Training: batch 134 begins at 08:26:09.376020\n",
            "Training: batch 135 begins at 08:26:09.382262\n",
            "Training: batch 136 begins at 08:26:09.389505\n",
            "Training: batch 137 begins at 08:26:09.395695\n",
            "Training: batch 138 begins at 08:26:09.402815\n",
            "Training: batch 139 begins at 08:26:09.410314\n",
            " 140/1875 [=>............................] - ETA: 12s - loss: 0.2686 - accuracy: 0.9025Training: batch 140 begins at 08:26:09.419753\n",
            "Training: batch 141 begins at 08:26:09.427044\n",
            "Training: batch 142 begins at 08:26:09.436426\n",
            "Training: batch 143 begins at 08:26:09.444045\n",
            "Training: batch 144 begins at 08:26:09.452481\n",
            "Training: batch 145 begins at 08:26:09.459297\n",
            "Training: batch 146 begins at 08:26:09.466822\n",
            " 147/1875 [=>............................] - ETA: 12s - loss: 0.2720 - accuracy: 0.9011Training: batch 147 begins at 08:26:09.476305\n",
            "Training: batch 148 begins at 08:26:09.483566\n",
            "Training: batch 149 begins at 08:26:09.491093\n",
            "Training: batch 150 begins at 08:26:09.498964\n",
            "Training: batch 151 begins at 08:26:09.505879\n",
            "Training: batch 152 begins at 08:26:09.513392\n",
            "Training: batch 153 begins at 08:26:09.520929\n",
            " 154/1875 [=>............................] - ETA: 12s - loss: 0.2713 - accuracy: 0.9018Training: batch 154 begins at 08:26:09.529446\n",
            "Training: batch 155 begins at 08:26:09.537027\n",
            "Training: batch 156 begins at 08:26:09.544947\n",
            "Training: batch 157 begins at 08:26:09.551384\n",
            "Training: batch 158 begins at 08:26:09.558766\n",
            "Training: batch 159 begins at 08:26:09.566470\n",
            "Training: batch 160 begins at 08:26:09.574101\n",
            " 161/1875 [=>............................] - ETA: 12s - loss: 0.2711 - accuracy: 0.9012Training: batch 161 begins at 08:26:09.582844\n",
            "Training: batch 162 begins at 08:26:09.590133\n",
            "Training: batch 163 begins at 08:26:09.597124\n",
            "Training: batch 164 begins at 08:26:09.604104\n",
            "Training: batch 165 begins at 08:26:09.611410\n",
            "Training: batch 166 begins at 08:26:09.618906\n",
            "Training: batch 167 begins at 08:26:09.625473\n",
            " 168/1875 [=>............................] - ETA: 12s - loss: 0.2700 - accuracy: 0.9020Training: batch 168 begins at 08:26:09.634410\n",
            "Training: batch 169 begins at 08:26:09.643790\n",
            "Training: batch 170 begins at 08:26:09.650962\n",
            "Training: batch 171 begins at 08:26:09.658517\n",
            "Training: batch 172 begins at 08:26:09.666814\n",
            "Training: batch 173 begins at 08:26:09.674629\n",
            "Training: batch 174 begins at 08:26:09.681835\n",
            " 175/1875 [=>............................] - ETA: 12s - loss: 0.2714 - accuracy: 0.9011Training: batch 175 begins at 08:26:09.690538\n",
            "Training: batch 176 begins at 08:26:09.697709\n",
            "Training: batch 177 begins at 08:26:09.705224\n",
            "Training: batch 178 begins at 08:26:09.713849\n",
            "Training: batch 179 begins at 08:26:09.721541\n",
            "Training: batch 180 begins at 08:26:09.729866\n",
            "Training: batch 181 begins at 08:26:09.737159\n",
            " 182/1875 [=>............................] - ETA: 12s - loss: 0.2710 - accuracy: 0.9014Training: batch 182 begins at 08:26:09.745889\n",
            "Training: batch 183 begins at 08:26:09.752918\n",
            "Training: batch 184 begins at 08:26:09.761363\n",
            "Training: batch 185 begins at 08:26:09.768309\n",
            "Training: batch 186 begins at 08:26:09.774588\n",
            "Training: batch 187 begins at 08:26:09.781126\n",
            "Training: batch 188 begins at 08:26:09.786335\n",
            " 189/1875 [==>...........................] - ETA: 12s - loss: 0.2699 - accuracy: 0.9010Training: batch 189 begins at 08:26:09.796743\n",
            "Training: batch 190 begins at 08:26:09.804697\n",
            "Training: batch 191 begins at 08:26:09.813593\n",
            "Training: batch 192 begins at 08:26:09.819761\n",
            "Training: batch 193 begins at 08:26:09.826776\n",
            "Training: batch 194 begins at 08:26:09.834341\n",
            "Training: batch 195 begins at 08:26:09.841523\n",
            " 196/1875 [==>...........................] - ETA: 12s - loss: 0.2701 - accuracy: 0.8999Training: batch 196 begins at 08:26:09.849923\n",
            "Training: batch 197 begins at 08:26:09.857089\n",
            "Training: batch 198 begins at 08:26:09.864132\n",
            "Training: batch 199 begins at 08:26:09.871605\n",
            "Training: batch 200 begins at 08:26:09.879550\n",
            "Training: batch 201 begins at 08:26:09.887298\n",
            "Training: batch 202 begins at 08:26:09.895429\n",
            " 203/1875 [==>...........................] - ETA: 12s - loss: 0.2690 - accuracy: 0.9006Training: batch 203 begins at 08:26:09.904003\n",
            "Training: batch 204 begins at 08:26:09.911721\n",
            "Training: batch 205 begins at 08:26:09.919414\n",
            "Training: batch 206 begins at 08:26:09.928036\n",
            "Training: batch 207 begins at 08:26:09.935563\n",
            "Training: batch 208 begins at 08:26:09.943254\n",
            "Training: batch 209 begins at 08:26:09.951334\n",
            " 210/1875 [==>...........................] - ETA: 12s - loss: 0.2663 - accuracy: 0.9021Training: batch 210 begins at 08:26:09.960162\n",
            "Training: batch 211 begins at 08:26:09.966461\n",
            "Training: batch 212 begins at 08:26:09.973626\n",
            "Training: batch 213 begins at 08:26:09.982334\n",
            "Training: batch 214 begins at 08:26:09.989593\n",
            "Training: batch 215 begins at 08:26:09.996616\n",
            "Training: batch 216 begins at 08:26:10.004748\n",
            " 217/1875 [==>...........................] - ETA: 12s - loss: 0.2662 - accuracy: 0.9019Training: batch 217 begins at 08:26:10.015816\n",
            "Training: batch 218 begins at 08:26:10.023998\n",
            "Training: batch 219 begins at 08:26:10.030487\n",
            "Training: batch 220 begins at 08:26:10.037891\n",
            "Training: batch 221 begins at 08:26:10.045820\n",
            "Training: batch 222 begins at 08:26:10.053558\n",
            "Training: batch 223 begins at 08:26:10.061111\n",
            " 224/1875 [==>...........................] - ETA: 12s - loss: 0.2636 - accuracy: 0.9026Training: batch 224 begins at 08:26:10.069501\n",
            "Training: batch 225 begins at 08:26:10.077711\n",
            "Training: batch 226 begins at 08:26:10.085459\n",
            "Training: batch 227 begins at 08:26:10.093773\n",
            "Training: batch 228 begins at 08:26:10.102197\n",
            "Training: batch 229 begins at 08:26:10.109711\n",
            "Training: batch 230 begins at 08:26:10.117418\n",
            " 231/1875 [==>...........................] - ETA: 12s - loss: 0.2605 - accuracy: 0.9031Training: batch 231 begins at 08:26:10.126885\n",
            "Training: batch 232 begins at 08:26:10.132882\n",
            "Training: batch 233 begins at 08:26:10.140654\n",
            "Training: batch 234 begins at 08:26:10.148890\n",
            "Training: batch 235 begins at 08:26:10.157474\n",
            "Training: batch 236 begins at 08:26:10.163407\n",
            "Training: batch 237 begins at 08:26:10.170785\n",
            " 238/1875 [==>...........................] - ETA: 12s - loss: 0.2613 - accuracy: 0.9026Training: batch 238 begins at 08:26:10.180859\n",
            "Training: batch 239 begins at 08:26:10.186823\n",
            "Training: batch 240 begins at 08:26:10.195363\n",
            "Training: batch 241 begins at 08:26:10.202417\n",
            "Training: batch 242 begins at 08:26:10.210278\n",
            "Training: batch 243 begins at 08:26:10.218535\n",
            "Training: batch 244 begins at 08:26:10.226491\n",
            " 245/1875 [==>...........................] - ETA: 12s - loss: 0.2616 - accuracy: 0.9024Training: batch 245 begins at 08:26:10.234549\n",
            "Training: batch 246 begins at 08:26:10.241426\n",
            "Training: batch 247 begins at 08:26:10.248204\n",
            "Training: batch 248 begins at 08:26:10.255864\n",
            "Training: batch 249 begins at 08:26:10.263667\n",
            "Training: batch 250 begins at 08:26:10.270565\n",
            "Training: batch 251 begins at 08:26:10.277708\n",
            " 252/1875 [===>..........................] - ETA: 12s - loss: 0.2628 - accuracy: 0.9020Training: batch 252 begins at 08:26:10.286594\n",
            "Training: batch 253 begins at 08:26:10.292356\n",
            "Training: batch 254 begins at 08:26:10.299191\n",
            "Training: batch 255 begins at 08:26:10.306002\n",
            "Training: batch 256 begins at 08:26:10.312751\n",
            "Training: batch 257 begins at 08:26:10.319764\n",
            "Training: batch 258 begins at 08:26:10.329382\n",
            " 259/1875 [===>..........................] - ETA: 12s - loss: 0.2609 - accuracy: 0.9023Training: batch 259 begins at 08:26:10.338028\n",
            "Training: batch 260 begins at 08:26:10.343844\n",
            "Training: batch 261 begins at 08:26:10.350940\n",
            "Training: batch 262 begins at 08:26:10.357834\n",
            "Training: batch 263 begins at 08:26:10.366452\n",
            "Training: batch 264 begins at 08:26:10.372207\n",
            "Training: batch 265 begins at 08:26:10.378945\n",
            " 266/1875 [===>..........................] - ETA: 12s - loss: 0.2588 - accuracy: 0.9030Training: batch 266 begins at 08:26:10.387560\n",
            "Training: batch 267 begins at 08:26:10.393458\n",
            "Training: batch 268 begins at 08:26:10.400871\n",
            "Training: batch 269 begins at 08:26:10.409684\n",
            "Training: batch 270 begins at 08:26:10.415572\n",
            "Training: batch 271 begins at 08:26:10.422645\n",
            "Training: batch 272 begins at 08:26:10.430018\n",
            " 273/1875 [===>..........................] - ETA: 11s - loss: 0.2603 - accuracy: 0.9019Training: batch 273 begins at 08:26:10.439160\n",
            "Training: batch 274 begins at 08:26:10.447297\n",
            "Training: batch 275 begins at 08:26:10.452875\n",
            "Training: batch 276 begins at 08:26:10.461202\n",
            "Training: batch 277 begins at 08:26:10.466862\n",
            "Training: batch 278 begins at 08:26:10.474907\n",
            "Training: batch 279 begins at 08:26:10.482400\n",
            " 280/1875 [===>..........................] - ETA: 11s - loss: 0.2592 - accuracy: 0.9021Training: batch 280 begins at 08:26:10.491323\n",
            "Training: batch 281 begins at 08:26:10.497332\n",
            "Training: batch 282 begins at 08:26:10.504720\n",
            "Training: batch 283 begins at 08:26:10.512419\n",
            "Training: batch 284 begins at 08:26:10.518179\n",
            "Training: batch 285 begins at 08:26:10.525395\n",
            "Training: batch 286 begins at 08:26:10.532604\n",
            " 287/1875 [===>..........................] - ETA: 11s - loss: 0.2582 - accuracy: 0.9024Training: batch 287 begins at 08:26:10.541525\n",
            "Training: batch 288 begins at 08:26:10.547102\n",
            "Training: batch 289 begins at 08:26:10.553736\n",
            "Training: batch 290 begins at 08:26:10.561185\n",
            "Training: batch 291 begins at 08:26:10.568852\n",
            "Training: batch 292 begins at 08:26:10.574495\n",
            "Training: batch 293 begins at 08:26:10.581735\n",
            "Training: batch 294 begins at 08:26:10.589427\n",
            " 295/1875 [===>..........................] - ETA: 11s - loss: 0.2574 - accuracy: 0.9033Training: batch 295 begins at 08:26:10.596701\n",
            "Training: batch 296 begins at 08:26:10.603661\n",
            "Training: batch 297 begins at 08:26:10.610602\n",
            "Training: batch 298 begins at 08:26:10.618568\n",
            "Training: batch 299 begins at 08:26:10.625077\n",
            "Training: batch 300 begins at 08:26:10.632079\n",
            "Training: batch 301 begins at 08:26:10.639639\n",
            " 302/1875 [===>..........................] - ETA: 11s - loss: 0.2585 - accuracy: 0.9029Training: batch 302 begins at 08:26:10.648196\n",
            "Training: batch 303 begins at 08:26:10.654178\n",
            "Training: batch 304 begins at 08:26:10.661508\n",
            "Training: batch 305 begins at 08:26:10.669591\n",
            "Training: batch 306 begins at 08:26:10.676880\n",
            "Training: batch 307 begins at 08:26:10.686082\n",
            "Training: batch 308 begins at 08:26:10.694568\n",
            " 309/1875 [===>..........................] - ETA: 11s - loss: 0.2584 - accuracy: 0.9025Training: batch 309 begins at 08:26:10.702944\n",
            "Training: batch 310 begins at 08:26:10.710295\n",
            "Training: batch 311 begins at 08:26:10.717904\n",
            "Training: batch 312 begins at 08:26:10.725845\n",
            "Training: batch 313 begins at 08:26:10.731549\n",
            "Training: batch 314 begins at 08:26:10.737382\n",
            "Training: batch 315 begins at 08:26:10.743346\n",
            "Training: batch 316 begins at 08:26:10.749859\n",
            " 317/1875 [====>.........................] - ETA: 11s - loss: 0.2571 - accuracy: 0.9032Training: batch 317 begins at 08:26:10.762843\n",
            "Training: batch 318 begins at 08:26:10.770490\n",
            "Training: batch 319 begins at 08:26:10.779276\n",
            "Training: batch 320 begins at 08:26:10.786751\n",
            "Training: batch 321 begins at 08:26:10.796762\n",
            " 322/1875 [====>.........................] - ETA: 11s - loss: 0.2583 - accuracy: 0.9025Training: batch 322 begins at 08:26:10.808850\n",
            "Training: batch 323 begins at 08:26:10.816722\n",
            "Training: batch 324 begins at 08:26:10.825595\n",
            "Training: batch 325 begins at 08:26:10.831481\n",
            "Training: batch 326 begins at 08:26:10.839436\n",
            "Training: batch 327 begins at 08:26:10.846944\n",
            "Training: batch 328 begins at 08:26:10.853897\n",
            " 329/1875 [====>.........................] - ETA: 11s - loss: 0.2580 - accuracy: 0.9028Training: batch 329 begins at 08:26:10.863008\n",
            "Training: batch 330 begins at 08:26:10.871275\n",
            "Training: batch 331 begins at 08:26:10.880771\n",
            "Training: batch 332 begins at 08:26:10.885863\n",
            "Training: batch 333 begins at 08:26:10.894614\n",
            "Training: batch 334 begins at 08:26:10.900954\n",
            "Training: batch 335 begins at 08:26:10.908132\n",
            " 336/1875 [====>.........................] - ETA: 11s - loss: 0.2571 - accuracy: 0.9031Training: batch 336 begins at 08:26:10.916778\n",
            "Training: batch 337 begins at 08:26:10.923781\n",
            "Training: batch 338 begins at 08:26:10.930864\n",
            "Training: batch 339 begins at 08:26:10.940533\n",
            "Training: batch 340 begins at 08:26:10.947320\n",
            "Training: batch 341 begins at 08:26:10.954887\n",
            "Training: batch 342 begins at 08:26:10.962573\n",
            " 343/1875 [====>.........................] - ETA: 11s - loss: 0.2562 - accuracy: 0.9037Training: batch 343 begins at 08:26:10.970630\n",
            "Training: batch 344 begins at 08:26:10.977819\n",
            "Training: batch 345 begins at 08:26:10.985314\n",
            "Training: batch 346 begins at 08:26:10.992909\n",
            "Training: batch 347 begins at 08:26:10.999756\n",
            "Training: batch 348 begins at 08:26:11.007423\n",
            "Training: batch 349 begins at 08:26:11.015554\n",
            " 350/1875 [====>.........................] - ETA: 11s - loss: 0.2549 - accuracy: 0.9041Training: batch 350 begins at 08:26:11.024392\n",
            "Training: batch 351 begins at 08:26:11.031225\n",
            "Training: batch 352 begins at 08:26:11.038399\n",
            "Training: batch 353 begins at 08:26:11.046508\n",
            "Training: batch 354 begins at 08:26:11.052435\n",
            "Training: batch 355 begins at 08:26:11.059215\n",
            "Training: batch 356 begins at 08:26:11.066334\n",
            " 357/1875 [====>.........................] - ETA: 11s - loss: 0.2546 - accuracy: 0.9046Training: batch 357 begins at 08:26:11.075399\n",
            "Training: batch 358 begins at 08:26:11.081299\n",
            "Training: batch 359 begins at 08:26:11.088539\n",
            "Training: batch 360 begins at 08:26:11.097494\n",
            "Training: batch 361 begins at 08:26:11.103371\n",
            "Training: batch 362 begins at 08:26:11.110291\n",
            "Training: batch 363 begins at 08:26:11.117290\n",
            " 364/1875 [====>.........................] - ETA: 11s - loss: 0.2527 - accuracy: 0.9051Training: batch 364 begins at 08:26:11.125881\n",
            "Training: batch 365 begins at 08:26:11.132765\n",
            "Training: batch 366 begins at 08:26:11.140037\n",
            "Training: batch 367 begins at 08:26:11.147500\n",
            "Training: batch 368 begins at 08:26:11.154343\n",
            "Training: batch 369 begins at 08:26:11.160719\n",
            "Training: batch 370 begins at 08:26:11.168035\n",
            " 371/1875 [====>.........................] - ETA: 11s - loss: 0.2532 - accuracy: 0.9053Training: batch 371 begins at 08:26:11.176826\n",
            "Training: batch 372 begins at 08:26:11.184650\n",
            "Training: batch 373 begins at 08:26:11.190482\n",
            "Training: batch 374 begins at 08:26:11.197411\n",
            "Training: batch 375 begins at 08:26:11.204530\n",
            "Training: batch 376 begins at 08:26:11.211720\n",
            "Training: batch 377 begins at 08:26:11.219035\n",
            " 378/1875 [=====>........................] - ETA: 11s - loss: 0.2519 - accuracy: 0.9057Training: batch 378 begins at 08:26:11.227092\n",
            "Training: batch 379 begins at 08:26:11.234465\n",
            "Training: batch 380 begins at 08:26:11.242457\n",
            "Training: batch 381 begins at 08:26:11.248206\n",
            "Training: batch 382 begins at 08:26:11.255844\n",
            "Training: batch 383 begins at 08:26:11.263747\n",
            "Training: batch 384 begins at 08:26:11.270778\n",
            " 385/1875 [=====>........................] - ETA: 11s - loss: 0.2527 - accuracy: 0.9054Training: batch 385 begins at 08:26:11.282619\n",
            "Training: batch 386 begins at 08:26:11.290707\n",
            "Training: batch 387 begins at 08:26:11.297818\n",
            "Training: batch 388 begins at 08:26:11.309355\n",
            "Training: batch 389 begins at 08:26:11.317046\n",
            "Training: batch 390 begins at 08:26:11.326687\n",
            " 391/1875 [=====>........................] - ETA: 11s - loss: 0.2509 - accuracy: 0.9062Training: batch 391 begins at 08:26:11.336340\n",
            "Training: batch 392 begins at 08:26:11.341847\n",
            "Training: batch 393 begins at 08:26:11.349181\n",
            "Training: batch 394 begins at 08:26:11.357748\n",
            "Training: batch 395 begins at 08:26:11.365112\n",
            "Training: batch 396 begins at 08:26:11.373499\n",
            "Training: batch 397 begins at 08:26:11.380224\n",
            " 398/1875 [=====>........................] - ETA: 11s - loss: 0.2509 - accuracy: 0.9058Training: batch 398 begins at 08:26:11.392136\n",
            "Training: batch 399 begins at 08:26:11.403142\n",
            "Training: batch 400 begins at 08:26:11.411165\n",
            "Training: batch 401 begins at 08:26:11.418584\n",
            "Training: batch 402 begins at 08:26:11.425135\n",
            "Training: batch 403 begins at 08:26:11.431666\n",
            "Training: batch 404 begins at 08:26:11.438934\n",
            " 405/1875 [=====>........................] - ETA: 11s - loss: 0.2523 - accuracy: 0.9054Training: batch 405 begins at 08:26:11.447963\n",
            "Training: batch 406 begins at 08:26:11.454008\n",
            "Training: batch 407 begins at 08:26:11.461261\n",
            "Training: batch 408 begins at 08:26:11.469097\n",
            "Training: batch 409 begins at 08:26:11.474784\n",
            "Training: batch 410 begins at 08:26:11.482375\n",
            "Training: batch 411 begins at 08:26:11.489921\n",
            " 412/1875 [=====>........................] - ETA: 11s - loss: 0.2525 - accuracy: 0.9053Training: batch 412 begins at 08:26:11.498285\n",
            "Training: batch 413 begins at 08:26:11.506059\n",
            "Training: batch 414 begins at 08:26:11.511782\n",
            "Training: batch 415 begins at 08:26:11.518717\n",
            "Training: batch 416 begins at 08:26:11.525781\n",
            "Training: batch 417 begins at 08:26:11.532002\n",
            "Training: batch 418 begins at 08:26:11.537819\n",
            "Training: batch 419 begins at 08:26:11.543379\n",
            " 420/1875 [=====>........................] - ETA: 10s - loss: 0.2546 - accuracy: 0.9048Training: batch 420 begins at 08:26:11.552749\n",
            "Training: batch 421 begins at 08:26:11.559866\n",
            "Training: batch 422 begins at 08:26:11.567383\n",
            "Training: batch 423 begins at 08:26:11.574920\n",
            "Training: batch 424 begins at 08:26:11.581414\n",
            "Training: batch 425 begins at 08:26:11.587770\n",
            "Training: batch 426 begins at 08:26:11.594623\n",
            " 427/1875 [=====>........................] - ETA: 10s - loss: 0.2551 - accuracy: 0.9042Training: batch 427 begins at 08:26:11.603304\n",
            "Training: batch 428 begins at 08:26:11.610700\n",
            "Training: batch 429 begins at 08:26:11.617189\n",
            "Training: batch 430 begins at 08:26:11.624570\n",
            "Training: batch 431 begins at 08:26:11.631360\n",
            "Training: batch 432 begins at 08:26:11.637417\n",
            "Training: batch 433 begins at 08:26:11.646219\n",
            " 434/1875 [=====>........................] - ETA: 10s - loss: 0.2558 - accuracy: 0.9042Training: batch 434 begins at 08:26:11.655646\n",
            "Training: batch 435 begins at 08:26:11.663003\n",
            "Training: batch 436 begins at 08:26:11.670767\n",
            "Training: batch 437 begins at 08:26:11.677474\n",
            "Training: batch 438 begins at 08:26:11.684644\n",
            "Training: batch 439 begins at 08:26:11.693130\n",
            "Training: batch 440 begins at 08:26:11.700520\n",
            " 441/1875 [======>.......................] - ETA: 10s - loss: 0.2565 - accuracy: 0.9041Training: batch 441 begins at 08:26:11.709686\n",
            "Training: batch 442 begins at 08:26:11.716763\n",
            "Training: batch 443 begins at 08:26:11.726709\n",
            "Training: batch 444 begins at 08:26:11.734167\n",
            "Training: batch 445 begins at 08:26:11.740600\n",
            "Training: batch 446 begins at 08:26:11.746790\n",
            " 447/1875 [======>.......................] - ETA: 10s - loss: 0.2563 - accuracy: 0.9041Training: batch 447 begins at 08:26:11.761350\n",
            "Training: batch 448 begins at 08:26:11.769323\n",
            "Training: batch 449 begins at 08:26:11.778522\n",
            "Training: batch 450 begins at 08:26:11.785779\n",
            "Training: batch 451 begins at 08:26:11.794767\n",
            "Training: batch 452 begins at 08:26:11.803909\n",
            " 453/1875 [======>.......................] - ETA: 10s - loss: 0.2559 - accuracy: 0.9040Training: batch 453 begins at 08:26:11.817362\n",
            "Training: batch 454 begins at 08:26:11.823381\n",
            "Training: batch 455 begins at 08:26:11.830582\n",
            "Training: batch 456 begins at 08:26:11.836429\n",
            "Training: batch 457 begins at 08:26:11.844523\n",
            "Training: batch 458 begins at 08:26:11.853491\n",
            "Training: batch 459 begins at 08:26:11.862571\n",
            " 460/1875 [======>.......................] - ETA: 10s - loss: 0.2563 - accuracy: 0.9039Training: batch 460 begins at 08:26:11.876722\n",
            "Training: batch 461 begins at 08:26:11.884866\n",
            "Training: batch 462 begins at 08:26:11.895821\n",
            "Training: batch 463 begins at 08:26:11.901950\n",
            "Training: batch 464 begins at 08:26:11.908482\n",
            "Training: batch 465 begins at 08:26:11.914479\n",
            "Training: batch 466 begins at 08:26:11.920558\n",
            " 467/1875 [======>.......................] - ETA: 10s - loss: 0.2561 - accuracy: 0.9040Training: batch 467 begins at 08:26:11.927899\n",
            "Training: batch 468 begins at 08:26:11.935529\n",
            "Training: batch 469 begins at 08:26:11.943226\n",
            "Training: batch 470 begins at 08:26:11.950625\n",
            "Training: batch 471 begins at 08:26:11.956970\n",
            "Training: batch 472 begins at 08:26:11.964243\n",
            "Training: batch 473 begins at 08:26:11.972235\n",
            " 474/1875 [======>.......................] - ETA: 10s - loss: 0.2559 - accuracy: 0.9044Training: batch 474 begins at 08:26:11.982884\n",
            "Training: batch 475 begins at 08:26:11.990628\n",
            "Training: batch 476 begins at 08:26:11.998881\n",
            "Training: batch 477 begins at 08:26:12.007697\n",
            "Training: batch 478 begins at 08:26:12.014543\n",
            "Training: batch 479 begins at 08:26:12.022330\n",
            "Training: batch 480 begins at 08:26:12.029910\n",
            " 481/1875 [======>.......................] - ETA: 10s - loss: 0.2563 - accuracy: 0.9040Training: batch 481 begins at 08:26:12.038339\n",
            "Training: batch 482 begins at 08:26:12.045946\n",
            "Training: batch 483 begins at 08:26:12.054260\n",
            "Training: batch 484 begins at 08:26:12.060758\n",
            "Training: batch 485 begins at 08:26:12.066964\n",
            "Training: batch 486 begins at 08:26:12.074124\n",
            "Training: batch 487 begins at 08:26:12.082420\n",
            " 488/1875 [======>.......................] - ETA: 10s - loss: 0.2565 - accuracy: 0.9038Training: batch 488 begins at 08:26:12.092736\n",
            "Training: batch 489 begins at 08:26:12.100349\n",
            "Training: batch 490 begins at 08:26:12.106819\n",
            "Training: batch 491 begins at 08:26:12.113735\n",
            "Training: batch 492 begins at 08:26:12.121177\n",
            "Training: batch 493 begins at 08:26:12.127647\n",
            "Training: batch 494 begins at 08:26:12.134425\n",
            " 495/1875 [======>.......................] - ETA: 10s - loss: 0.2574 - accuracy: 0.9037Training: batch 495 begins at 08:26:12.143088\n",
            "Training: batch 496 begins at 08:26:12.149812\n",
            "Training: batch 497 begins at 08:26:12.157317\n",
            "Training: batch 498 begins at 08:26:12.163304\n",
            "Training: batch 499 begins at 08:26:12.169182\n",
            "Training: batch 500 begins at 08:26:12.176437\n",
            "Training: batch 501 begins at 08:26:12.184539\n",
            " 502/1875 [=======>......................] - ETA: 10s - loss: 0.2584 - accuracy: 0.9033Training: batch 502 begins at 08:26:12.194237\n",
            "Training: batch 503 begins at 08:26:12.200916\n",
            "Training: batch 504 begins at 08:26:12.208117\n",
            "Training: batch 505 begins at 08:26:12.215624\n",
            "Training: batch 506 begins at 08:26:12.221971\n",
            "Training: batch 507 begins at 08:26:12.228933\n",
            "Training: batch 508 begins at 08:26:12.235516\n",
            " 509/1875 [=======>......................] - ETA: 10s - loss: 0.2582 - accuracy: 0.9029Training: batch 509 begins at 08:26:12.244553\n",
            "Training: batch 510 begins at 08:26:12.251541\n",
            "Training: batch 511 begins at 08:26:12.258736\n",
            "Training: batch 512 begins at 08:26:12.265858\n",
            "Training: batch 513 begins at 08:26:12.272368\n",
            "Training: batch 514 begins at 08:26:12.280128\n",
            "Training: batch 515 begins at 08:26:12.287295\n",
            " 516/1875 [=======>......................] - ETA: 10s - loss: 0.2582 - accuracy: 0.9029Training: batch 516 begins at 08:26:12.297178\n",
            "Training: batch 517 begins at 08:26:12.304738\n",
            "Training: batch 518 begins at 08:26:12.311445\n",
            "Training: batch 519 begins at 08:26:12.318477\n",
            "Training: batch 520 begins at 08:26:12.326120\n",
            "Training: batch 521 begins at 08:26:12.332971\n",
            "Training: batch 522 begins at 08:26:12.340137\n",
            " 523/1875 [=======>......................] - ETA: 10s - loss: 0.2585 - accuracy: 0.9030Training: batch 523 begins at 08:26:12.349909\n",
            "Training: batch 524 begins at 08:26:12.357067\n",
            "Training: batch 525 begins at 08:26:12.363421\n",
            "Training: batch 526 begins at 08:26:12.369911\n",
            "Training: batch 527 begins at 08:26:12.376187\n",
            "Training: batch 528 begins at 08:26:12.383367\n",
            "Training: batch 529 begins at 08:26:12.391072\n",
            " 530/1875 [=======>......................] - ETA: 10s - loss: 0.2592 - accuracy: 0.9025Training: batch 530 begins at 08:26:12.400959\n",
            "Training: batch 531 begins at 08:26:12.407611\n",
            "Training: batch 532 begins at 08:26:12.414837\n",
            "Training: batch 533 begins at 08:26:12.422104\n",
            "Training: batch 534 begins at 08:26:12.428973\n",
            "Training: batch 535 begins at 08:26:12.436293\n",
            "Training: batch 536 begins at 08:26:12.442925\n",
            " 537/1875 [=======>......................] - ETA: 10s - loss: 0.2601 - accuracy: 0.9023Training: batch 537 begins at 08:26:12.456326\n",
            "Training: batch 538 begins at 08:26:12.464066\n",
            "Training: batch 539 begins at 08:26:12.470988\n",
            "Training: batch 540 begins at 08:26:12.477312\n",
            "Training: batch 541 begins at 08:26:12.484798\n",
            "Training: batch 542 begins at 08:26:12.492250\n",
            "Training: batch 543 begins at 08:26:12.500329\n",
            " 544/1875 [=======>......................] - ETA: 10s - loss: 0.2609 - accuracy: 0.9020Training: batch 544 begins at 08:26:12.510282\n",
            "Training: batch 545 begins at 08:26:12.517318\n",
            "Training: batch 546 begins at 08:26:12.527900\n",
            "Training: batch 547 begins at 08:26:12.535032\n",
            "Training: batch 548 begins at 08:26:12.541241\n",
            "Training: batch 549 begins at 08:26:12.548632\n",
            "Training: batch 550 begins at 08:26:12.557464\n",
            " 551/1875 [=======>......................] - ETA: 10s - loss: 0.2607 - accuracy: 0.9018Training: batch 551 begins at 08:26:12.566826\n",
            "Training: batch 552 begins at 08:26:12.573591\n",
            "Training: batch 553 begins at 08:26:12.579734\n",
            "Training: batch 554 begins at 08:26:12.587138\n",
            "Training: batch 555 begins at 08:26:12.594100\n",
            "Training: batch 556 begins at 08:26:12.601724\n",
            "Training: batch 557 begins at 08:26:12.609920\n",
            " 558/1875 [=======>......................] - ETA: 9s - loss: 0.2605 - accuracy: 0.9021 Training: batch 558 begins at 08:26:12.618590\n",
            "Training: batch 559 begins at 08:26:12.626429\n",
            "Training: batch 560 begins at 08:26:12.632960\n",
            "Training: batch 561 begins at 08:26:12.640271\n",
            "Training: batch 562 begins at 08:26:12.647821\n",
            "Training: batch 563 begins at 08:26:12.655499\n",
            "Training: batch 564 begins at 08:26:12.662454\n",
            " 565/1875 [========>.....................] - ETA: 9s - loss: 0.2612 - accuracy: 0.9018Training: batch 565 begins at 08:26:12.672408\n",
            "Training: batch 566 begins at 08:26:12.679660\n",
            "Training: batch 567 begins at 08:26:12.686019\n",
            "Training: batch 568 begins at 08:26:12.693630\n",
            "Training: batch 569 begins at 08:26:12.701496\n",
            "Training: batch 570 begins at 08:26:12.710220\n",
            "Training: batch 571 begins at 08:26:12.718028\n",
            " 572/1875 [========>.....................] - ETA: 9s - loss: 0.2611 - accuracy: 0.9022Training: batch 572 begins at 08:26:12.726663\n",
            "Training: batch 573 begins at 08:26:12.734600\n",
            "Training: batch 574 begins at 08:26:12.741424\n",
            "Training: batch 575 begins at 08:26:12.749037\n",
            "Training: batch 576 begins at 08:26:12.760241\n",
            "Training: batch 577 begins at 08:26:12.770317\n",
            " 578/1875 [========>.....................] - ETA: 9s - loss: 0.2608 - accuracy: 0.9021Training: batch 578 begins at 08:26:12.779978\n",
            "Training: batch 579 begins at 08:26:12.786937\n",
            "Training: batch 580 begins at 08:26:12.794450\n",
            "Training: batch 581 begins at 08:26:12.805342\n",
            "Training: batch 582 begins at 08:26:12.812239\n",
            "Training: batch 583 begins at 08:26:12.818033\n",
            "Training: batch 584 begins at 08:26:12.824349\n",
            " 585/1875 [========>.....................] - ETA: 9s - loss: 0.2604 - accuracy: 0.9022Training: batch 585 begins at 08:26:12.835003\n",
            "Training: batch 586 begins at 08:26:12.841320\n",
            "Training: batch 587 begins at 08:26:12.847337\n",
            "Training: batch 588 begins at 08:26:12.854292\n",
            "Training: batch 589 begins at 08:26:12.860034\n",
            "Training: batch 590 begins at 08:26:12.865674\n",
            "Training: batch 591 begins at 08:26:12.871402\n",
            "Training: batch 592 begins at 08:26:12.876993\n",
            " 593/1875 [========>.....................] - ETA: 9s - loss: 0.2594 - accuracy: 0.9027Training: batch 593 begins at 08:26:12.885553\n",
            "Training: batch 594 begins at 08:26:12.891302\n",
            "Training: batch 595 begins at 08:26:12.899997\n",
            "Training: batch 596 begins at 08:26:12.905599\n",
            "Training: batch 597 begins at 08:26:12.914091\n",
            "Training: batch 598 begins at 08:26:12.922234\n",
            "Training: batch 599 begins at 08:26:12.931254\n",
            " 600/1875 [========>.....................] - ETA: 9s - loss: 0.2589 - accuracy: 0.9027Training: batch 600 begins at 08:26:12.940282\n",
            "Training: batch 601 begins at 08:26:12.946350\n",
            "Training: batch 602 begins at 08:26:12.952234\n",
            "Training: batch 603 begins at 08:26:12.958809\n",
            "Training: batch 604 begins at 08:26:12.965276\n",
            "Training: batch 605 begins at 08:26:12.973190\n",
            "Training: batch 606 begins at 08:26:12.980388\n",
            "Training: batch 607 begins at 08:26:12.987572\n",
            " 608/1875 [========>.....................] - ETA: 9s - loss: 0.2582 - accuracy: 0.9029Training: batch 608 begins at 08:26:12.997602\n",
            "Training: batch 609 begins at 08:26:13.006874\n",
            "Training: batch 610 begins at 08:26:13.016656\n",
            "Training: batch 611 begins at 08:26:13.025456\n",
            "Training: batch 612 begins at 08:26:13.032832\n",
            "Training: batch 613 begins at 08:26:13.042320\n",
            " 614/1875 [========>.....................] - ETA: 9s - loss: 0.2586 - accuracy: 0.9025Training: batch 614 begins at 08:26:13.053542\n",
            "Training: batch 615 begins at 08:26:13.066301\n",
            "Training: batch 616 begins at 08:26:13.073024\n",
            "Training: batch 617 begins at 08:26:13.080328\n",
            "Training: batch 618 begins at 08:26:13.088703\n",
            "Training: batch 619 begins at 08:26:13.099807\n",
            " 620/1875 [========>.....................] - ETA: 9s - loss: 0.2585 - accuracy: 0.9024Training: batch 620 begins at 08:26:13.110186\n",
            "Training: batch 621 begins at 08:26:13.118786\n",
            "Training: batch 622 begins at 08:26:13.128716\n",
            "Training: batch 623 begins at 08:26:13.137407\n",
            "Training: batch 624 begins at 08:26:13.146828\n",
            " 625/1875 [=========>....................] - ETA: 9s - loss: 0.2590 - accuracy: 0.9021Training: batch 625 begins at 08:26:13.159548\n",
            "Training: batch 626 begins at 08:26:13.168384\n",
            "Training: batch 627 begins at 08:26:13.174142\n",
            "Training: batch 628 begins at 08:26:13.181817\n",
            "Training: batch 629 begins at 08:26:13.188871\n",
            "Training: batch 630 begins at 08:26:13.194625\n",
            "Training: batch 631 begins at 08:26:13.202251\n",
            " 632/1875 [=========>....................] - ETA: 9s - loss: 0.2596 - accuracy: 0.9020Training: batch 632 begins at 08:26:13.211105\n",
            "Training: batch 633 begins at 08:26:13.219694\n",
            "Training: batch 634 begins at 08:26:13.225336\n",
            "Training: batch 635 begins at 08:26:13.233357\n",
            "Training: batch 636 begins at 08:26:13.240341\n",
            "Training: batch 637 begins at 08:26:13.246368\n",
            "Training: batch 638 begins at 08:26:13.253969\n",
            " 639/1875 [=========>....................] - ETA: 9s - loss: 0.2587 - accuracy: 0.9024Training: batch 639 begins at 08:26:13.263571\n",
            "Training: batch 640 begins at 08:26:13.269912\n",
            "Training: batch 641 begins at 08:26:13.277729\n",
            "Training: batch 642 begins at 08:26:13.284113\n",
            "Training: batch 643 begins at 08:26:13.291032\n",
            "Training: batch 644 begins at 08:26:13.297368\n",
            "Training: batch 645 begins at 08:26:13.304027\n",
            "Training: batch 646 begins at 08:26:13.311244\n",
            " 647/1875 [=========>....................] - ETA: 9s - loss: 0.2586 - accuracy: 0.9024Training: batch 647 begins at 08:26:13.319465\n",
            "Training: batch 648 begins at 08:26:13.326724\n",
            "Training: batch 649 begins at 08:26:13.333816\n",
            "Training: batch 650 begins at 08:26:13.341281\n",
            "Training: batch 651 begins at 08:26:13.349720\n",
            "Training: batch 652 begins at 08:26:13.356956\n",
            "Training: batch 653 begins at 08:26:13.364471\n",
            " 654/1875 [=========>....................] - ETA: 9s - loss: 0.2582 - accuracy: 0.9024Training: batch 654 begins at 08:26:13.372706\n",
            "Training: batch 655 begins at 08:26:13.379980\n",
            "Training: batch 656 begins at 08:26:13.387095\n",
            "Training: batch 657 begins at 08:26:13.394299\n",
            "Training: batch 658 begins at 08:26:13.400328\n",
            "Training: batch 659 begins at 08:26:13.406997\n",
            "Training: batch 660 begins at 08:26:13.413880\n",
            " 661/1875 [=========>....................] - ETA: 9s - loss: 0.2576 - accuracy: 0.9027Training: batch 661 begins at 08:26:13.422745\n",
            "Training: batch 662 begins at 08:26:13.428635\n",
            "Training: batch 663 begins at 08:26:13.435007\n",
            "Training: batch 664 begins at 08:26:13.442880\n",
            "Training: batch 665 begins at 08:26:13.449886\n",
            "Training: batch 666 begins at 08:26:13.456494\n",
            "Training: batch 667 begins at 08:26:13.463886\n",
            "Training: batch 668 begins at 08:26:13.470527\n",
            " 669/1875 [=========>....................] - ETA: 9s - loss: 0.2583 - accuracy: 0.9023Training: batch 669 begins at 08:26:13.479806\n",
            "Training: batch 670 begins at 08:26:13.487627\n",
            "Training: batch 671 begins at 08:26:13.494335\n",
            "Training: batch 672 begins at 08:26:13.501551\n",
            "Training: batch 673 begins at 08:26:13.508088\n",
            "Training: batch 674 begins at 08:26:13.515638\n",
            "Training: batch 675 begins at 08:26:13.523590\n",
            " 676/1875 [=========>....................] - ETA: 9s - loss: 0.2586 - accuracy: 0.9022Training: batch 676 begins at 08:26:13.533570\n",
            "Training: batch 677 begins at 08:26:13.541482\n",
            "Training: batch 678 begins at 08:26:13.549103\n",
            "Training: batch 679 begins at 08:26:13.555868\n",
            "Training: batch 680 begins at 08:26:13.562181\n",
            "Training: batch 681 begins at 08:26:13.569788\n",
            "Training: batch 682 begins at 08:26:13.577615\n",
            " 683/1875 [=========>....................] - ETA: 9s - loss: 0.2579 - accuracy: 0.9022Training: batch 683 begins at 08:26:13.586773\n",
            "Training: batch 684 begins at 08:26:13.593674\n",
            "Training: batch 685 begins at 08:26:13.600908\n",
            "Training: batch 686 begins at 08:26:13.607006\n",
            "Training: batch 687 begins at 08:26:13.614033\n",
            "Training: batch 688 begins at 08:26:13.621546\n",
            "Training: batch 689 begins at 08:26:13.629480\n",
            " 690/1875 [==========>...................] - ETA: 9s - loss: 0.2581 - accuracy: 0.9022Training: batch 690 begins at 08:26:13.638456\n",
            "Training: batch 691 begins at 08:26:13.646402\n",
            "Training: batch 692 begins at 08:26:13.653442\n",
            "Training: batch 693 begins at 08:26:13.659665\n",
            "Training: batch 694 begins at 08:26:13.666852\n",
            "Training: batch 695 begins at 08:26:13.673238\n",
            "Training: batch 696 begins at 08:26:13.680399\n",
            " 697/1875 [==========>...................] - ETA: 8s - loss: 0.2591 - accuracy: 0.9021Training: batch 697 begins at 08:26:13.689577\n",
            "Training: batch 698 begins at 08:26:13.696758\n",
            "Training: batch 699 begins at 08:26:13.704162\n",
            "Training: batch 700 begins at 08:26:13.710597\n",
            "Training: batch 701 begins at 08:26:13.716601\n",
            "Training: batch 702 begins at 08:26:13.723764\n",
            "Training: batch 703 begins at 08:26:13.731437\n",
            " 704/1875 [==========>...................] - ETA: 8s - loss: 0.2588 - accuracy: 0.9021Training: batch 704 begins at 08:26:13.741051\n",
            "Training: batch 705 begins at 08:26:13.749338\n",
            "Training: batch 706 begins at 08:26:13.757260\n",
            "Training: batch 707 begins at 08:26:13.763677\n",
            "Training: batch 708 begins at 08:26:13.772527\n",
            "Training: batch 709 begins at 08:26:13.779238\n",
            "Training: batch 710 begins at 08:26:13.790430\n",
            " 711/1875 [==========>...................] - ETA: 8s - loss: 0.2584 - accuracy: 0.9023Training: batch 711 begins at 08:26:13.805968\n",
            "Training: batch 712 begins at 08:26:13.813838\n",
            "Training: batch 713 begins at 08:26:13.821613\n",
            "Training: batch 714 begins at 08:26:13.829503\n",
            "Training: batch 715 begins at 08:26:13.839596\n",
            "Training: batch 716 begins at 08:26:13.847800\n",
            " 717/1875 [==========>...................] - ETA: 8s - loss: 0.2581 - accuracy: 0.9021Training: batch 717 begins at 08:26:13.859926\n",
            "Training: batch 718 begins at 08:26:13.867596\n",
            "Training: batch 719 begins at 08:26:13.875325\n",
            "Training: batch 720 begins at 08:26:13.880225\n",
            "Training: batch 721 begins at 08:26:13.887597\n",
            "Training: batch 722 begins at 08:26:13.895012\n",
            "Training: batch 723 begins at 08:26:13.903233\n",
            " 724/1875 [==========>...................] - ETA: 8s - loss: 0.2579 - accuracy: 0.9022Training: batch 724 begins at 08:26:13.912440\n",
            "Training: batch 725 begins at 08:26:13.919738\n",
            "Training: batch 726 begins at 08:26:13.928059\n",
            "Training: batch 727 begins at 08:26:13.935719\n",
            "Training: batch 728 begins at 08:26:13.942224\n",
            "Training: batch 729 begins at 08:26:13.949891\n",
            "Training: batch 730 begins at 08:26:13.959053\n",
            " 731/1875 [==========>...................] - ETA: 8s - loss: 0.2583 - accuracy: 0.9019Training: batch 731 begins at 08:26:13.967847\n",
            "Training: batch 732 begins at 08:26:13.975782\n",
            "Training: batch 733 begins at 08:26:13.982842\n",
            "Training: batch 734 begins at 08:26:13.989425\n",
            "Training: batch 735 begins at 08:26:13.997110\n",
            "Training: batch 736 begins at 08:26:14.003854\n",
            "Training: batch 737 begins at 08:26:14.011904\n",
            " 738/1875 [==========>...................] - ETA: 8s - loss: 0.2581 - accuracy: 0.9019Training: batch 738 begins at 08:26:14.020222\n",
            "Training: batch 739 begins at 08:26:14.028537\n",
            "Training: batch 740 begins at 08:26:14.036492\n",
            "Training: batch 741 begins at 08:26:14.045414\n",
            "Training: batch 742 begins at 08:26:14.053636\n",
            "Training: batch 743 begins at 08:26:14.061651\n",
            " 744/1875 [==========>...................] - ETA: 8s - loss: 0.2579 - accuracy: 0.9019Training: batch 744 begins at 08:26:14.070342\n",
            "Training: batch 745 begins at 08:26:14.077392\n",
            "Training: batch 746 begins at 08:26:14.083632\n",
            "Training: batch 747 begins at 08:26:14.090775\n",
            "Training: batch 748 begins at 08:26:14.099230\n",
            "Training: batch 749 begins at 08:26:14.107358\n",
            "Training: batch 750 begins at 08:26:14.115214\n",
            " 751/1875 [===========>..................] - ETA: 8s - loss: 0.2569 - accuracy: 0.9025Training: batch 751 begins at 08:26:14.125530\n",
            "Training: batch 752 begins at 08:26:14.133581\n",
            "Training: batch 753 begins at 08:26:14.141670\n",
            "Training: batch 754 begins at 08:26:14.149525\n",
            "Training: batch 755 begins at 08:26:14.157360\n",
            "Training: batch 756 begins at 08:26:14.164299\n",
            "Training: batch 757 begins at 08:26:14.171540\n",
            " 758/1875 [===========>..................] - ETA: 8s - loss: 0.2560 - accuracy: 0.9028Training: batch 758 begins at 08:26:14.181804\n",
            "Training: batch 759 begins at 08:26:14.188504\n",
            "Training: batch 760 begins at 08:26:14.194092\n",
            "Training: batch 761 begins at 08:26:14.201004\n",
            "Training: batch 762 begins at 08:26:14.207624\n",
            "Training: batch 763 begins at 08:26:14.214464\n",
            "Training: batch 764 begins at 08:26:14.220993\n",
            "Training: batch 765 begins at 08:26:14.228361\n",
            " 766/1875 [===========>..................] - ETA: 8s - loss: 0.2567 - accuracy: 0.9027Training: batch 766 begins at 08:26:14.238379\n",
            "Training: batch 767 begins at 08:26:14.245091\n",
            "Training: batch 768 begins at 08:26:14.252620\n",
            "Training: batch 769 begins at 08:26:14.260091\n",
            "Training: batch 770 begins at 08:26:14.268267\n",
            "Training: batch 771 begins at 08:26:14.275957\n",
            "Training: batch 772 begins at 08:26:14.283514\n",
            " 773/1875 [===========>..................] - ETA: 8s - loss: 0.2569 - accuracy: 0.9026Training: batch 773 begins at 08:26:14.291296\n",
            "Training: batch 774 begins at 08:26:14.298867\n",
            "Training: batch 775 begins at 08:26:14.306218\n",
            "Training: batch 776 begins at 08:26:14.313764\n",
            "Training: batch 777 begins at 08:26:14.321905\n",
            "Training: batch 778 begins at 08:26:14.329593\n",
            "Training: batch 779 begins at 08:26:14.336938\n",
            " 780/1875 [===========>..................] - ETA: 8s - loss: 0.2568 - accuracy: 0.9028Training: batch 780 begins at 08:26:14.346754\n",
            "Training: batch 781 begins at 08:26:14.354574\n",
            "Training: batch 782 begins at 08:26:14.362450\n",
            "Training: batch 783 begins at 08:26:14.369091\n",
            "Training: batch 784 begins at 08:26:14.376362\n",
            "Training: batch 785 begins at 08:26:14.384480\n",
            "Training: batch 786 begins at 08:26:14.391509\n",
            " 787/1875 [===========>..................] - ETA: 8s - loss: 0.2572 - accuracy: 0.9028Training: batch 787 begins at 08:26:14.399781\n",
            "Training: batch 788 begins at 08:26:14.408016\n",
            "Training: batch 789 begins at 08:26:14.415176\n",
            "Training: batch 790 begins at 08:26:14.424372\n",
            "Training: batch 791 begins at 08:26:14.431704\n",
            "Training: batch 792 begins at 08:26:14.439392\n",
            "Training: batch 793 begins at 08:26:14.447711\n",
            " 794/1875 [===========>..................] - ETA: 8s - loss: 0.2575 - accuracy: 0.9027Training: batch 794 begins at 08:26:14.457487\n",
            "Training: batch 795 begins at 08:26:14.465599\n",
            "Training: batch 796 begins at 08:26:14.472796\n",
            "Training: batch 797 begins at 08:26:14.480292\n",
            "Training: batch 798 begins at 08:26:14.487324\n",
            "Training: batch 799 begins at 08:26:14.494626\n",
            "Training: batch 800 begins at 08:26:14.501320\n",
            " 801/1875 [===========>..................] - ETA: 8s - loss: 0.2574 - accuracy: 0.9026Training: batch 801 begins at 08:26:14.510894\n",
            "Training: batch 802 begins at 08:26:14.518936\n",
            "Training: batch 803 begins at 08:26:14.526441\n",
            "Training: batch 804 begins at 08:26:14.534125\n",
            "Training: batch 805 begins at 08:26:14.541814\n",
            "Training: batch 806 begins at 08:26:14.549333\n",
            " 807/1875 [===========>..................] - ETA: 8s - loss: 0.2577 - accuracy: 0.9025Training: batch 807 begins at 08:26:14.562195\n",
            "Training: batch 808 begins at 08:26:14.570039\n",
            "Training: batch 809 begins at 08:26:14.577393\n",
            "Training: batch 810 begins at 08:26:14.585295\n",
            "Training: batch 811 begins at 08:26:14.592936\n",
            "Training: batch 812 begins at 08:26:14.602674\n",
            " 813/1875 [============>.................] - ETA: 8s - loss: 0.2586 - accuracy: 0.9022Training: batch 813 begins at 08:26:14.612719\n",
            "Training: batch 814 begins at 08:26:14.620533\n",
            "Training: batch 815 begins at 08:26:14.628238\n",
            "Training: batch 816 begins at 08:26:14.635041\n",
            "Training: batch 817 begins at 08:26:14.641505\n",
            "Training: batch 818 begins at 08:26:14.649246\n",
            "Training: batch 819 begins at 08:26:14.655770\n",
            " 820/1875 [============>.................] - ETA: 8s - loss: 0.2585 - accuracy: 0.9021Training: batch 820 begins at 08:26:14.666751\n",
            "Training: batch 821 begins at 08:26:14.673861\n",
            "Training: batch 822 begins at 08:26:14.681354\n",
            "Training: batch 823 begins at 08:26:14.689180\n",
            "Training: batch 824 begins at 08:26:14.695543\n",
            "Training: batch 825 begins at 08:26:14.703096\n",
            "Training: batch 826 begins at 08:26:14.709308\n",
            " 827/1875 [============>.................] - ETA: 8s - loss: 0.2581 - accuracy: 0.9021Training: batch 827 begins at 08:26:14.719528\n",
            "Training: batch 828 begins at 08:26:14.727422\n",
            "Training: batch 829 begins at 08:26:14.734873\n",
            "Training: batch 830 begins at 08:26:14.742030\n",
            "Training: batch 831 begins at 08:26:14.749434\n",
            "Training: batch 832 begins at 08:26:14.757512\n",
            "Training: batch 833 begins at 08:26:14.765487\n",
            " 834/1875 [============>.................] - ETA: 7s - loss: 0.2579 - accuracy: 0.9022Training: batch 834 begins at 08:26:14.774442\n",
            "Training: batch 835 begins at 08:26:14.781731\n",
            "Training: batch 836 begins at 08:26:14.790197\n",
            "Training: batch 837 begins at 08:26:14.798402\n",
            "Training: batch 838 begins at 08:26:14.806169\n",
            "Training: batch 839 begins at 08:26:14.813444\n",
            "Training: batch 840 begins at 08:26:14.820621\n",
            " 841/1875 [============>.................] - ETA: 7s - loss: 0.2576 - accuracy: 0.9022Training: batch 841 begins at 08:26:14.830635\n",
            "Training: batch 842 begins at 08:26:14.836547\n",
            "Training: batch 843 begins at 08:26:14.848712\n",
            "Training: batch 844 begins at 08:26:14.856562\n",
            "Training: batch 845 begins at 08:26:14.868763\n",
            "Training: batch 846 begins at 08:26:14.873962\n",
            " 847/1875 [============>.................] - ETA: 7s - loss: 0.2574 - accuracy: 0.9022Training: batch 847 begins at 08:26:14.884178\n",
            "Training: batch 848 begins at 08:26:14.890322\n",
            "Training: batch 849 begins at 08:26:14.896613\n",
            "Training: batch 850 begins at 08:26:14.905804\n",
            "Training: batch 851 begins at 08:26:14.911782\n",
            "Training: batch 852 begins at 08:26:14.917353\n",
            "Training: batch 853 begins at 08:26:14.923024\n",
            "Training: batch 854 begins at 08:26:14.928888\n",
            " 855/1875 [============>.................] - ETA: 7s - loss: 0.2570 - accuracy: 0.9024Training: batch 855 begins at 08:26:14.939632\n",
            "Training: batch 856 begins at 08:26:14.946243\n",
            "Training: batch 857 begins at 08:26:14.954885\n",
            "Training: batch 858 begins at 08:26:14.960798\n",
            "Training: batch 859 begins at 08:26:14.970067\n",
            "Training: batch 860 begins at 08:26:14.976134\n",
            " 861/1875 [============>.................] - ETA: 7s - loss: 0.2575 - accuracy: 0.9022Training: batch 861 begins at 08:26:14.986192\n",
            "Training: batch 862 begins at 08:26:14.994427\n",
            "Training: batch 863 begins at 08:26:15.000623\n",
            "Training: batch 864 begins at 08:26:15.010398\n",
            "Training: batch 865 begins at 08:26:15.020302\n",
            "Training: batch 866 begins at 08:26:15.028284\n",
            " 867/1875 [============>.................] - ETA: 7s - loss: 0.2576 - accuracy: 0.9023Training: batch 867 begins at 08:26:15.040791\n",
            "Training: batch 868 begins at 08:26:15.047094\n",
            "Training: batch 869 begins at 08:26:15.058956\n",
            "Training: batch 870 begins at 08:26:15.069960\n",
            "Training: batch 871 begins at 08:26:15.076924\n",
            "Training: batch 872 begins at 08:26:15.087012\n",
            " 873/1875 [============>.................] - ETA: 7s - loss: 0.2578 - accuracy: 0.9022Training: batch 873 begins at 08:26:15.095390\n",
            "Training: batch 874 begins at 08:26:15.101899\n",
            "Training: batch 875 begins at 08:26:15.109263\n",
            "Training: batch 876 begins at 08:26:15.117615\n",
            "Training: batch 877 begins at 08:26:15.124504\n",
            "Training: batch 878 begins at 08:26:15.132534\n",
            "Training: batch 879 begins at 08:26:15.140500\n",
            " 880/1875 [=============>................] - ETA: 7s - loss: 0.2581 - accuracy: 0.9020Training: batch 880 begins at 08:26:15.149389\n",
            "Training: batch 881 begins at 08:26:15.155703\n",
            "Training: batch 882 begins at 08:26:15.161935\n",
            "Training: batch 883 begins at 08:26:15.167897\n",
            "Training: batch 884 begins at 08:26:15.173740\n",
            "Training: batch 885 begins at 08:26:15.179926\n",
            "Training: batch 886 begins at 08:26:15.189650\n",
            "Training: batch 887 begins at 08:26:15.195328\n",
            " 888/1875 [=============>................] - ETA: 7s - loss: 0.2580 - accuracy: 0.9020Training: batch 888 begins at 08:26:15.203094\n",
            "Training: batch 889 begins at 08:26:15.209260\n",
            "Training: batch 890 begins at 08:26:15.217506\n",
            "Training: batch 891 begins at 08:26:15.225347\n",
            "Training: batch 892 begins at 08:26:15.233129\n",
            "Training: batch 893 begins at 08:26:15.239783\n",
            "Training: batch 894 begins at 08:26:15.246994\n",
            " 895/1875 [=============>................] - ETA: 7s - loss: 0.2580 - accuracy: 0.9020Training: batch 895 begins at 08:26:15.255562\n",
            "Training: batch 896 begins at 08:26:15.263377\n",
            "Training: batch 897 begins at 08:26:15.269896\n",
            "Training: batch 898 begins at 08:26:15.277332\n",
            "Training: batch 899 begins at 08:26:15.284818\n",
            "Training: batch 900 begins at 08:26:15.292378\n",
            "Training: batch 901 begins at 08:26:15.299923\n",
            " 902/1875 [=============>................] - ETA: 7s - loss: 0.2575 - accuracy: 0.9022Training: batch 902 begins at 08:26:15.308755\n",
            "Training: batch 903 begins at 08:26:15.315986\n",
            "Training: batch 904 begins at 08:26:15.322429\n",
            "Training: batch 905 begins at 08:26:15.329765\n",
            "Training: batch 906 begins at 08:26:15.338967\n",
            "Training: batch 907 begins at 08:26:15.347702\n",
            "Training: batch 908 begins at 08:26:15.353330\n",
            " 909/1875 [=============>................] - ETA: 7s - loss: 0.2572 - accuracy: 0.9023Training: batch 909 begins at 08:26:15.363060\n",
            "Training: batch 910 begins at 08:26:15.372905\n",
            "Training: batch 911 begins at 08:26:15.378322\n",
            "Training: batch 912 begins at 08:26:15.385562\n",
            "Training: batch 913 begins at 08:26:15.393522\n",
            "Training: batch 914 begins at 08:26:15.401424\n",
            "Training: batch 915 begins at 08:26:15.407800\n",
            " 916/1875 [=============>................] - ETA: 7s - loss: 0.2571 - accuracy: 0.9023Training: batch 916 begins at 08:26:15.416278\n",
            "Training: batch 917 begins at 08:26:15.422933\n",
            "Training: batch 918 begins at 08:26:15.430337\n",
            "Training: batch 919 begins at 08:26:15.437650\n",
            "Training: batch 920 begins at 08:26:15.444740\n",
            "Training: batch 921 begins at 08:26:15.451662\n",
            "Training: batch 922 begins at 08:26:15.458870\n",
            " 923/1875 [=============>................] - ETA: 7s - loss: 0.2578 - accuracy: 0.9021Training: batch 923 begins at 08:26:15.467924\n",
            "Training: batch 924 begins at 08:26:15.474958\n",
            "Training: batch 925 begins at 08:26:15.482372\n",
            "Training: batch 926 begins at 08:26:15.489640\n",
            "Training: batch 927 begins at 08:26:15.497254\n",
            "Training: batch 928 begins at 08:26:15.504800\n",
            "Training: batch 929 begins at 08:26:15.512594\n",
            " 930/1875 [=============>................] - ETA: 7s - loss: 0.2582 - accuracy: 0.9019Training: batch 930 begins at 08:26:15.522355\n",
            "Training: batch 931 begins at 08:26:15.529963\n",
            "Training: batch 932 begins at 08:26:15.538338\n",
            "Training: batch 933 begins at 08:26:15.545099\n",
            "Training: batch 934 begins at 08:26:15.552050\n",
            "Training: batch 935 begins at 08:26:15.559506\n",
            "Training: batch 936 begins at 08:26:15.567104\n",
            " 937/1875 [=============>................] - ETA: 7s - loss: 0.2586 - accuracy: 0.9017Training: batch 937 begins at 08:26:15.575051\n",
            "Training: batch 938 begins at 08:26:15.582241\n",
            "Training: batch 939 begins at 08:26:15.589007\n",
            "Training: batch 940 begins at 08:26:15.596296\n",
            "Training: batch 941 begins at 08:26:15.603025\n",
            "Training: batch 942 begins at 08:26:15.609005\n",
            "Training: batch 943 begins at 08:26:15.616106\n",
            "Training: batch 944 begins at 08:26:15.623399\n",
            " 945/1875 [==============>...............] - ETA: 7s - loss: 0.2587 - accuracy: 0.9016Training: batch 945 begins at 08:26:15.631255\n",
            "Training: batch 946 begins at 08:26:15.638396\n",
            "Training: batch 947 begins at 08:26:15.645702\n",
            "Training: batch 948 begins at 08:26:15.653083\n",
            "Training: batch 949 begins at 08:26:15.659589\n",
            "Training: batch 950 begins at 08:26:15.666870\n",
            "Training: batch 951 begins at 08:26:15.674454\n",
            " 952/1875 [==============>...............] - ETA: 7s - loss: 0.2586 - accuracy: 0.9016Training: batch 952 begins at 08:26:15.683356\n",
            "Training: batch 953 begins at 08:26:15.690526\n",
            "Training: batch 954 begins at 08:26:15.696753\n",
            "Training: batch 955 begins at 08:26:15.703003\n",
            "Training: batch 956 begins at 08:26:15.710292\n",
            "Training: batch 957 begins at 08:26:15.717576\n",
            "Training: batch 958 begins at 08:26:15.724899\n",
            " 959/1875 [==============>...............] - ETA: 7s - loss: 0.2587 - accuracy: 0.9016Training: batch 959 begins at 08:26:15.733992\n",
            "Training: batch 960 begins at 08:26:15.741579\n",
            "Training: batch 961 begins at 08:26:15.749455\n",
            "Training: batch 962 begins at 08:26:15.757013\n",
            "Training: batch 963 begins at 08:26:15.764014\n",
            "Training: batch 964 begins at 08:26:15.771658\n",
            "Training: batch 965 begins at 08:26:15.779282\n",
            " 966/1875 [==============>...............] - ETA: 6s - loss: 0.2589 - accuracy: 0.9015Training: batch 966 begins at 08:26:15.787747\n",
            "Training: batch 967 begins at 08:26:15.794859\n",
            "Training: batch 968 begins at 08:26:15.801865\n",
            "Training: batch 969 begins at 08:26:15.808757\n",
            "Training: batch 970 begins at 08:26:15.816742\n",
            "Training: batch 971 begins at 08:26:15.823507\n",
            "Training: batch 972 begins at 08:26:15.830648\n",
            " 973/1875 [==============>...............] - ETA: 6s - loss: 0.2589 - accuracy: 0.9015Training: batch 973 begins at 08:26:15.839809\n",
            "Training: batch 974 begins at 08:26:15.845766\n",
            "Training: batch 975 begins at 08:26:15.852757\n",
            "Training: batch 976 begins at 08:26:15.860560\n",
            "Training: batch 977 begins at 08:26:15.866114\n",
            "Training: batch 978 begins at 08:26:15.875581\n",
            "Training: batch 979 begins at 08:26:15.884711\n",
            " 980/1875 [==============>...............] - ETA: 6s - loss: 0.2592 - accuracy: 0.9013Training: batch 980 begins at 08:26:15.893932\n",
            "Training: batch 981 begins at 08:26:15.900139\n",
            "Training: batch 982 begins at 08:26:15.908242\n",
            "Training: batch 983 begins at 08:26:15.915957\n",
            "Training: batch 984 begins at 08:26:15.922660\n",
            "Training: batch 985 begins at 08:26:15.929622\n",
            "Training: batch 986 begins at 08:26:15.936986\n",
            " 987/1875 [==============>...............] - ETA: 6s - loss: 0.2594 - accuracy: 0.9013Training: batch 987 begins at 08:26:15.945672\n",
            "Training: batch 988 begins at 08:26:15.951494\n",
            "Training: batch 989 begins at 08:26:15.958700\n",
            "Training: batch 990 begins at 08:26:15.965725\n",
            "Training: batch 991 begins at 08:26:15.972430\n",
            "Training: batch 992 begins at 08:26:15.979612\n",
            "Training: batch 993 begins at 08:26:15.987413\n",
            " 994/1875 [==============>...............] - ETA: 6s - loss: 0.2596 - accuracy: 0.9013Training: batch 994 begins at 08:26:15.996768\n",
            "Training: batch 995 begins at 08:26:16.003307\n",
            "Training: batch 996 begins at 08:26:16.011398\n",
            "Training: batch 997 begins at 08:26:16.020521\n",
            "Training: batch 998 begins at 08:26:16.027297\n",
            "Training: batch 999 begins at 08:26:16.034663\n",
            "Training: batch 1000 begins at 08:26:16.042102\n",
            "1001/1875 [===============>..............] - ETA: 6s - loss: 0.2596 - accuracy: 0.9012Training: batch 1001 begins at 08:26:16.050250\n",
            "Training: batch 1002 begins at 08:26:16.057805\n",
            "Training: batch 1003 begins at 08:26:16.066779\n",
            "Training: batch 1004 begins at 08:26:16.073844\n",
            "Training: batch 1005 begins at 08:26:16.082025\n",
            "Training: batch 1006 begins at 08:26:16.089368\n",
            "Training: batch 1007 begins at 08:26:16.097338\n",
            "1008/1875 [===============>..............] - ETA: 6s - loss: 0.2600 - accuracy: 0.9011Training: batch 1008 begins at 08:26:16.106527\n",
            "Training: batch 1009 begins at 08:26:16.115306\n",
            "Training: batch 1010 begins at 08:26:16.122042\n",
            "Training: batch 1011 begins at 08:26:16.128361\n",
            "Training: batch 1012 begins at 08:26:16.136547\n",
            "Training: batch 1013 begins at 08:26:16.143979\n",
            "Training: batch 1014 begins at 08:26:16.151926\n",
            "1015/1875 [===============>..............] - ETA: 6s - loss: 0.2598 - accuracy: 0.9012Training: batch 1015 begins at 08:26:16.161735\n",
            "Training: batch 1016 begins at 08:26:16.169182\n",
            "Training: batch 1017 begins at 08:26:16.176745\n",
            "Training: batch 1018 begins at 08:26:16.184311\n",
            "Training: batch 1019 begins at 08:26:16.191365\n",
            "Training: batch 1020 begins at 08:26:16.198828\n",
            "1021/1875 [===============>..............] - ETA: 6s - loss: 0.2595 - accuracy: 0.9014Training: batch 1021 begins at 08:26:16.217730\n",
            "Training: batch 1022 begins at 08:26:16.228681\n",
            "Training: batch 1023 begins at 08:26:16.241696\n",
            "Training: batch 1024 begins at 08:26:16.253407\n",
            "Training: batch 1025 begins at 08:26:16.262505\n",
            "1026/1875 [===============>..............] - ETA: 6s - loss: 0.2594 - accuracy: 0.9014Training: batch 1026 begins at 08:26:16.275380\n",
            "Training: batch 1027 begins at 08:26:16.282725\n",
            "Training: batch 1028 begins at 08:26:16.288882\n",
            "Training: batch 1029 begins at 08:26:16.294613\n",
            "Training: batch 1030 begins at 08:26:16.302003\n",
            "Training: batch 1031 begins at 08:26:16.312706\n",
            "Training: batch 1032 begins at 08:26:16.321129\n",
            "1033/1875 [===============>..............] - ETA: 6s - loss: 0.2591 - accuracy: 0.9015Training: batch 1033 begins at 08:26:16.334826\n",
            "Training: batch 1034 begins at 08:26:16.343615\n",
            "Training: batch 1035 begins at 08:26:16.354705\n",
            "Training: batch 1036 begins at 08:26:16.361757\n",
            "Training: batch 1037 begins at 08:26:16.373060\n",
            "1038/1875 [===============>..............] - ETA: 6s - loss: 0.2591 - accuracy: 0.9014Training: batch 1038 begins at 08:26:16.387059\n",
            "Training: batch 1039 begins at 08:26:16.394086\n",
            "Training: batch 1040 begins at 08:26:16.408711\n",
            "Training: batch 1041 begins at 08:26:16.420233\n",
            "Training: batch 1042 begins at 08:26:16.431093\n",
            "1043/1875 [===============>..............] - ETA: 6s - loss: 0.2592 - accuracy: 0.9013Training: batch 1043 begins at 08:26:16.437814\n",
            "Training: batch 1044 begins at 08:26:16.446437\n",
            "Training: batch 1045 begins at 08:26:16.458421\n",
            "Training: batch 1046 begins at 08:26:16.464833\n",
            "Training: batch 1047 begins at 08:26:16.472349\n",
            "Training: batch 1048 begins at 08:26:16.480090\n",
            "1049/1875 [===============>..............] - ETA: 6s - loss: 0.2589 - accuracy: 0.9013Training: batch 1049 begins at 08:26:16.489036\n",
            "Training: batch 1050 begins at 08:26:16.499114\n",
            "Training: batch 1051 begins at 08:26:16.505846\n",
            "Training: batch 1052 begins at 08:26:16.516017\n",
            "Training: batch 1053 begins at 08:26:16.523900\n",
            "Training: batch 1054 begins at 08:26:16.532382\n",
            "1055/1875 [===============>..............] - ETA: 6s - loss: 0.2594 - accuracy: 0.9012Training: batch 1055 begins at 08:26:16.542129\n",
            "Training: batch 1056 begins at 08:26:16.549620\n",
            "Training: batch 1057 begins at 08:26:16.557294\n",
            "Training: batch 1058 begins at 08:26:16.564044\n",
            "Training: batch 1059 begins at 08:26:16.570462\n",
            "Training: batch 1060 begins at 08:26:16.576973\n",
            "Training: batch 1061 begins at 08:26:16.585445\n",
            "1062/1875 [===============>..............] - ETA: 6s - loss: 0.2595 - accuracy: 0.9013Training: batch 1062 begins at 08:26:16.597893\n",
            "Training: batch 1063 begins at 08:26:16.605037\n",
            "Training: batch 1064 begins at 08:26:16.613773\n",
            "Training: batch 1065 begins at 08:26:16.621342\n",
            "Training: batch 1066 begins at 08:26:16.629612\n",
            "Training: batch 1067 begins at 08:26:16.636895\n",
            "1068/1875 [================>.............] - ETA: 6s - loss: 0.2596 - accuracy: 0.9012Training: batch 1068 begins at 08:26:16.647665\n",
            "Training: batch 1069 begins at 08:26:16.656009\n",
            "Training: batch 1070 begins at 08:26:16.663622\n",
            "Training: batch 1071 begins at 08:26:16.670919\n",
            "Training: batch 1072 begins at 08:26:16.679485\n",
            "Training: batch 1073 begins at 08:26:16.687846\n",
            "Training: batch 1074 begins at 08:26:16.695512\n",
            "1075/1875 [================>.............] - ETA: 6s - loss: 0.2596 - accuracy: 0.9013Training: batch 1075 begins at 08:26:16.705274\n",
            "Training: batch 1076 begins at 08:26:16.712300\n",
            "Training: batch 1077 begins at 08:26:16.719601\n",
            "Training: batch 1078 begins at 08:26:16.726596\n",
            "Training: batch 1079 begins at 08:26:16.733004\n",
            "Training: batch 1080 begins at 08:26:16.740669\n",
            "Training: batch 1081 begins at 08:26:16.748259\n",
            "1082/1875 [================>.............] - ETA: 6s - loss: 0.2596 - accuracy: 0.9012Training: batch 1082 begins at 08:26:16.757066\n",
            "Training: batch 1083 begins at 08:26:16.765195\n",
            "Training: batch 1084 begins at 08:26:16.773449\n",
            "Training: batch 1085 begins at 08:26:16.786979\n",
            "Training: batch 1086 begins at 08:26:16.802473\n",
            "1087/1875 [================>.............] - ETA: 6s - loss: 0.2594 - accuracy: 0.9012Training: batch 1087 begins at 08:26:16.812636\n",
            "Training: batch 1088 begins at 08:26:16.821410\n",
            "Training: batch 1089 begins at 08:26:16.829857\n",
            "Training: batch 1090 begins at 08:26:16.837538\n",
            "Training: batch 1091 begins at 08:26:16.845635\n",
            "Training: batch 1092 begins at 08:26:16.854624\n",
            "1093/1875 [================>.............] - ETA: 6s - loss: 0.2595 - accuracy: 0.9011Training: batch 1093 begins at 08:26:16.863745\n",
            "Training: batch 1094 begins at 08:26:16.872013\n",
            "Training: batch 1095 begins at 08:26:16.878962\n",
            "Training: batch 1096 begins at 08:26:16.887170\n",
            "Training: batch 1097 begins at 08:26:16.895016\n",
            "Training: batch 1098 begins at 08:26:16.902835\n",
            "1099/1875 [================>.............] - ETA: 6s - loss: 0.2595 - accuracy: 0.9011Training: batch 1099 begins at 08:26:16.919295\n",
            "Training: batch 1100 begins at 08:26:16.929043\n",
            "Training: batch 1101 begins at 08:26:16.937779\n",
            "Training: batch 1102 begins at 08:26:16.945064\n",
            "Training: batch 1103 begins at 08:26:16.952773\n",
            "Training: batch 1104 begins at 08:26:16.961033\n",
            "1105/1875 [================>.............] - ETA: 5s - loss: 0.2591 - accuracy: 0.9012Training: batch 1105 begins at 08:26:16.969920\n",
            "Training: batch 1106 begins at 08:26:16.977511\n",
            "Training: batch 1107 begins at 08:26:16.984070\n",
            "Training: batch 1108 begins at 08:26:16.990555\n",
            "Training: batch 1109 begins at 08:26:16.998875\n",
            "Training: batch 1110 begins at 08:26:17.006953\n",
            "Training: batch 1111 begins at 08:26:17.015350\n",
            "1112/1875 [================>.............] - ETA: 5s - loss: 0.2591 - accuracy: 0.9012Training: batch 1112 begins at 08:26:17.024858\n",
            "Training: batch 1113 begins at 08:26:17.032287\n",
            "Training: batch 1114 begins at 08:26:17.040289\n",
            "Training: batch 1115 begins at 08:26:17.048536\n",
            "Training: batch 1116 begins at 08:26:17.057440\n",
            "Training: batch 1117 begins at 08:26:17.066175\n",
            "1118/1875 [================>.............] - ETA: 5s - loss: 0.2585 - accuracy: 0.9015Training: batch 1118 begins at 08:26:17.075985\n",
            "Training: batch 1119 begins at 08:26:17.084038\n",
            "Training: batch 1120 begins at 08:26:17.092095\n",
            "Training: batch 1121 begins at 08:26:17.100922\n",
            "Training: batch 1122 begins at 08:26:17.107722\n",
            "Training: batch 1123 begins at 08:26:17.114074\n",
            "Training: batch 1124 begins at 08:26:17.121393\n",
            "1125/1875 [=================>............] - ETA: 5s - loss: 0.2594 - accuracy: 0.9013Training: batch 1125 begins at 08:26:17.130310\n",
            "Training: batch 1126 begins at 08:26:17.138304\n",
            "Training: batch 1127 begins at 08:26:17.147366\n",
            "Training: batch 1128 begins at 08:26:17.153687\n",
            "Training: batch 1129 begins at 08:26:17.161704\n",
            "Training: batch 1130 begins at 08:26:17.170168\n",
            "Training: batch 1131 begins at 08:26:17.178370\n",
            "1132/1875 [=================>............] - ETA: 5s - loss: 0.2604 - accuracy: 0.9011Training: batch 1132 begins at 08:26:17.186516\n",
            "Training: batch 1133 begins at 08:26:17.193626\n",
            "Training: batch 1134 begins at 08:26:17.204862\n",
            "Training: batch 1135 begins at 08:26:17.217371\n",
            "Training: batch 1136 begins at 08:26:17.225018\n",
            "Training: batch 1137 begins at 08:26:17.232940\n",
            "1138/1875 [=================>............] - ETA: 5s - loss: 0.2608 - accuracy: 0.9011Training: batch 1138 begins at 08:26:17.242847\n",
            "Training: batch 1139 begins at 08:26:17.249951\n",
            "Training: batch 1140 begins at 08:26:17.256348\n",
            "Training: batch 1141 begins at 08:26:17.262361\n",
            "Training: batch 1142 begins at 08:26:17.268581\n",
            "Training: batch 1143 begins at 08:26:17.275252\n",
            "Training: batch 1144 begins at 08:26:17.281824\n",
            "Training: batch 1145 begins at 08:26:17.288242\n",
            "1146/1875 [=================>............] - ETA: 5s - loss: 0.2609 - accuracy: 0.9009Training: batch 1146 begins at 08:26:17.296466\n",
            "Training: batch 1147 begins at 08:26:17.303473\n",
            "Training: batch 1148 begins at 08:26:17.312197\n",
            "Training: batch 1149 begins at 08:26:17.319952\n",
            "Training: batch 1150 begins at 08:26:17.328379\n",
            "Training: batch 1151 begins at 08:26:17.336915\n",
            "1152/1875 [=================>............] - ETA: 5s - loss: 0.2610 - accuracy: 0.9009Training: batch 1152 begins at 08:26:17.347694\n",
            "Training: batch 1153 begins at 08:26:17.355091\n",
            "Training: batch 1154 begins at 08:26:17.362989\n",
            "Training: batch 1155 begins at 08:26:17.372053\n",
            "Training: batch 1156 begins at 08:26:17.381875\n",
            "Training: batch 1157 begins at 08:26:17.390839\n",
            "1158/1875 [=================>............] - ETA: 5s - loss: 0.2611 - accuracy: 0.9007Training: batch 1158 begins at 08:26:17.399163\n",
            "Training: batch 1159 begins at 08:26:17.408178\n",
            "Training: batch 1160 begins at 08:26:17.426450\n",
            "Training: batch 1161 begins at 08:26:17.439736\n",
            "1162/1875 [=================>............] - ETA: 5s - loss: 0.2613 - accuracy: 0.9006Training: batch 1162 begins at 08:26:17.455609\n",
            "Training: batch 1163 begins at 08:26:17.470399\n",
            "Training: batch 1164 begins at 08:26:17.478135\n",
            "Training: batch 1165 begins at 08:26:17.484873\n",
            "Training: batch 1166 begins at 08:26:17.494282\n",
            "Training: batch 1167 begins at 08:26:17.501106\n",
            "1168/1875 [=================>............] - ETA: 5s - loss: 0.2617 - accuracy: 0.9004Training: batch 1168 begins at 08:26:17.512164\n",
            "Training: batch 1169 begins at 08:26:17.519008\n",
            "Training: batch 1170 begins at 08:26:17.529426\n",
            "Training: batch 1171 begins at 08:26:17.539771\n",
            "Training: batch 1172 begins at 08:26:17.547784\n",
            "1173/1875 [=================>............] - ETA: 5s - loss: 0.2621 - accuracy: 0.9003Training: batch 1173 begins at 08:26:17.561771\n",
            "Training: batch 1174 begins at 08:26:17.574299\n",
            "Training: batch 1175 begins at 08:26:17.584985\n",
            "Training: batch 1176 begins at 08:26:17.594899\n",
            "Training: batch 1177 begins at 08:26:17.604878\n",
            "1178/1875 [=================>............] - ETA: 5s - loss: 0.2623 - accuracy: 0.9002Training: batch 1178 begins at 08:26:17.620941\n",
            "Training: batch 1179 begins at 08:26:17.631449\n",
            "Training: batch 1180 begins at 08:26:17.641273\n",
            "Training: batch 1181 begins at 08:26:17.649656\n",
            "Training: batch 1182 begins at 08:26:17.658789\n",
            "Training: batch 1183 begins at 08:26:17.665594\n",
            "1184/1875 [=================>............] - ETA: 5s - loss: 0.2623 - accuracy: 0.9001Training: batch 1184 begins at 08:26:17.675938\n",
            "Training: batch 1185 begins at 08:26:17.684636\n",
            "Training: batch 1186 begins at 08:26:17.692677\n",
            "Training: batch 1187 begins at 08:26:17.700886\n",
            "Training: batch 1188 begins at 08:26:17.708189\n",
            "Training: batch 1189 begins at 08:26:17.716645\n",
            "1190/1875 [==================>...........] - ETA: 5s - loss: 0.2622 - accuracy: 0.9002Training: batch 1190 begins at 08:26:17.727826\n",
            "Training: batch 1191 begins at 08:26:17.737874\n",
            "Training: batch 1192 begins at 08:26:17.745573\n",
            "Training: batch 1193 begins at 08:26:17.754431\n",
            "Training: batch 1194 begins at 08:26:17.764746\n",
            "Training: batch 1195 begins at 08:26:17.774558\n",
            "1196/1875 [==================>...........] - ETA: 5s - loss: 0.2623 - accuracy: 0.9002Training: batch 1196 begins at 08:26:17.787318\n",
            "Training: batch 1197 begins at 08:26:17.798868\n",
            "Training: batch 1198 begins at 08:26:17.812216\n",
            "Training: batch 1199 begins at 08:26:17.819725\n",
            "Training: batch 1200 begins at 08:26:17.826317\n",
            "1201/1875 [==================>...........] - ETA: 5s - loss: 0.2628 - accuracy: 0.9000Training: batch 1201 begins at 08:26:17.839327\n",
            "Training: batch 1202 begins at 08:26:17.848995\n",
            "Training: batch 1203 begins at 08:26:17.859771\n",
            "Training: batch 1204 begins at 08:26:17.869783\n",
            "Training: batch 1205 begins at 08:26:17.881703\n",
            "1206/1875 [==================>...........] - ETA: 5s - loss: 0.2627 - accuracy: 0.9000Training: batch 1206 begins at 08:26:17.892400\n",
            "Training: batch 1207 begins at 08:26:17.901355\n",
            "Training: batch 1208 begins at 08:26:17.909829\n",
            "Training: batch 1209 begins at 08:26:17.916423\n",
            "Training: batch 1210 begins at 08:26:17.922702\n",
            "Training: batch 1211 begins at 08:26:17.929933\n",
            "1212/1875 [==================>...........] - ETA: 5s - loss: 0.2627 - accuracy: 0.9000Training: batch 1212 begins at 08:26:17.945924\n",
            "Training: batch 1213 begins at 08:26:17.958088\n",
            "Training: batch 1214 begins at 08:26:17.966133\n",
            "Training: batch 1215 begins at 08:26:17.973937\n",
            "Training: batch 1216 begins at 08:26:17.981485\n",
            "Training: batch 1217 begins at 08:26:17.989032\n",
            "1218/1875 [==================>...........] - ETA: 5s - loss: 0.2628 - accuracy: 0.9000Training: batch 1218 begins at 08:26:17.999331\n",
            "Training: batch 1219 begins at 08:26:18.006260\n",
            "Training: batch 1220 begins at 08:26:18.014036\n",
            "Training: batch 1221 begins at 08:26:18.020900\n",
            "Training: batch 1222 begins at 08:26:18.028953\n",
            "Training: batch 1223 begins at 08:26:18.035826\n",
            "Training: batch 1224 begins at 08:26:18.045558\n",
            "1225/1875 [==================>...........] - ETA: 5s - loss: 0.2631 - accuracy: 0.8999Training: batch 1225 begins at 08:26:18.056067\n",
            "Training: batch 1226 begins at 08:26:18.064069\n",
            "Training: batch 1227 begins at 08:26:18.072599\n",
            "Training: batch 1228 begins at 08:26:18.079855\n",
            "Training: batch 1229 begins at 08:26:18.087906\n",
            "Training: batch 1230 begins at 08:26:18.096250\n",
            "1231/1875 [==================>...........] - ETA: 5s - loss: 0.2629 - accuracy: 0.9000Training: batch 1231 begins at 08:26:18.106827\n",
            "Training: batch 1232 begins at 08:26:18.113818\n",
            "Training: batch 1233 begins at 08:26:18.120495\n",
            "Training: batch 1234 begins at 08:26:18.126964\n",
            "Training: batch 1235 begins at 08:26:18.134434\n",
            "Training: batch 1236 begins at 08:26:18.141133\n",
            "Training: batch 1237 begins at 08:26:18.148593\n",
            "1238/1875 [==================>...........] - ETA: 5s - loss: 0.2627 - accuracy: 0.9000Training: batch 1238 begins at 08:26:18.156724\n",
            "Training: batch 1239 begins at 08:26:18.164340\n",
            "Training: batch 1240 begins at 08:26:18.172209\n",
            "Training: batch 1241 begins at 08:26:18.178987\n",
            "Training: batch 1242 begins at 08:26:18.186271\n",
            "Training: batch 1243 begins at 08:26:18.193865\n",
            "Training: batch 1244 begins at 08:26:18.201708\n",
            "1245/1875 [==================>...........] - ETA: 4s - loss: 0.2629 - accuracy: 0.8999Training: batch 1245 begins at 08:26:18.210308\n",
            "Training: batch 1246 begins at 08:26:18.217779\n",
            "Training: batch 1247 begins at 08:26:18.226195\n",
            "Training: batch 1248 begins at 08:26:18.233123\n",
            "Training: batch 1249 begins at 08:26:18.240440\n",
            "Training: batch 1250 begins at 08:26:18.246589\n",
            "Training: batch 1251 begins at 08:26:18.256746\n",
            "1252/1875 [===================>..........] - ETA: 4s - loss: 0.2628 - accuracy: 0.8999Training: batch 1252 begins at 08:26:18.266848\n",
            "Training: batch 1253 begins at 08:26:18.274684\n",
            "Training: batch 1254 begins at 08:26:18.281044\n",
            "Training: batch 1255 begins at 08:26:18.287454\n",
            "Training: batch 1256 begins at 08:26:18.294733\n",
            "Training: batch 1257 begins at 08:26:18.302498\n",
            "Training: batch 1258 begins at 08:26:18.310481\n",
            "1259/1875 [===================>..........] - ETA: 4s - loss: 0.2630 - accuracy: 0.8998Training: batch 1259 begins at 08:26:18.319063\n",
            "Training: batch 1260 begins at 08:26:18.325898\n",
            "Training: batch 1261 begins at 08:26:18.332409\n",
            "Training: batch 1262 begins at 08:26:18.340116\n",
            "Training: batch 1263 begins at 08:26:18.346920\n",
            "Training: batch 1264 begins at 08:26:18.354566\n",
            "Training: batch 1265 begins at 08:26:18.362230\n",
            "1266/1875 [===================>..........] - ETA: 4s - loss: 0.2626 - accuracy: 0.8999Training: batch 1266 begins at 08:26:18.372121\n",
            "Training: batch 1267 begins at 08:26:18.380399\n",
            "Training: batch 1268 begins at 08:26:18.386939\n",
            "Training: batch 1269 begins at 08:26:18.394565\n",
            "Training: batch 1270 begins at 08:26:18.402300\n",
            "Training: batch 1271 begins at 08:26:18.409830\n",
            "Training: batch 1272 begins at 08:26:18.417512\n",
            "1273/1875 [===================>..........] - ETA: 4s - loss: 0.2625 - accuracy: 0.8999Training: batch 1273 begins at 08:26:18.427428\n",
            "Training: batch 1274 begins at 08:26:18.433938\n",
            "Training: batch 1275 begins at 08:26:18.440230\n",
            "Training: batch 1276 begins at 08:26:18.447114\n",
            "Training: batch 1277 begins at 08:26:18.454546\n",
            "Training: batch 1278 begins at 08:26:18.462052\n",
            "Training: batch 1279 begins at 08:26:18.469803\n",
            "1280/1875 [===================>..........] - ETA: 4s - loss: 0.2622 - accuracy: 0.9000Training: batch 1280 begins at 08:26:18.479159\n",
            "Training: batch 1281 begins at 08:26:18.485751\n",
            "Training: batch 1282 begins at 08:26:18.491721\n",
            "Training: batch 1283 begins at 08:26:18.498946\n",
            "Training: batch 1284 begins at 08:26:18.508018\n",
            "Training: batch 1285 begins at 08:26:18.514001\n",
            "Training: batch 1286 begins at 08:26:18.521098\n",
            "1287/1875 [===================>..........] - ETA: 4s - loss: 0.2621 - accuracy: 0.9000Training: batch 1287 begins at 08:26:18.536743\n",
            "Training: batch 1288 begins at 08:26:18.543012\n",
            "Training: batch 1289 begins at 08:26:18.548947\n",
            "Training: batch 1290 begins at 08:26:18.554631\n",
            "Training: batch 1291 begins at 08:26:18.560381\n",
            "Training: batch 1292 begins at 08:26:18.566064\n",
            "Training: batch 1293 begins at 08:26:18.571652\n",
            "Training: batch 1294 begins at 08:26:18.579708\n",
            "1295/1875 [===================>..........] - ETA: 4s - loss: 0.2617 - accuracy: 0.9000Training: batch 1295 begins at 08:26:18.591493\n",
            "Training: batch 1296 begins at 08:26:18.597367\n",
            "Training: batch 1297 begins at 08:26:18.607836\n",
            "Training: batch 1298 begins at 08:26:18.614157\n",
            "Training: batch 1299 begins at 08:26:18.623411\n",
            "Training: batch 1300 begins at 08:26:18.633351\n",
            "1301/1875 [===================>..........] - ETA: 4s - loss: 0.2623 - accuracy: 0.8999Training: batch 1301 begins at 08:26:18.645541\n",
            "Training: batch 1302 begins at 08:26:18.651617\n",
            "Training: batch 1303 begins at 08:26:18.659240\n",
            "Training: batch 1304 begins at 08:26:18.667420\n",
            "Training: batch 1305 begins at 08:26:18.675474\n",
            "Training: batch 1306 begins at 08:26:18.681534\n",
            "Training: batch 1307 begins at 08:26:18.690546\n",
            "1308/1875 [===================>..........] - ETA: 4s - loss: 0.2620 - accuracy: 0.8999Training: batch 1308 begins at 08:26:18.701052\n",
            "Training: batch 1309 begins at 08:26:18.707036\n",
            "Training: batch 1310 begins at 08:26:18.716489\n",
            "Training: batch 1311 begins at 08:26:18.722614\n",
            "Training: batch 1312 begins at 08:26:18.735137\n",
            "Training: batch 1313 begins at 08:26:18.741727\n",
            "1314/1875 [====================>.........] - ETA: 4s - loss: 0.2618 - accuracy: 0.9001Training: batch 1314 begins at 08:26:18.751763\n",
            "Training: batch 1315 begins at 08:26:18.758900\n",
            "Training: batch 1316 begins at 08:26:18.766647\n",
            "Training: batch 1317 begins at 08:26:18.774184\n",
            "Training: batch 1318 begins at 08:26:18.781930\n",
            "Training: batch 1319 begins at 08:26:18.791360\n",
            "Training: batch 1320 begins at 08:26:18.799477\n",
            "1321/1875 [====================>.........] - ETA: 4s - loss: 0.2615 - accuracy: 0.9002Training: batch 1321 begins at 08:26:18.807622\n",
            "Training: batch 1322 begins at 08:26:18.814224\n",
            "Training: batch 1323 begins at 08:26:18.827917\n",
            "Training: batch 1324 begins at 08:26:18.837204\n",
            "Training: batch 1325 begins at 08:26:18.843919\n",
            "Training: batch 1326 begins at 08:26:18.850663\n",
            "1327/1875 [====================>.........] - ETA: 4s - loss: 0.2613 - accuracy: 0.9003Training: batch 1327 begins at 08:26:18.859190\n",
            "Training: batch 1328 begins at 08:26:18.866390\n",
            "Training: batch 1329 begins at 08:26:18.877572\n",
            "Training: batch 1330 begins at 08:26:18.884846\n",
            "Training: batch 1331 begins at 08:26:18.893371\n",
            "Training: batch 1332 begins at 08:26:18.900000\n",
            "1333/1875 [====================>.........] - ETA: 4s - loss: 0.2616 - accuracy: 0.9002Training: batch 1333 begins at 08:26:18.910286\n",
            "Training: batch 1334 begins at 08:26:18.918033\n",
            "Training: batch 1335 begins at 08:26:18.924186\n",
            "Training: batch 1336 begins at 08:26:18.931526\n",
            "Training: batch 1337 begins at 08:26:18.939217\n",
            "Training: batch 1338 begins at 08:26:18.954472\n",
            "1339/1875 [====================>.........] - ETA: 4s - loss: 0.2615 - accuracy: 0.9002Training: batch 1339 begins at 08:26:18.963309\n",
            "Training: batch 1340 begins at 08:26:18.970918\n",
            "Training: batch 1341 begins at 08:26:18.978306\n",
            "Training: batch 1342 begins at 08:26:18.985927\n",
            "Training: batch 1343 begins at 08:26:18.994436\n",
            "Training: batch 1344 begins at 08:26:19.002116\n",
            "1345/1875 [====================>.........] - ETA: 4s - loss: 0.2612 - accuracy: 0.9003Training: batch 1345 begins at 08:26:19.014252\n",
            "Training: batch 1346 begins at 08:26:19.027513\n",
            "Training: batch 1347 begins at 08:26:19.035838\n",
            "Training: batch 1348 begins at 08:26:19.044340\n",
            "Training: batch 1349 begins at 08:26:19.053765\n",
            "1350/1875 [====================>.........] - ETA: 4s - loss: 0.2614 - accuracy: 0.9002Training: batch 1350 begins at 08:26:19.064775\n",
            "Training: batch 1351 begins at 08:26:19.075004\n",
            "Training: batch 1352 begins at 08:26:19.086098\n",
            "Training: batch 1353 begins at 08:26:19.093895\n",
            "Training: batch 1354 begins at 08:26:19.102218\n",
            "Training: batch 1355 begins at 08:26:19.110767\n",
            "1356/1875 [====================>.........] - ETA: 4s - loss: 0.2612 - accuracy: 0.9003Training: batch 1356 begins at 08:26:19.121408\n",
            "Training: batch 1357 begins at 08:26:19.130622\n",
            "Training: batch 1358 begins at 08:26:19.137140\n",
            "Training: batch 1359 begins at 08:26:19.143567\n",
            "Training: batch 1360 begins at 08:26:19.153069\n",
            "Training: batch 1361 begins at 08:26:19.162452\n",
            "1362/1875 [====================>.........] - ETA: 4s - loss: 0.2615 - accuracy: 0.9003Training: batch 1362 begins at 08:26:19.176539\n",
            "Training: batch 1363 begins at 08:26:19.184492\n",
            "Training: batch 1364 begins at 08:26:19.192354\n",
            "Training: batch 1365 begins at 08:26:19.201865\n",
            "Training: batch 1366 begins at 08:26:19.208365\n",
            "Training: batch 1367 begins at 08:26:19.218105\n",
            "1368/1875 [====================>.........] - ETA: 4s - loss: 0.2612 - accuracy: 0.9003Training: batch 1368 begins at 08:26:19.229555\n",
            "Training: batch 1369 begins at 08:26:19.238435\n",
            "Training: batch 1370 begins at 08:26:19.245921\n",
            "Training: batch 1371 begins at 08:26:19.254082\n",
            "Training: batch 1372 begins at 08:26:19.261460\n",
            "Training: batch 1373 begins at 08:26:19.269004\n",
            "1374/1875 [====================>.........] - ETA: 3s - loss: 0.2611 - accuracy: 0.9004Training: batch 1374 begins at 08:26:19.280664\n",
            "Training: batch 1375 begins at 08:26:19.290663\n",
            "Training: batch 1376 begins at 08:26:19.297763\n",
            "Training: batch 1377 begins at 08:26:19.304434\n",
            "Training: batch 1378 begins at 08:26:19.310309\n",
            "Training: batch 1379 begins at 08:26:19.316896\n",
            "Training: batch 1380 begins at 08:26:19.324362\n",
            "1381/1875 [=====================>........] - ETA: 3s - loss: 0.2611 - accuracy: 0.9005Training: batch 1381 begins at 08:26:19.331128\n",
            "Training: batch 1382 begins at 08:26:19.341591\n",
            "Training: batch 1383 begins at 08:26:19.349597\n",
            "Training: batch 1384 begins at 08:26:19.358387\n",
            "Training: batch 1385 begins at 08:26:19.366649\n",
            "Training: batch 1386 begins at 08:26:19.375721\n",
            "1387/1875 [=====================>........] - ETA: 3s - loss: 0.2609 - accuracy: 0.9005Training: batch 1387 begins at 08:26:19.385291\n",
            "Training: batch 1388 begins at 08:26:19.394582\n",
            "Training: batch 1389 begins at 08:26:19.402788\n",
            "Training: batch 1390 begins at 08:26:19.411670\n",
            "Training: batch 1391 begins at 08:26:19.417508\n",
            "Training: batch 1392 begins at 08:26:19.423820\n",
            "Training: batch 1393 begins at 08:26:19.433233\n",
            "1394/1875 [=====================>........] - ETA: 3s - loss: 0.2611 - accuracy: 0.9004Training: batch 1394 begins at 08:26:19.446647\n",
            "Training: batch 1395 begins at 08:26:19.454698\n",
            "Training: batch 1396 begins at 08:26:19.462573\n",
            "Training: batch 1397 begins at 08:26:19.470379\n",
            "Training: batch 1398 begins at 08:26:19.478375\n",
            "Training: batch 1399 begins at 08:26:19.486110\n",
            "1400/1875 [=====================>........] - ETA: 3s - loss: 0.2608 - accuracy: 0.9006Training: batch 1400 begins at 08:26:19.497014\n",
            "Training: batch 1401 begins at 08:26:19.503914\n",
            "Training: batch 1402 begins at 08:26:19.514818\n",
            "Training: batch 1403 begins at 08:26:19.523923\n",
            "Training: batch 1404 begins at 08:26:19.529599\n",
            "Training: batch 1405 begins at 08:26:19.539937\n",
            "1406/1875 [=====================>........] - ETA: 3s - loss: 0.2608 - accuracy: 0.9007Training: batch 1406 begins at 08:26:19.553397\n",
            "Training: batch 1407 begins at 08:26:19.559352\n",
            "Training: batch 1408 begins at 08:26:19.568133\n",
            "Training: batch 1409 begins at 08:26:19.578299\n",
            "Training: batch 1410 begins at 08:26:19.586520\n",
            "Training: batch 1411 begins at 08:26:19.595954\n",
            "1412/1875 [=====================>........] - ETA: 3s - loss: 0.2607 - accuracy: 0.9008Training: batch 1412 begins at 08:26:19.611020\n",
            "Training: batch 1413 begins at 08:26:19.617889\n",
            "Training: batch 1414 begins at 08:26:19.631940\n",
            "Training: batch 1415 begins at 08:26:19.639697\n",
            "Training: batch 1416 begins at 08:26:19.648904\n",
            "Training: batch 1417 begins at 08:26:19.657273\n",
            "1418/1875 [=====================>........] - ETA: 3s - loss: 0.2608 - accuracy: 0.9008Training: batch 1418 begins at 08:26:19.670458\n",
            "Training: batch 1419 begins at 08:26:19.677980\n",
            "Training: batch 1420 begins at 08:26:19.684401\n",
            "Training: batch 1421 begins at 08:26:19.689920\n",
            "Training: batch 1422 begins at 08:26:19.696198\n",
            "Training: batch 1423 begins at 08:26:19.708515\n",
            "Training: batch 1424 begins at 08:26:19.714871\n",
            "1425/1875 [=====================>........] - ETA: 3s - loss: 0.2608 - accuracy: 0.9008Training: batch 1425 begins at 08:26:19.723677\n",
            "Training: batch 1426 begins at 08:26:19.730253\n",
            "Training: batch 1427 begins at 08:26:19.736748\n",
            "Training: batch 1428 begins at 08:26:19.744438\n",
            "Training: batch 1429 begins at 08:26:19.751991\n",
            "Training: batch 1430 begins at 08:26:19.758841\n",
            "Training: batch 1431 begins at 08:26:19.769469\n",
            "1432/1875 [=====================>........] - ETA: 3s - loss: 0.2606 - accuracy: 0.9009Training: batch 1432 begins at 08:26:19.778936\n",
            "Training: batch 1433 begins at 08:26:19.788179\n",
            "Training: batch 1434 begins at 08:26:19.794519\n",
            "Training: batch 1435 begins at 08:26:19.800313\n",
            "Training: batch 1436 begins at 08:26:19.809853\n",
            "Training: batch 1437 begins at 08:26:19.814738\n",
            "Training: batch 1438 begins at 08:26:19.819505\n",
            "1439/1875 [======================>.......] - ETA: 3s - loss: 0.2603 - accuracy: 0.9011Training: batch 1439 begins at 08:26:19.830789\n",
            "Training: batch 1440 begins at 08:26:19.837331\n",
            "Training: batch 1441 begins at 08:26:19.841921\n",
            "Training: batch 1442 begins at 08:26:19.851452\n",
            "Training: batch 1443 begins at 08:26:19.856889\n",
            "Training: batch 1444 begins at 08:26:19.863560\n",
            "Training: batch 1445 begins at 08:26:19.870804\n",
            "1446/1875 [======================>.......] - ETA: 3s - loss: 0.2600 - accuracy: 0.9012Training: batch 1446 begins at 08:26:19.882443\n",
            "Training: batch 1447 begins at 08:26:19.888878\n",
            "Training: batch 1448 begins at 08:26:19.894493\n",
            "Training: batch 1449 begins at 08:26:19.901626\n",
            "Training: batch 1450 begins at 08:26:19.908432\n",
            "Training: batch 1451 begins at 08:26:19.918368\n",
            "Training: batch 1452 begins at 08:26:19.927651\n",
            "1453/1875 [======================>.......] - ETA: 3s - loss: 0.2601 - accuracy: 0.9012Training: batch 1453 begins at 08:26:19.937381\n",
            "Training: batch 1454 begins at 08:26:19.945651\n",
            "Training: batch 1455 begins at 08:26:19.955187\n",
            "Training: batch 1456 begins at 08:26:19.961886\n",
            "Training: batch 1457 begins at 08:26:19.969538\n",
            "Training: batch 1458 begins at 08:26:19.976587\n",
            "Training: batch 1459 begins at 08:26:19.983897\n",
            "1460/1875 [======================>.......] - ETA: 3s - loss: 0.2601 - accuracy: 0.9011Training: batch 1460 begins at 08:26:19.994727\n",
            "Training: batch 1461 begins at 08:26:20.000952\n",
            "Training: batch 1462 begins at 08:26:20.005871\n",
            "Training: batch 1463 begins at 08:26:20.013445\n",
            "Training: batch 1464 begins at 08:26:20.021809\n",
            "Training: batch 1465 begins at 08:26:20.027741\n",
            "Training: batch 1466 begins at 08:26:20.033586\n",
            "Training: batch 1467 begins at 08:26:20.039631\n",
            "1468/1875 [======================>.......] - ETA: 3s - loss: 0.2602 - accuracy: 0.9012Training: batch 1468 begins at 08:26:20.052003\n",
            "Training: batch 1469 begins at 08:26:20.064036\n",
            "Training: batch 1470 begins at 08:26:20.077712\n",
            "Training: batch 1471 begins at 08:26:20.091200\n",
            "1472/1875 [======================>.......] - ETA: 3s - loss: 0.2601 - accuracy: 0.9012Training: batch 1472 begins at 08:26:20.102991\n",
            "Training: batch 1473 begins at 08:26:20.113429\n",
            "Training: batch 1474 begins at 08:26:20.122406\n",
            "Training: batch 1475 begins at 08:26:20.132859\n",
            "Training: batch 1476 begins at 08:26:20.143944\n",
            "1477/1875 [======================>.......] - ETA: 3s - loss: 0.2603 - accuracy: 0.9012Training: batch 1477 begins at 08:26:20.155393\n",
            "Training: batch 1478 begins at 08:26:20.164621\n",
            "Training: batch 1479 begins at 08:26:20.179207\n",
            "Training: batch 1480 begins at 08:26:20.185869\n",
            "Training: batch 1481 begins at 08:26:20.196693\n",
            "1482/1875 [======================>.......] - ETA: 3s - loss: 0.2606 - accuracy: 0.9011Training: batch 1482 begins at 08:26:20.209720\n",
            "Training: batch 1483 begins at 08:26:20.218378\n",
            "Training: batch 1484 begins at 08:26:20.228829\n",
            "Training: batch 1485 begins at 08:26:20.237990\n",
            "Training: batch 1486 begins at 08:26:20.251129\n",
            "1487/1875 [======================>.......] - ETA: 3s - loss: 0.2604 - accuracy: 0.9012Training: batch 1487 begins at 08:26:20.263193\n",
            "Training: batch 1488 begins at 08:26:20.269295\n",
            "Training: batch 1489 begins at 08:26:20.277346\n",
            "Training: batch 1490 begins at 08:26:20.286422\n",
            "Training: batch 1491 begins at 08:26:20.294809\n",
            "Training: batch 1492 begins at 08:26:20.303296\n",
            "1493/1875 [======================>.......] - ETA: 3s - loss: 0.2607 - accuracy: 0.9010Training: batch 1493 begins at 08:26:20.313116\n",
            "Training: batch 1494 begins at 08:26:20.322305\n",
            "Training: batch 1495 begins at 08:26:20.330311\n",
            "Training: batch 1496 begins at 08:26:20.337335\n",
            "Training: batch 1497 begins at 08:26:20.349063\n",
            "Training: batch 1498 begins at 08:26:20.355905\n",
            "1499/1875 [======================>.......] - ETA: 3s - loss: 0.2609 - accuracy: 0.9010Training: batch 1499 begins at 08:26:20.364408\n",
            "Training: batch 1500 begins at 08:26:20.372905\n",
            "Training: batch 1501 begins at 08:26:20.378945\n",
            "Training: batch 1502 begins at 08:26:20.387308\n",
            "Training: batch 1503 begins at 08:26:20.395890\n",
            "Training: batch 1504 begins at 08:26:20.402488\n",
            "Training: batch 1505 begins at 08:26:20.408980\n",
            "1506/1875 [=======================>......] - ETA: 2s - loss: 0.2611 - accuracy: 0.9010Training: batch 1506 begins at 08:26:20.420181\n",
            "Training: batch 1507 begins at 08:26:20.426825\n",
            "Training: batch 1508 begins at 08:26:20.434659\n",
            "Training: batch 1509 begins at 08:26:20.441237\n",
            "Training: batch 1510 begins at 08:26:20.449030\n",
            "Training: batch 1511 begins at 08:26:20.457955\n",
            "Training: batch 1512 begins at 08:26:20.464741\n",
            "1513/1875 [=======================>......] - ETA: 2s - loss: 0.2610 - accuracy: 0.9010Training: batch 1513 begins at 08:26:20.473919\n",
            "Training: batch 1514 begins at 08:26:20.481067\n",
            "Training: batch 1515 begins at 08:26:20.487275\n",
            "Training: batch 1516 begins at 08:26:20.493802\n",
            "Training: batch 1517 begins at 08:26:20.507345\n",
            "Training: batch 1518 begins at 08:26:20.514287\n",
            "Training: batch 1519 begins at 08:26:20.520918\n",
            "1520/1875 [=======================>......] - ETA: 2s - loss: 0.2606 - accuracy: 0.9012Training: batch 1520 begins at 08:26:20.533078\n",
            "Training: batch 1521 begins at 08:26:20.539671\n",
            "Training: batch 1522 begins at 08:26:20.546061\n",
            "Training: batch 1523 begins at 08:26:20.552441\n",
            "Training: batch 1524 begins at 08:26:20.559475\n",
            "Training: batch 1525 begins at 08:26:20.567434\n",
            "Training: batch 1526 begins at 08:26:20.574308\n",
            "1527/1875 [=======================>......] - ETA: 2s - loss: 0.2605 - accuracy: 0.9013Training: batch 1527 begins at 08:26:20.583730\n",
            "Training: batch 1528 begins at 08:26:20.590835\n",
            "Training: batch 1529 begins at 08:26:20.598474\n",
            "Training: batch 1530 begins at 08:26:20.607329\n",
            "Training: batch 1531 begins at 08:26:20.613210\n",
            "Training: batch 1532 begins at 08:26:20.623555\n",
            "Training: batch 1533 begins at 08:26:20.628351\n",
            "1534/1875 [=======================>......] - ETA: 2s - loss: 0.2607 - accuracy: 0.9013Training: batch 1534 begins at 08:26:20.635192\n",
            "Training: batch 1535 begins at 08:26:20.642982\n",
            "Training: batch 1536 begins at 08:26:20.649736\n",
            "Training: batch 1537 begins at 08:26:20.655391\n",
            "Training: batch 1538 begins at 08:26:20.664026\n",
            "Training: batch 1539 begins at 08:26:20.673967\n",
            "Training: batch 1540 begins at 08:26:20.681659\n",
            "1541/1875 [=======================>......] - ETA: 2s - loss: 0.2605 - accuracy: 0.9013Training: batch 1541 begins at 08:26:20.691086\n",
            "Training: batch 1542 begins at 08:26:20.697589\n",
            "Training: batch 1543 begins at 08:26:20.702394\n",
            "Training: batch 1544 begins at 08:26:20.709672\n",
            "Training: batch 1545 begins at 08:26:20.717359\n",
            "Training: batch 1546 begins at 08:26:20.723968\n",
            "Training: batch 1547 begins at 08:26:20.731796\n",
            "Training: batch 1548 begins at 08:26:20.738349\n",
            "1549/1875 [=======================>......] - ETA: 2s - loss: 0.2608 - accuracy: 0.9012Training: batch 1549 begins at 08:26:20.751442\n",
            "Training: batch 1550 begins at 08:26:20.761244\n",
            "Training: batch 1551 begins at 08:26:20.769765\n",
            "Training: batch 1552 begins at 08:26:20.778816\n",
            "Training: batch 1553 begins at 08:26:20.788082\n",
            "Training: batch 1554 begins at 08:26:20.797601\n",
            "1555/1875 [=======================>......] - ETA: 2s - loss: 0.2607 - accuracy: 0.9013Training: batch 1555 begins at 08:26:20.810059\n",
            "Training: batch 1556 begins at 08:26:20.819587\n",
            "Training: batch 1557 begins at 08:26:20.830044\n",
            "Training: batch 1558 begins at 08:26:20.838637\n",
            "Training: batch 1559 begins at 08:26:20.847791\n",
            "Training: batch 1560 begins at 08:26:20.856141\n",
            "1561/1875 [=======================>......] - ETA: 2s - loss: 0.2607 - accuracy: 0.9013Training: batch 1561 begins at 08:26:20.866884\n",
            "Training: batch 1562 begins at 08:26:20.877041\n",
            "Training: batch 1563 begins at 08:26:20.892572\n",
            "Training: batch 1564 begins at 08:26:20.899371\n",
            "Training: batch 1565 begins at 08:26:20.907280\n",
            "1566/1875 [========================>.....] - ETA: 2s - loss: 0.2607 - accuracy: 0.9013Training: batch 1566 begins at 08:26:20.916689\n",
            "Training: batch 1567 begins at 08:26:20.927673\n",
            "Training: batch 1568 begins at 08:26:20.937538\n",
            "Training: batch 1569 begins at 08:26:20.944322\n",
            "Training: batch 1570 begins at 08:26:20.954196\n",
            "Training: batch 1571 begins at 08:26:20.960209\n",
            "1572/1875 [========================>.....] - ETA: 2s - loss: 0.2606 - accuracy: 0.9013Training: batch 1572 begins at 08:26:20.975570\n",
            "Training: batch 1573 begins at 08:26:20.983070\n",
            "Training: batch 1574 begins at 08:26:20.991062\n",
            "Training: batch 1575 begins at 08:26:21.000316\n",
            "Training: batch 1576 begins at 08:26:21.009358\n",
            "Training: batch 1577 begins at 08:26:21.016837\n",
            "1578/1875 [========================>.....] - ETA: 2s - loss: 0.2608 - accuracy: 0.9012Training: batch 1578 begins at 08:26:21.028285\n",
            "Training: batch 1579 begins at 08:26:21.035295\n",
            "Training: batch 1580 begins at 08:26:21.045312\n",
            "Training: batch 1581 begins at 08:26:21.051371\n",
            "Training: batch 1582 begins at 08:26:21.058874\n",
            "Training: batch 1583 begins at 08:26:21.065361\n",
            "Training: batch 1584 begins at 08:26:21.073987\n",
            "1585/1875 [========================>.....] - ETA: 2s - loss: 0.2606 - accuracy: 0.9013Training: batch 1585 begins at 08:26:21.084838\n",
            "Training: batch 1586 begins at 08:26:21.091001\n",
            "Training: batch 1587 begins at 08:26:21.097417\n",
            "Training: batch 1588 begins at 08:26:21.104745\n",
            "Training: batch 1589 begins at 08:26:21.110485\n",
            "Training: batch 1590 begins at 08:26:21.117846\n",
            "Training: batch 1591 begins at 08:26:21.125505\n",
            "1592/1875 [========================>.....] - ETA: 2s - loss: 0.2605 - accuracy: 0.9013Training: batch 1592 begins at 08:26:21.135914\n",
            "Training: batch 1593 begins at 08:26:21.145391\n",
            "Training: batch 1594 begins at 08:26:21.154510\n",
            "Training: batch 1595 begins at 08:26:21.161894\n",
            "Training: batch 1596 begins at 08:26:21.168277\n",
            "Training: batch 1597 begins at 08:26:21.172919\n",
            "Training: batch 1598 begins at 08:26:21.180119\n",
            "1599/1875 [========================>.....] - ETA: 2s - loss: 0.2606 - accuracy: 0.9014Training: batch 1599 begins at 08:26:21.188139\n",
            "Training: batch 1600 begins at 08:26:21.198350\n",
            "Training: batch 1601 begins at 08:26:21.205098\n",
            "Training: batch 1602 begins at 08:26:21.213670\n",
            "Training: batch 1603 begins at 08:26:21.220014\n",
            "Training: batch 1604 begins at 08:26:21.225046\n",
            "Training: batch 1605 begins at 08:26:21.233052\n",
            "1606/1875 [========================>.....] - ETA: 2s - loss: 0.2604 - accuracy: 0.9015Training: batch 1606 begins at 08:26:21.243127\n",
            "Training: batch 1607 begins at 08:26:21.251684\n",
            "Training: batch 1608 begins at 08:26:21.257095\n",
            "Training: batch 1609 begins at 08:26:21.264328\n",
            "Training: batch 1610 begins at 08:26:21.270460\n",
            "Training: batch 1611 begins at 08:26:21.276639\n",
            "Training: batch 1612 begins at 08:26:21.284649\n",
            "1613/1875 [========================>.....] - ETA: 2s - loss: 0.2606 - accuracy: 0.9014Training: batch 1613 begins at 08:26:21.294756\n",
            "Training: batch 1614 begins at 08:26:21.302878\n",
            "Training: batch 1615 begins at 08:26:21.309197\n",
            "Training: batch 1616 begins at 08:26:21.317302\n",
            "Training: batch 1617 begins at 08:26:21.326820\n",
            "Training: batch 1618 begins at 08:26:21.334116\n",
            "1619/1875 [========================>.....] - ETA: 2s - loss: 0.2606 - accuracy: 0.9014Training: batch 1619 begins at 08:26:21.345511\n",
            "Training: batch 1620 begins at 08:26:21.353911\n",
            "Training: batch 1621 begins at 08:26:21.361911\n",
            "Training: batch 1622 begins at 08:26:21.369656\n",
            "Training: batch 1623 begins at 08:26:21.377730\n",
            "Training: batch 1624 begins at 08:26:21.386056\n",
            "1625/1875 [=========================>....] - ETA: 2s - loss: 0.2607 - accuracy: 0.9013Training: batch 1625 begins at 08:26:21.400106\n",
            "Training: batch 1626 begins at 08:26:21.409539\n",
            "Training: batch 1627 begins at 08:26:21.418657\n",
            "Training: batch 1628 begins at 08:26:21.425822\n",
            "Training: batch 1629 begins at 08:26:21.436323\n",
            "Training: batch 1630 begins at 08:26:21.445897\n",
            "1631/1875 [=========================>....] - ETA: 1s - loss: 0.2609 - accuracy: 0.9012Training: batch 1631 begins at 08:26:21.456069\n",
            "Training: batch 1632 begins at 08:26:21.465013\n",
            "Training: batch 1633 begins at 08:26:21.473613\n",
            "Training: batch 1634 begins at 08:26:21.483097\n",
            "Training: batch 1635 begins at 08:26:21.493723\n",
            "Training: batch 1636 begins at 08:26:21.502943\n",
            "1637/1875 [=========================>....] - ETA: 1s - loss: 0.2607 - accuracy: 0.9013Training: batch 1637 begins at 08:26:21.514611\n",
            "Training: batch 1638 begins at 08:26:21.523327\n",
            "Training: batch 1639 begins at 08:26:21.530227\n",
            "Training: batch 1640 begins at 08:26:21.540005\n",
            "Training: batch 1641 begins at 08:26:21.550089\n",
            "Training: batch 1642 begins at 08:26:21.560203\n",
            "1643/1875 [=========================>....] - ETA: 1s - loss: 0.2607 - accuracy: 0.9013Training: batch 1643 begins at 08:26:21.570950\n",
            "Training: batch 1644 begins at 08:26:21.581018\n",
            "Training: batch 1645 begins at 08:26:21.589106\n",
            "Training: batch 1646 begins at 08:26:21.596583\n",
            "Training: batch 1647 begins at 08:26:21.604452\n",
            "Training: batch 1648 begins at 08:26:21.611671\n",
            "1649/1875 [=========================>....] - ETA: 1s - loss: 0.2608 - accuracy: 0.9013Training: batch 1649 begins at 08:26:21.620456\n",
            "Training: batch 1650 begins at 08:26:21.628830\n",
            "Training: batch 1651 begins at 08:26:21.637003\n",
            "Training: batch 1652 begins at 08:26:21.644074\n",
            "Training: batch 1653 begins at 08:26:21.650972\n",
            "Training: batch 1654 begins at 08:26:21.656686\n",
            "Training: batch 1655 begins at 08:26:21.665163\n",
            "1656/1875 [=========================>....] - ETA: 1s - loss: 0.2611 - accuracy: 0.9012Training: batch 1656 begins at 08:26:21.672443\n",
            "Training: batch 1657 begins at 08:26:21.680058\n",
            "Training: batch 1658 begins at 08:26:21.689094\n",
            "Training: batch 1659 begins at 08:26:21.696004\n",
            "Training: batch 1660 begins at 08:26:21.705134\n",
            "Training: batch 1661 begins at 08:26:21.714044\n",
            "Training: batch 1662 begins at 08:26:21.719791\n",
            "1663/1875 [=========================>....] - ETA: 1s - loss: 0.2612 - accuracy: 0.9010Training: batch 1663 begins at 08:26:21.729881\n",
            "Training: batch 1664 begins at 08:26:21.736699\n",
            "Training: batch 1665 begins at 08:26:21.744190\n",
            "Training: batch 1666 begins at 08:26:21.754997\n",
            "Training: batch 1667 begins at 08:26:21.764783\n",
            "Training: batch 1668 begins at 08:26:21.772827\n",
            "1669/1875 [=========================>....] - ETA: 1s - loss: 0.2617 - accuracy: 0.9009Training: batch 1669 begins at 08:26:21.786542\n",
            "Training: batch 1670 begins at 08:26:21.796457\n",
            "Training: batch 1671 begins at 08:26:21.809309\n",
            "Training: batch 1672 begins at 08:26:21.818827\n",
            "Training: batch 1673 begins at 08:26:21.828998\n",
            "1674/1875 [=========================>....] - ETA: 1s - loss: 0.2620 - accuracy: 0.9008Training: batch 1674 begins at 08:26:21.841030\n",
            "Training: batch 1675 begins at 08:26:21.849777\n",
            "Training: batch 1676 begins at 08:26:21.857743\n",
            "Training: batch 1677 begins at 08:26:21.867706\n",
            "Training: batch 1678 begins at 08:26:21.878549\n",
            "Training: batch 1679 begins at 08:26:21.886856\n",
            "1680/1875 [=========================>....] - ETA: 1s - loss: 0.2619 - accuracy: 0.9008Training: batch 1680 begins at 08:26:21.899763\n",
            "Training: batch 1681 begins at 08:26:21.906883\n",
            "Training: batch 1682 begins at 08:26:21.915361\n",
            "Training: batch 1683 begins at 08:26:21.924692\n",
            "Training: batch 1684 begins at 08:26:21.935230\n",
            "Training: batch 1685 begins at 08:26:21.944494\n",
            "1686/1875 [=========================>....] - ETA: 1s - loss: 0.2618 - accuracy: 0.9009Training: batch 1686 begins at 08:26:21.957481\n",
            "Training: batch 1687 begins at 08:26:21.967740\n",
            "Training: batch 1688 begins at 08:26:21.974363\n",
            "Training: batch 1689 begins at 08:26:21.981363\n",
            "Training: batch 1690 begins at 08:26:21.989429\n",
            "Training: batch 1691 begins at 08:26:21.998449\n",
            "1692/1875 [==========================>...] - ETA: 1s - loss: 0.2615 - accuracy: 0.9011Training: batch 1692 begins at 08:26:22.008121\n",
            "Training: batch 1693 begins at 08:26:22.016820\n",
            "Training: batch 1694 begins at 08:26:22.027727\n",
            "Training: batch 1695 begins at 08:26:22.035934\n",
            "Training: batch 1696 begins at 08:26:22.042160\n",
            "Training: batch 1697 begins at 08:26:22.049540\n",
            "Training: batch 1698 begins at 08:26:22.055743\n",
            "1699/1875 [==========================>...] - ETA: 1s - loss: 0.2614 - accuracy: 0.9012Training: batch 1699 begins at 08:26:22.065360\n",
            "Training: batch 1700 begins at 08:26:22.072561\n",
            "Training: batch 1701 begins at 08:26:22.083215\n",
            "Training: batch 1702 begins at 08:26:22.092563\n",
            "Training: batch 1703 begins at 08:26:22.098586\n",
            "Training: batch 1704 begins at 08:26:22.104541\n",
            "1705/1875 [==========================>...] - ETA: 1s - loss: 0.2611 - accuracy: 0.9013Training: batch 1705 begins at 08:26:22.116487\n",
            "Training: batch 1706 begins at 08:26:22.127807\n",
            "Training: batch 1707 begins at 08:26:22.135250\n",
            "Training: batch 1708 begins at 08:26:22.142600\n",
            "Training: batch 1709 begins at 08:26:22.151350\n",
            "Training: batch 1710 begins at 08:26:22.158435\n",
            "1711/1875 [==========================>...] - ETA: 1s - loss: 0.2609 - accuracy: 0.9014Training: batch 1711 begins at 08:26:22.169219\n",
            "Training: batch 1712 begins at 08:26:22.175840\n",
            "Training: batch 1713 begins at 08:26:22.182390\n",
            "Training: batch 1714 begins at 08:26:22.190455\n",
            "Training: batch 1715 begins at 08:26:22.196355\n",
            "Training: batch 1716 begins at 08:26:22.204274\n",
            "1717/1875 [==========================>...] - ETA: 1s - loss: 0.2608 - accuracy: 0.9014Training: batch 1717 begins at 08:26:22.218083\n",
            "Training: batch 1718 begins at 08:26:22.224368\n",
            "Training: batch 1719 begins at 08:26:22.233674\n",
            "Training: batch 1720 begins at 08:26:22.240768\n",
            "Training: batch 1721 begins at 08:26:22.249483\n",
            "Training: batch 1722 begins at 08:26:22.258844\n",
            "Training: batch 1723 begins at 08:26:22.264685\n",
            "1724/1875 [==========================>...] - ETA: 1s - loss: 0.2609 - accuracy: 0.9014Training: batch 1724 begins at 08:26:22.272219\n",
            "Training: batch 1725 begins at 08:26:22.278459\n",
            "Training: batch 1726 begins at 08:26:22.284817\n",
            "Training: batch 1727 begins at 08:26:22.290832\n",
            "Training: batch 1728 begins at 08:26:22.300867\n",
            "Training: batch 1729 begins at 08:26:22.306904\n",
            "Training: batch 1730 begins at 08:26:22.313890\n",
            "Training: batch 1731 begins at 08:26:22.320020\n",
            "1732/1875 [==========================>...] - ETA: 1s - loss: 0.2610 - accuracy: 0.9015Training: batch 1732 begins at 08:26:22.330735\n",
            "Training: batch 1733 begins at 08:26:22.336419\n",
            "Training: batch 1734 begins at 08:26:22.343808\n",
            "Training: batch 1735 begins at 08:26:22.349461\n",
            "Training: batch 1736 begins at 08:26:22.357812\n",
            "Training: batch 1737 begins at 08:26:22.365809\n",
            "Training: batch 1738 begins at 08:26:22.372113\n",
            "1739/1875 [==========================>...] - ETA: 1s - loss: 0.2612 - accuracy: 0.9013Training: batch 1739 begins at 08:26:22.381765\n",
            "Training: batch 1740 begins at 08:26:22.388707\n",
            "Training: batch 1741 begins at 08:26:22.394492\n",
            "Training: batch 1742 begins at 08:26:22.401843\n",
            "Training: batch 1743 begins at 08:26:22.414206\n",
            "Training: batch 1744 begins at 08:26:22.420641\n",
            "Training: batch 1745 begins at 08:26:22.427541\n",
            "1746/1875 [==========================>...] - ETA: 1s - loss: 0.2615 - accuracy: 0.9013Training: batch 1746 begins at 08:26:22.434700\n",
            "Training: batch 1747 begins at 08:26:22.443107\n",
            "Training: batch 1748 begins at 08:26:22.451389\n",
            "Training: batch 1749 begins at 08:26:22.458838\n",
            "Training: batch 1750 begins at 08:26:22.466743\n",
            "Training: batch 1751 begins at 08:26:22.472643\n",
            "Training: batch 1752 begins at 08:26:22.479910\n",
            "1753/1875 [===========================>..] - ETA: 0s - loss: 0.2613 - accuracy: 0.9013Training: batch 1753 begins at 08:26:22.487617\n",
            "Training: batch 1754 begins at 08:26:22.494825\n",
            "Training: batch 1755 begins at 08:26:22.501778\n",
            "Training: batch 1756 begins at 08:26:22.508403\n",
            "Training: batch 1757 begins at 08:26:22.514741\n",
            "Training: batch 1758 begins at 08:26:22.521866\n",
            "Training: batch 1759 begins at 08:26:22.527849\n",
            "Training: batch 1760 begins at 08:26:22.535007\n",
            "1761/1875 [===========================>..] - ETA: 0s - loss: 0.2615 - accuracy: 0.9012Training: batch 1761 begins at 08:26:22.543603\n",
            "Training: batch 1762 begins at 08:26:22.550395\n",
            "Training: batch 1763 begins at 08:26:22.557753\n",
            "Training: batch 1764 begins at 08:26:22.564816\n",
            "Training: batch 1765 begins at 08:26:22.571942\n",
            "Training: batch 1766 begins at 08:26:22.582866\n",
            "Training: batch 1767 begins at 08:26:22.589872\n",
            "1768/1875 [===========================>..] - ETA: 0s - loss: 0.2614 - accuracy: 0.9012Training: batch 1768 begins at 08:26:22.597761\n",
            "Training: batch 1769 begins at 08:26:22.610762\n",
            "Training: batch 1770 begins at 08:26:22.617758\n",
            "Training: batch 1771 begins at 08:26:22.625699\n",
            "Training: batch 1772 begins at 08:26:22.633367\n",
            "Training: batch 1773 begins at 08:26:22.641362\n",
            "1774/1875 [===========================>..] - ETA: 0s - loss: 0.2612 - accuracy: 0.9013Training: batch 1774 begins at 08:26:22.648988\n",
            "Training: batch 1775 begins at 08:26:22.656592\n",
            "Training: batch 1776 begins at 08:26:22.662597\n",
            "Training: batch 1777 begins at 08:26:22.669843\n",
            "Training: batch 1778 begins at 08:26:22.679990\n",
            "Training: batch 1779 begins at 08:26:22.687435\n",
            "Training: batch 1780 begins at 08:26:22.693824\n",
            "1781/1875 [===========================>..] - ETA: 0s - loss: 0.2611 - accuracy: 0.9014Training: batch 1781 begins at 08:26:22.703390\n",
            "Training: batch 1782 begins at 08:26:22.710610\n",
            "Training: batch 1783 begins at 08:26:22.717812\n",
            "Training: batch 1784 begins at 08:26:22.723596\n",
            "Training: batch 1785 begins at 08:26:22.730349\n",
            "Training: batch 1786 begins at 08:26:22.738933\n",
            "Training: batch 1787 begins at 08:26:22.745056\n",
            "1788/1875 [===========================>..] - ETA: 0s - loss: 0.2612 - accuracy: 0.9014Training: batch 1788 begins at 08:26:22.754371\n",
            "Training: batch 1789 begins at 08:26:22.761921\n",
            "Training: batch 1790 begins at 08:26:22.769081\n",
            "Training: batch 1791 begins at 08:26:22.775634\n",
            "Training: batch 1792 begins at 08:26:22.783515\n",
            "Training: batch 1793 begins at 08:26:22.795556\n",
            "1794/1875 [===========================>..] - ETA: 0s - loss: 0.2616 - accuracy: 0.9013Training: batch 1794 begins at 08:26:22.804450\n",
            "Training: batch 1795 begins at 08:26:22.814609\n",
            "Training: batch 1796 begins at 08:26:22.820584\n",
            "Training: batch 1797 begins at 08:26:22.827927\n",
            "Training: batch 1798 begins at 08:26:22.834340\n",
            "Training: batch 1799 begins at 08:26:22.841077\n",
            "Training: batch 1800 begins at 08:26:22.848483\n",
            "1801/1875 [===========================>..] - ETA: 0s - loss: 0.2619 - accuracy: 0.9013Training: batch 1801 begins at 08:26:22.857460\n",
            "Training: batch 1802 begins at 08:26:22.867882\n",
            "Training: batch 1803 begins at 08:26:22.874887\n",
            "Training: batch 1804 begins at 08:26:22.880859\n",
            "Training: batch 1805 begins at 08:26:22.887983\n",
            "Training: batch 1806 begins at 08:26:22.895762\n",
            "Training: batch 1807 begins at 08:26:22.903725\n",
            "1808/1875 [===========================>..] - ETA: 0s - loss: 0.2619 - accuracy: 0.9011Training: batch 1808 begins at 08:26:22.911576\n",
            "Training: batch 1809 begins at 08:26:22.917758\n",
            "Training: batch 1810 begins at 08:26:22.925844\n",
            "Training: batch 1811 begins at 08:26:22.932030\n",
            "Training: batch 1812 begins at 08:26:22.938872\n",
            "Training: batch 1813 begins at 08:26:22.948125\n",
            "Training: batch 1814 begins at 08:26:22.954642\n",
            "1815/1875 [============================>.] - ETA: 0s - loss: 0.2618 - accuracy: 0.9013Training: batch 1815 begins at 08:26:22.964464\n",
            "Training: batch 1816 begins at 08:26:22.971077\n",
            "Training: batch 1817 begins at 08:26:22.980340\n",
            "Training: batch 1818 begins at 08:26:22.986773\n",
            "Training: batch 1819 begins at 08:26:22.994688\n",
            "Training: batch 1820 begins at 08:26:23.002919\n",
            "1821/1875 [============================>.] - ETA: 0s - loss: 0.2617 - accuracy: 0.9013Training: batch 1821 begins at 08:26:23.011904\n",
            "Training: batch 1822 begins at 08:26:23.020025\n",
            "Training: batch 1823 begins at 08:26:23.029139\n",
            "Training: batch 1824 begins at 08:26:23.035437\n",
            "Training: batch 1825 begins at 08:26:23.042993\n",
            "Training: batch 1826 begins at 08:26:23.049254\n",
            "Training: batch 1827 begins at 08:26:23.057932\n",
            "1828/1875 [============================>.] - ETA: 0s - loss: 0.2616 - accuracy: 0.9013Training: batch 1828 begins at 08:26:23.065712\n",
            "Training: batch 1829 begins at 08:26:23.072617\n",
            "Training: batch 1830 begins at 08:26:23.080806\n",
            "Training: batch 1831 begins at 08:26:23.087109\n",
            "Training: batch 1832 begins at 08:26:23.093080\n",
            "Training: batch 1833 begins at 08:26:23.099359\n",
            "Training: batch 1834 begins at 08:26:23.113972\n",
            "1835/1875 [============================>.] - ETA: 0s - loss: 0.2617 - accuracy: 0.9013Training: batch 1835 begins at 08:26:23.125200\n",
            "Training: batch 1836 begins at 08:26:23.131712\n",
            "Training: batch 1837 begins at 08:26:23.142236\n",
            "Training: batch 1838 begins at 08:26:23.146962\n",
            "Training: batch 1839 begins at 08:26:23.154075\n",
            "Training: batch 1840 begins at 08:26:23.162945\n",
            "Training: batch 1841 begins at 08:26:23.170793\n",
            "1842/1875 [============================>.] - ETA: 0s - loss: 0.2617 - accuracy: 0.9013Training: batch 1842 begins at 08:26:23.178918\n",
            "Training: batch 1843 begins at 08:26:23.184978\n",
            "Training: batch 1844 begins at 08:26:23.192713\n",
            "Training: batch 1845 begins at 08:26:23.200711\n",
            "Training: batch 1846 begins at 08:26:23.208234\n",
            "Training: batch 1847 begins at 08:26:23.216733\n",
            "Training: batch 1848 begins at 08:26:23.225214\n",
            "1849/1875 [============================>.] - ETA: 0s - loss: 0.2615 - accuracy: 0.9014Training: batch 1849 begins at 08:26:23.239106\n",
            "Training: batch 1850 begins at 08:26:23.244701\n",
            "Training: batch 1851 begins at 08:26:23.253400\n",
            "Training: batch 1852 begins at 08:26:23.263040\n",
            "Training: batch 1853 begins at 08:26:23.272620\n",
            "Training: batch 1854 begins at 08:26:23.280210\n",
            "1855/1875 [============================>.] - ETA: 0s - loss: 0.2616 - accuracy: 0.9013Training: batch 1855 begins at 08:26:23.294631\n",
            "Training: batch 1856 begins at 08:26:23.301470\n",
            "Training: batch 1857 begins at 08:26:23.309878\n",
            "Training: batch 1858 begins at 08:26:23.316908\n",
            "Training: batch 1859 begins at 08:26:23.326344\n",
            "Training: batch 1860 begins at 08:26:23.334694\n",
            "1861/1875 [============================>.] - ETA: 0s - loss: 0.2619 - accuracy: 0.9012Training: batch 1861 begins at 08:26:23.342902\n",
            "Training: batch 1862 begins at 08:26:23.351591\n",
            "Training: batch 1863 begins at 08:26:23.359203\n",
            "Training: batch 1864 begins at 08:26:23.368682\n",
            "Training: batch 1865 begins at 08:26:23.378513\n",
            "Training: batch 1866 begins at 08:26:23.390406\n",
            "1867/1875 [============================>.] - ETA: 0s - loss: 0.2621 - accuracy: 0.9011Training: batch 1867 begins at 08:26:23.398480\n",
            "Training: batch 1868 begins at 08:26:23.406514\n",
            "Training: batch 1869 begins at 08:26:23.414459\n",
            "Training: batch 1870 begins at 08:26:23.424250\n",
            "Training: batch 1871 begins at 08:26:23.433543\n",
            "Training: batch 1872 begins at 08:26:23.443386\n",
            "1873/1875 [============================>.] - ETA: 0s - loss: 0.2619 - accuracy: 0.9012Training: batch 1873 begins at 08:26:23.454314\n",
            "Training: batch 1874 begins at 08:26:23.462794\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2619 - accuracy: 0.9012\n",
            "Epoch 10/10\n",
            "Training: batch 0 begins at 08:26:23.482546\n",
            "   1/1875 [..............................] - ETA: 24s - loss: 0.3106 - accuracy: 0.9062Training: batch 1 begins at 08:26:23.494115\n",
            "Training: batch 2 begins at 08:26:23.500137\n",
            "Training: batch 3 begins at 08:26:23.506608\n",
            "Training: batch 4 begins at 08:26:23.512279\n",
            "Training: batch 5 begins at 08:26:23.518645\n",
            "Training: batch 6 begins at 08:26:23.524134\n",
            "Training: batch 7 begins at 08:26:23.530747\n",
            "   8/1875 [..............................] - ETA: 13s - loss: 0.2505 - accuracy: 0.8906Training: batch 8 begins at 08:26:23.543711\n",
            "Training: batch 9 begins at 08:26:23.551903\n",
            "Training: batch 10 begins at 08:26:23.559774\n",
            "Training: batch 11 begins at 08:26:23.568359\n",
            "Training: batch 12 begins at 08:26:23.576367\n",
            "Training: batch 13 begins at 08:26:23.585175\n",
            "  14/1875 [..............................] - ETA: 14s - loss: 0.2334 - accuracy: 0.9040Training: batch 14 begins at 08:26:23.593829\n",
            "Training: batch 15 begins at 08:26:23.606895\n",
            "Training: batch 16 begins at 08:26:23.612443\n",
            "Training: batch 17 begins at 08:26:23.620297\n",
            "Training: batch 18 begins at 08:26:23.640139\n",
            "  19/1875 [..............................] - ETA: 16s - loss: 0.2624 - accuracy: 0.8980Training: batch 19 begins at 08:26:23.649440\n",
            "Training: batch 20 begins at 08:26:23.659464\n",
            "Training: batch 21 begins at 08:26:23.665072\n",
            "Training: batch 22 begins at 08:26:23.672465\n",
            "Training: batch 23 begins at 08:26:23.682936\n",
            "Training: batch 24 begins at 08:26:23.688902\n",
            "  25/1875 [..............................] - ETA: 15s - loss: 0.2793 - accuracy: 0.8963Training: batch 25 begins at 08:26:23.698559\n",
            "Training: batch 26 begins at 08:26:23.705981\n",
            "Training: batch 27 begins at 08:26:23.713962\n",
            "Training: batch 28 begins at 08:26:23.723925\n",
            "Training: batch 29 begins at 08:26:23.733047\n",
            "Training: batch 30 begins at 08:26:23.741389\n",
            "  31/1875 [..............................] - ETA: 15s - loss: 0.2695 - accuracy: 0.8982Training: batch 31 begins at 08:26:23.749324\n",
            "Training: batch 32 begins at 08:26:23.756362\n",
            "Training: batch 33 begins at 08:26:23.762810\n",
            "Training: batch 34 begins at 08:26:23.770472\n",
            "Training: batch 35 begins at 08:26:23.778675\n",
            "Training: batch 36 begins at 08:26:23.785689\n",
            "Training: batch 37 begins at 08:26:23.794847\n",
            "  38/1875 [..............................] - ETA: 15s - loss: 0.2644 - accuracy: 0.8980Training: batch 38 begins at 08:26:23.804681\n",
            "Training: batch 39 begins at 08:26:23.812544\n",
            "Training: batch 40 begins at 08:26:23.819385\n",
            "Training: batch 41 begins at 08:26:23.826685\n",
            "Training: batch 42 begins at 08:26:23.833442\n",
            "Training: batch 43 begins at 08:26:23.839869\n",
            "Training: batch 44 begins at 08:26:23.846998\n",
            "  45/1875 [..............................] - ETA: 15s - loss: 0.2934 - accuracy: 0.8882Training: batch 45 begins at 08:26:23.856853\n",
            "Training: batch 46 begins at 08:26:23.864831\n",
            "Training: batch 47 begins at 08:26:23.871467\n",
            "Training: batch 48 begins at 08:26:23.877955\n",
            "Training: batch 49 begins at 08:26:23.886522\n",
            "Training: batch 50 begins at 08:26:23.892724\n",
            "Training: batch 51 begins at 08:26:23.899791\n",
            "  52/1875 [..............................] - ETA: 14s - loss: 0.3017 - accuracy: 0.8864Training: batch 52 begins at 08:26:23.910533\n",
            "Training: batch 53 begins at 08:26:23.917291\n",
            "Training: batch 54 begins at 08:26:23.923450\n",
            "Training: batch 55 begins at 08:26:23.929587\n",
            "Training: batch 56 begins at 08:26:23.938974\n",
            "Training: batch 57 begins at 08:26:23.946739\n",
            "Training: batch 58 begins at 08:26:23.960185\n",
            "  59/1875 [..............................] - ETA: 14s - loss: 0.3041 - accuracy: 0.8851Training: batch 59 begins at 08:26:23.969045\n",
            "Training: batch 60 begins at 08:26:23.975778\n",
            "Training: batch 61 begins at 08:26:23.985814\n",
            "Training: batch 62 begins at 08:26:23.994893\n",
            "Training: batch 63 begins at 08:26:24.003273\n",
            "Training: batch 64 begins at 08:26:24.013681\n",
            "  65/1875 [>.............................] - ETA: 15s - loss: 0.2983 - accuracy: 0.8875Training: batch 65 begins at 08:26:24.027900\n",
            "Training: batch 66 begins at 08:26:24.037304\n",
            "Training: batch 67 begins at 08:26:24.046248\n",
            "Training: batch 68 begins at 08:26:24.052947\n",
            "Training: batch 69 begins at 08:26:24.062749\n",
            "  70/1875 [>.............................] - ETA: 15s - loss: 0.3012 - accuracy: 0.8844Training: batch 70 begins at 08:26:24.077285\n",
            "Training: batch 71 begins at 08:26:24.089747\n",
            "Training: batch 72 begins at 08:26:24.101215\n",
            "Training: batch 73 begins at 08:26:24.112247\n",
            "Training: batch 74 begins at 08:26:24.121906\n",
            "  75/1875 [>.............................] - ETA: 15s - loss: 0.3013 - accuracy: 0.8829Training: batch 75 begins at 08:26:24.136372\n",
            "Training: batch 76 begins at 08:26:24.143694\n",
            "Training: batch 77 begins at 08:26:24.151380\n",
            "Training: batch 78 begins at 08:26:24.157331\n",
            "Training: batch 79 begins at 08:26:24.166973\n",
            "Training: batch 80 begins at 08:26:24.173863\n",
            "Training: batch 81 begins at 08:26:24.179188\n",
            "  82/1875 [>.............................] - ETA: 15s - loss: 0.2940 - accuracy: 0.8838Training: batch 82 begins at 08:26:24.187710\n",
            "Training: batch 83 begins at 08:26:24.195459\n",
            "Training: batch 84 begins at 08:26:24.202857\n",
            "Training: batch 85 begins at 08:26:24.210719\n",
            "Training: batch 86 begins at 08:26:24.218752\n",
            "Training: batch 87 begins at 08:26:24.227719\n",
            "Training: batch 88 begins at 08:26:24.233522\n",
            "  89/1875 [>.............................] - ETA: 15s - loss: 0.2896 - accuracy: 0.8866Training: batch 89 begins at 08:26:24.245750\n",
            "Training: batch 90 begins at 08:26:24.254265\n",
            "Training: batch 91 begins at 08:26:24.265797\n",
            "Training: batch 92 begins at 08:26:24.275128\n",
            "Training: batch 93 begins at 08:26:24.282047\n",
            "Training: batch 94 begins at 08:26:24.289498\n",
            "  95/1875 [>.............................] - ETA: 15s - loss: 0.2826 - accuracy: 0.8901Training: batch 95 begins at 08:26:24.299141\n",
            "Training: batch 96 begins at 08:26:24.305785\n",
            "Training: batch 97 begins at 08:26:24.314880\n",
            "Training: batch 98 begins at 08:26:24.323170\n",
            "Training: batch 99 begins at 08:26:24.329715\n",
            "Training: batch 100 begins at 08:26:24.336196\n",
            "Training: batch 101 begins at 08:26:24.343017\n",
            " 102/1875 [>.............................] - ETA: 15s - loss: 0.2799 - accuracy: 0.8922Training: batch 102 begins at 08:26:24.352112\n",
            "Training: batch 103 begins at 08:26:24.359295\n",
            "Training: batch 104 begins at 08:26:24.367381\n",
            "Training: batch 105 begins at 08:26:24.375879\n",
            "Training: batch 106 begins at 08:26:24.384079\n",
            "Training: batch 107 begins at 08:26:24.392324\n",
            " 108/1875 [>.............................] - ETA: 15s - loss: 0.2757 - accuracy: 0.8927Training: batch 108 begins at 08:26:24.402311\n",
            "Training: batch 109 begins at 08:26:24.410056\n",
            "Training: batch 110 begins at 08:26:24.418090\n",
            "Training: batch 111 begins at 08:26:24.426629\n",
            "Training: batch 112 begins at 08:26:24.434585\n",
            "Training: batch 113 begins at 08:26:24.443432\n",
            " 114/1875 [>.............................] - ETA: 14s - loss: 0.2797 - accuracy: 0.8920Training: batch 114 begins at 08:26:24.453344\n",
            "Training: batch 115 begins at 08:26:24.460654\n",
            "Training: batch 116 begins at 08:26:24.468389\n",
            "Training: batch 117 begins at 08:26:24.475566\n",
            "Training: batch 118 begins at 08:26:24.483308\n",
            "Training: batch 119 begins at 08:26:24.490847\n",
            "Training: batch 120 begins at 08:26:24.497453\n",
            " 121/1875 [>.............................] - ETA: 14s - loss: 0.2778 - accuracy: 0.8928Training: batch 121 begins at 08:26:24.508773\n",
            "Training: batch 122 begins at 08:26:24.516094\n",
            "Training: batch 123 begins at 08:26:24.523837\n",
            "Training: batch 124 begins at 08:26:24.530240\n",
            "Training: batch 125 begins at 08:26:24.537671\n",
            "Training: batch 126 begins at 08:26:24.544111\n",
            "Training: batch 127 begins at 08:26:24.551693\n",
            " 128/1875 [=>............................] - ETA: 14s - loss: 0.2802 - accuracy: 0.8928Training: batch 128 begins at 08:26:24.564890\n",
            "Training: batch 129 begins at 08:26:24.572762\n",
            "Training: batch 130 begins at 08:26:24.580848\n",
            "Training: batch 131 begins at 08:26:24.589020\n",
            "Training: batch 132 begins at 08:26:24.596271\n",
            "Training: batch 133 begins at 08:26:24.604517\n",
            " 134/1875 [=>............................] - ETA: 14s - loss: 0.2793 - accuracy: 0.8939Training: batch 134 begins at 08:26:24.615660\n",
            "Training: batch 135 begins at 08:26:24.624288\n",
            "Training: batch 136 begins at 08:26:24.632496\n",
            "Training: batch 137 begins at 08:26:24.640338\n",
            "Training: batch 138 begins at 08:26:24.647564\n",
            "Training: batch 139 begins at 08:26:24.655308\n",
            "Training: batch 140 begins at 08:26:24.662453\n",
            " 141/1875 [=>............................] - ETA: 14s - loss: 0.2805 - accuracy: 0.8943Training: batch 141 begins at 08:26:24.672241\n",
            "Training: batch 142 begins at 08:26:24.680028\n",
            "Training: batch 143 begins at 08:26:24.688325\n",
            "Training: batch 144 begins at 08:26:24.695386\n",
            "Training: batch 145 begins at 08:26:24.703142\n",
            "Training: batch 146 begins at 08:26:24.710788\n",
            "Training: batch 147 begins at 08:26:24.717301\n",
            " 148/1875 [=>............................] - ETA: 14s - loss: 0.2794 - accuracy: 0.8946Training: batch 148 begins at 08:26:24.727162\n",
            "Training: batch 149 begins at 08:26:24.735348\n",
            "Training: batch 150 begins at 08:26:24.742433\n",
            "Training: batch 151 begins at 08:26:24.748964\n",
            "Training: batch 152 begins at 08:26:24.756497\n",
            "Training: batch 153 begins at 08:26:24.763356\n",
            "Training: batch 154 begins at 08:26:24.772365\n",
            " 155/1875 [=>............................] - ETA: 14s - loss: 0.2769 - accuracy: 0.8958Training: batch 155 begins at 08:26:24.781333\n",
            "Training: batch 156 begins at 08:26:24.792076\n",
            "Training: batch 157 begins at 08:26:24.798717\n",
            "Training: batch 158 begins at 08:26:24.805024\n",
            "Training: batch 159 begins at 08:26:24.812547\n",
            "Training: batch 160 begins at 08:26:24.818796\n",
            "Training: batch 161 begins at 08:26:24.827943\n",
            " 162/1875 [=>............................] - ETA: 14s - loss: 0.2750 - accuracy: 0.8962Training: batch 162 begins at 08:26:24.837969\n",
            "Training: batch 163 begins at 08:26:24.846965\n",
            "Training: batch 164 begins at 08:26:24.854540\n",
            "Training: batch 165 begins at 08:26:24.863879\n",
            "Training: batch 166 begins at 08:26:24.875612\n",
            "Training: batch 167 begins at 08:26:24.883082\n",
            " 168/1875 [=>............................] - ETA: 14s - loss: 0.2771 - accuracy: 0.8949Training: batch 168 begins at 08:26:24.893160\n",
            "Training: batch 169 begins at 08:26:24.901620\n",
            "Training: batch 170 begins at 08:26:24.911484\n",
            "Training: batch 171 begins at 08:26:24.919492\n",
            "Training: batch 172 begins at 08:26:24.928005\n",
            "Training: batch 173 begins at 08:26:24.935895\n",
            " 174/1875 [=>............................] - ETA: 14s - loss: 0.2768 - accuracy: 0.8946Training: batch 174 begins at 08:26:24.946334\n",
            "Training: batch 175 begins at 08:26:24.953331\n",
            "Training: batch 176 begins at 08:26:24.961322\n",
            "Training: batch 177 begins at 08:26:24.970723\n",
            "Training: batch 178 begins at 08:26:24.980182\n",
            "Training: batch 179 begins at 08:26:24.988728\n",
            " 180/1875 [=>............................] - ETA: 14s - loss: 0.2747 - accuracy: 0.8953Training: batch 180 begins at 08:26:25.001442\n",
            "Training: batch 181 begins at 08:26:25.012299\n",
            "Training: batch 182 begins at 08:26:25.021267\n",
            "Training: batch 183 begins at 08:26:25.029057\n",
            "Training: batch 184 begins at 08:26:25.036379\n",
            "Training: batch 185 begins at 08:26:25.044401\n",
            " 186/1875 [=>............................] - ETA: 14s - loss: 0.2751 - accuracy: 0.8955Training: batch 186 begins at 08:26:25.053877\n",
            "Training: batch 187 begins at 08:26:25.063179\n",
            "Training: batch 188 begins at 08:26:25.069933\n",
            "Training: batch 189 begins at 08:26:25.079532\n",
            "Training: batch 190 begins at 08:26:25.089714\n",
            "Training: batch 191 begins at 08:26:25.097986\n",
            " 192/1875 [==>...........................] - ETA: 14s - loss: 0.2749 - accuracy: 0.8953Training: batch 192 begins at 08:26:25.110909\n",
            "Training: batch 193 begins at 08:26:25.119423\n",
            "Training: batch 194 begins at 08:26:25.129517\n",
            "Training: batch 195 begins at 08:26:25.140407\n",
            "Training: batch 196 begins at 08:26:25.149415\n",
            " 197/1875 [==>...........................] - ETA: 14s - loss: 0.2741 - accuracy: 0.8959Training: batch 197 begins at 08:26:25.162096\n",
            "Training: batch 198 begins at 08:26:25.170235\n",
            "Training: batch 199 begins at 08:26:25.178166\n",
            "Training: batch 200 begins at 08:26:25.186212\n",
            "Training: batch 201 begins at 08:26:25.194227\n",
            "Training: batch 202 begins at 08:26:25.199987\n",
            "Training: batch 203 begins at 08:26:25.208924\n",
            " 204/1875 [==>...........................] - ETA: 14s - loss: 0.2700 - accuracy: 0.8972Training: batch 204 begins at 08:26:25.220658\n",
            "Training: batch 205 begins at 08:26:25.226588\n",
            "Training: batch 206 begins at 08:26:25.234863\n",
            "Training: batch 207 begins at 08:26:25.244688\n",
            "Training: batch 208 begins at 08:26:25.255302\n",
            "Training: batch 209 begins at 08:26:25.266573\n",
            " 210/1875 [==>...........................] - ETA: 14s - loss: 0.2665 - accuracy: 0.8987Training: batch 210 begins at 08:26:25.279668\n",
            "Training: batch 211 begins at 08:26:25.286164\n",
            "Training: batch 212 begins at 08:26:25.294433\n",
            "Training: batch 213 begins at 08:26:25.303369\n",
            "Training: batch 214 begins at 08:26:25.311101\n",
            "Training: batch 215 begins at 08:26:25.317328\n",
            "Training: batch 216 begins at 08:26:25.323528\n",
            " 217/1875 [==>...........................] - ETA: 14s - loss: 0.2632 - accuracy: 0.8993Training: batch 217 begins at 08:26:25.333618\n",
            "Training: batch 218 begins at 08:26:25.341362\n",
            "Training: batch 219 begins at 08:26:25.349571\n",
            "Training: batch 220 begins at 08:26:25.356966\n",
            "Training: batch 221 begins at 08:26:25.364386\n",
            "Training: batch 222 begins at 08:26:25.372709\n",
            " 223/1875 [==>...........................] - ETA: 14s - loss: 0.2613 - accuracy: 0.8997Training: batch 223 begins at 08:26:25.381005\n",
            "Training: batch 224 begins at 08:26:25.388861\n",
            "Training: batch 225 begins at 08:26:25.398505\n",
            "Training: batch 226 begins at 08:26:25.405811\n",
            "Training: batch 227 begins at 08:26:25.414498\n",
            "Training: batch 228 begins at 08:26:25.426859\n",
            " 229/1875 [==>...........................] - ETA: 14s - loss: 0.2627 - accuracy: 0.8997Training: batch 229 begins at 08:26:25.436522\n",
            "Training: batch 230 begins at 08:26:25.446773\n",
            "Training: batch 231 begins at 08:26:25.455259\n",
            "Training: batch 232 begins at 08:26:25.465915\n",
            "Training: batch 233 begins at 08:26:25.473821\n",
            "Training: batch 234 begins at 08:26:25.481504\n",
            " 235/1875 [==>...........................] - ETA: 14s - loss: 0.2658 - accuracy: 0.8993Training: batch 235 begins at 08:26:25.490911\n",
            "Training: batch 236 begins at 08:26:25.497043\n",
            "Training: batch 237 begins at 08:26:25.505011\n",
            "Training: batch 238 begins at 08:26:25.513862\n",
            "Training: batch 239 begins at 08:26:25.522688\n",
            "Training: batch 240 begins at 08:26:25.530777\n",
            "Training: batch 241 begins at 08:26:25.538316\n",
            " 242/1875 [==>...........................] - ETA: 13s - loss: 0.2648 - accuracy: 0.9002Training: batch 242 begins at 08:26:25.547642\n",
            "Training: batch 243 begins at 08:26:25.555543\n",
            "Training: batch 244 begins at 08:26:25.563661\n",
            "Training: batch 245 begins at 08:26:25.572444\n",
            "Training: batch 246 begins at 08:26:25.580728\n",
            "Training: batch 247 begins at 08:26:25.589015\n",
            " 248/1875 [==>...........................] - ETA: 13s - loss: 0.2636 - accuracy: 0.9002Training: batch 248 begins at 08:26:25.598345\n",
            "Training: batch 249 begins at 08:26:25.605888\n",
            "Training: batch 250 begins at 08:26:25.614513\n",
            "Training: batch 251 begins at 08:26:25.621663\n",
            "Training: batch 252 begins at 08:26:25.628624\n",
            "Training: batch 253 begins at 08:26:25.636361\n",
            "Training: batch 254 begins at 08:26:25.644037\n",
            " 255/1875 [===>..........................] - ETA: 13s - loss: 0.2626 - accuracy: 0.9012Training: batch 255 begins at 08:26:25.653044\n",
            "Training: batch 256 begins at 08:26:25.660404\n",
            "Training: batch 257 begins at 08:26:25.667436\n",
            "Training: batch 258 begins at 08:26:25.676446\n",
            "Training: batch 259 begins at 08:26:25.683710\n",
            "Training: batch 260 begins at 08:26:25.691582\n",
            "Training: batch 261 begins at 08:26:25.698755\n",
            " 262/1875 [===>..........................] - ETA: 13s - loss: 0.2654 - accuracy: 0.9003Training: batch 262 begins at 08:26:25.707943\n",
            "Training: batch 263 begins at 08:26:25.715333\n",
            "Training: batch 264 begins at 08:26:25.722646\n",
            "Training: batch 265 begins at 08:26:25.730502\n",
            "Training: batch 266 begins at 08:26:25.738812\n",
            "Training: batch 267 begins at 08:26:25.747480\n",
            "Training: batch 268 begins at 08:26:25.755439\n",
            " 269/1875 [===>..........................] - ETA: 13s - loss: 0.2643 - accuracy: 0.9010Training: batch 269 begins at 08:26:25.764871\n",
            "Training: batch 270 begins at 08:26:25.772973\n",
            "Training: batch 271 begins at 08:26:25.780724\n",
            "Training: batch 272 begins at 08:26:25.788443\n",
            "Training: batch 273 begins at 08:26:25.798973\n",
            "Training: batch 274 begins at 08:26:25.806702\n",
            " 275/1875 [===>..........................] - ETA: 13s - loss: 0.2642 - accuracy: 0.9013Training: batch 275 begins at 08:26:25.816031\n",
            "Training: batch 276 begins at 08:26:25.825458\n",
            "Training: batch 277 begins at 08:26:25.831806\n",
            "Training: batch 278 begins at 08:26:25.840226\n",
            "Training: batch 279 begins at 08:26:25.847021\n",
            "Training: batch 280 begins at 08:26:25.854493\n",
            "Training: batch 281 begins at 08:26:25.862120\n",
            " 282/1875 [===>..........................] - ETA: 13s - loss: 0.2628 - accuracy: 0.9018Training: batch 282 begins at 08:26:25.871175\n",
            "Training: batch 283 begins at 08:26:25.878480\n",
            "Training: batch 284 begins at 08:26:25.885674\n",
            "Training: batch 285 begins at 08:26:25.894796\n",
            "Training: batch 286 begins at 08:26:25.900533\n",
            "Training: batch 287 begins at 08:26:25.911240\n",
            " 288/1875 [===>..........................] - ETA: 13s - loss: 0.2610 - accuracy: 0.9021Training: batch 288 begins at 08:26:25.921935\n",
            "Training: batch 289 begins at 08:26:25.931523\n",
            "Training: batch 290 begins at 08:26:25.940567\n",
            "Training: batch 291 begins at 08:26:25.955932\n",
            "Training: batch 292 begins at 08:26:25.966779\n",
            " 293/1875 [===>..........................] - ETA: 13s - loss: 0.2595 - accuracy: 0.9029Training: batch 293 begins at 08:26:25.976505\n",
            "Training: batch 294 begins at 08:26:25.985366\n",
            "Training: batch 295 begins at 08:26:25.992500\n",
            "Training: batch 296 begins at 08:26:25.999015\n",
            "Training: batch 297 begins at 08:26:26.005616\n",
            "Training: batch 298 begins at 08:26:26.011625\n",
            "Training: batch 299 begins at 08:26:26.018097\n",
            " 300/1875 [===>..........................] - ETA: 13s - loss: 0.2589 - accuracy: 0.9031Training: batch 300 begins at 08:26:26.027400\n",
            "Training: batch 301 begins at 08:26:26.033954\n",
            "Training: batch 302 begins at 08:26:26.041125\n",
            "Training: batch 303 begins at 08:26:26.048805\n",
            "Training: batch 304 begins at 08:26:26.055395\n",
            "Training: batch 305 begins at 08:26:26.062814\n",
            "Training: batch 306 begins at 08:26:26.070386\n",
            " 307/1875 [===>..........................] - ETA: 13s - loss: 0.2595 - accuracy: 0.9028Training: batch 307 begins at 08:26:26.079526\n",
            "Training: batch 308 begins at 08:26:26.086596\n",
            "Training: batch 309 begins at 08:26:26.095300\n",
            "Training: batch 310 begins at 08:26:26.101904\n",
            "Training: batch 311 begins at 08:26:26.108160\n",
            "Training: batch 312 begins at 08:26:26.115502\n",
            "Training: batch 313 begins at 08:26:26.123312\n",
            " 314/1875 [====>.........................] - ETA: 13s - loss: 0.2586 - accuracy: 0.9030Training: batch 314 begins at 08:26:26.131870\n",
            "Training: batch 315 begins at 08:26:26.138723\n",
            "Training: batch 316 begins at 08:26:26.146428\n",
            "Training: batch 317 begins at 08:26:26.154355\n",
            "Training: batch 318 begins at 08:26:26.162394\n",
            "Training: batch 319 begins at 08:26:26.169180\n",
            "Training: batch 320 begins at 08:26:26.176138\n",
            " 321/1875 [====>.........................] - ETA: 13s - loss: 0.2591 - accuracy: 0.9031Training: batch 321 begins at 08:26:26.187250\n",
            "Training: batch 322 begins at 08:26:26.195189\n",
            "Training: batch 323 begins at 08:26:26.201739\n",
            "Training: batch 324 begins at 08:26:26.207697\n",
            "Training: batch 325 begins at 08:26:26.213820\n",
            "Training: batch 326 begins at 08:26:26.221047\n",
            "Training: batch 327 begins at 08:26:26.228645\n",
            " 328/1875 [====>.........................] - ETA: 12s - loss: 0.2581 - accuracy: 0.9035Training: batch 328 begins at 08:26:26.238648\n",
            "Training: batch 329 begins at 08:26:26.245410\n",
            "Training: batch 330 begins at 08:26:26.252837\n",
            "Training: batch 331 begins at 08:26:26.260749\n",
            "Training: batch 332 begins at 08:26:26.268404\n",
            "Training: batch 333 begins at 08:26:26.276450\n",
            "Training: batch 334 begins at 08:26:26.285103\n",
            " 335/1875 [====>.........................] - ETA: 12s - loss: 0.2570 - accuracy: 0.9035Training: batch 335 begins at 08:26:26.294793\n",
            "Training: batch 336 begins at 08:26:26.301374\n",
            "Training: batch 337 begins at 08:26:26.308376\n",
            "Training: batch 338 begins at 08:26:26.314849\n",
            "Training: batch 339 begins at 08:26:26.322521\n",
            "Training: batch 340 begins at 08:26:26.328760\n",
            "Training: batch 341 begins at 08:26:26.335073\n",
            "Training: batch 342 begins at 08:26:26.342131\n",
            " 343/1875 [====>.........................] - ETA: 12s - loss: 0.2567 - accuracy: 0.9034Training: batch 343 begins at 08:26:26.349330\n",
            "Training: batch 344 begins at 08:26:26.356117\n",
            "Training: batch 345 begins at 08:26:26.365709\n",
            "Training: batch 346 begins at 08:26:26.382227\n",
            "Training: batch 347 begins at 08:26:26.389228\n",
            "Training: batch 348 begins at 08:26:26.395501\n",
            " 349/1875 [====>.........................] - ETA: 12s - loss: 0.2595 - accuracy: 0.9028Training: batch 349 begins at 08:26:26.405465\n",
            "Training: batch 350 begins at 08:26:26.411670\n",
            "Training: batch 351 begins at 08:26:26.417472\n",
            "Training: batch 352 begins at 08:26:26.423784\n",
            "Training: batch 353 begins at 08:26:26.431524\n",
            "Training: batch 354 begins at 08:26:26.441464\n",
            "Training: batch 355 begins at 08:26:26.451794\n",
            " 356/1875 [====>.........................] - ETA: 12s - loss: 0.2587 - accuracy: 0.9034Training: batch 356 begins at 08:26:26.460609\n",
            "Training: batch 357 begins at 08:26:26.466627\n",
            "Training: batch 358 begins at 08:26:26.475452\n",
            "Training: batch 359 begins at 08:26:26.484772\n",
            "Training: batch 360 begins at 08:26:26.490790\n",
            "Training: batch 361 begins at 08:26:26.500387\n",
            " 362/1875 [====>.........................] - ETA: 12s - loss: 0.2590 - accuracy: 0.9035Training: batch 362 begins at 08:26:26.512901\n",
            "Training: batch 363 begins at 08:26:26.521584\n",
            "Training: batch 364 begins at 08:26:26.532817\n",
            "Training: batch 365 begins at 08:26:26.542792\n",
            "Training: batch 366 begins at 08:26:26.550863\n",
            "Training: batch 367 begins at 08:26:26.558276\n",
            " 368/1875 [====>.........................] - ETA: 12s - loss: 0.2583 - accuracy: 0.9038Training: batch 368 begins at 08:26:26.568468\n",
            "Training: batch 369 begins at 08:26:26.575845\n",
            "Training: batch 370 begins at 08:26:26.582331\n",
            "Training: batch 371 begins at 08:26:26.589940\n",
            "Training: batch 372 begins at 08:26:26.598422\n",
            "Training: batch 373 begins at 08:26:26.605296\n",
            "Training: batch 374 begins at 08:26:26.611713\n",
            " 375/1875 [=====>........................] - ETA: 12s - loss: 0.2572 - accuracy: 0.9040Training: batch 375 begins at 08:26:26.620429\n",
            "Training: batch 376 begins at 08:26:26.630347\n",
            "Training: batch 377 begins at 08:26:26.638422\n",
            "Training: batch 378 begins at 08:26:26.644796\n",
            "Training: batch 379 begins at 08:26:26.651891\n",
            "Training: batch 380 begins at 08:26:26.659116\n",
            "Training: batch 381 begins at 08:26:26.666668\n",
            " 382/1875 [=====>........................] - ETA: 12s - loss: 0.2571 - accuracy: 0.9043Training: batch 382 begins at 08:26:26.675812\n",
            "Training: batch 383 begins at 08:26:26.682297\n",
            "Training: batch 384 begins at 08:26:26.689443\n",
            "Training: batch 385 begins at 08:26:26.695702\n",
            "Training: batch 386 begins at 08:26:26.701429\n",
            "Training: batch 387 begins at 08:26:26.708213\n",
            "Training: batch 388 begins at 08:26:26.715932\n",
            "Training: batch 389 begins at 08:26:26.722930\n",
            " 390/1875 [=====>........................] - ETA: 12s - loss: 0.2568 - accuracy: 0.9045Training: batch 390 begins at 08:26:26.732267\n",
            "Training: batch 391 begins at 08:26:26.740359\n",
            "Training: batch 392 begins at 08:26:26.747273\n",
            "Training: batch 393 begins at 08:26:26.754002\n",
            "Training: batch 394 begins at 08:26:26.761263\n",
            "Training: batch 395 begins at 08:26:26.769047\n",
            "Training: batch 396 begins at 08:26:26.777134\n",
            " 397/1875 [=====>........................] - ETA: 12s - loss: 0.2579 - accuracy: 0.9040Training: batch 397 begins at 08:26:26.785419\n",
            "Training: batch 398 begins at 08:26:26.794551\n",
            "Training: batch 399 begins at 08:26:26.801980\n",
            "Training: batch 400 begins at 08:26:26.809057\n",
            "Training: batch 401 begins at 08:26:26.816728\n",
            "Training: batch 402 begins at 08:26:26.824031\n",
            "Training: batch 403 begins at 08:26:26.831370\n",
            " 404/1875 [=====>........................] - ETA: 12s - loss: 0.2578 - accuracy: 0.9043Training: batch 404 begins at 08:26:26.840200\n",
            "Training: batch 405 begins at 08:26:26.847632\n",
            "Training: batch 406 begins at 08:26:26.853720\n",
            "Training: batch 407 begins at 08:26:26.860720\n",
            "Training: batch 408 begins at 08:26:26.868357\n",
            "Training: batch 409 begins at 08:26:26.875851\n",
            "Training: batch 410 begins at 08:26:26.882799\n",
            " 411/1875 [=====>........................] - ETA: 12s - loss: 0.2575 - accuracy: 0.9041Training: batch 411 begins at 08:26:26.891413\n",
            "Training: batch 412 begins at 08:26:26.899197\n",
            "Training: batch 413 begins at 08:26:26.905696\n",
            "Training: batch 414 begins at 08:26:26.912444\n",
            "Training: batch 415 begins at 08:26:26.919810\n",
            "Training: batch 416 begins at 08:26:26.927317\n",
            "Training: batch 417 begins at 08:26:26.934978\n",
            " 418/1875 [=====>........................] - ETA: 12s - loss: 0.2574 - accuracy: 0.9041Training: batch 418 begins at 08:26:26.944899\n",
            "Training: batch 419 begins at 08:26:26.952674\n",
            "Training: batch 420 begins at 08:26:26.960032\n",
            "Training: batch 421 begins at 08:26:26.966880\n",
            "Training: batch 422 begins at 08:26:26.973866\n",
            "Training: batch 423 begins at 08:26:26.982050\n",
            "Training: batch 424 begins at 08:26:26.989293\n",
            " 425/1875 [=====>........................] - ETA: 11s - loss: 0.2565 - accuracy: 0.9046Training: batch 425 begins at 08:26:26.998639\n",
            "Training: batch 426 begins at 08:26:27.005045\n",
            "Training: batch 427 begins at 08:26:27.012749\n",
            "Training: batch 428 begins at 08:26:27.020239\n",
            "Training: batch 429 begins at 08:26:27.028352\n",
            "Training: batch 430 begins at 08:26:27.037098\n",
            "Training: batch 431 begins at 08:26:27.045409\n",
            " 432/1875 [=====>........................] - ETA: 11s - loss: 0.2563 - accuracy: 0.9045Training: batch 432 begins at 08:26:27.054903\n",
            "Training: batch 433 begins at 08:26:27.061299\n",
            "Training: batch 434 begins at 08:26:27.068753\n",
            "Training: batch 435 begins at 08:26:27.076473\n",
            "Training: batch 436 begins at 08:26:27.084188\n",
            "Training: batch 437 begins at 08:26:27.089740\n",
            "Training: batch 438 begins at 08:26:27.098584\n",
            " 439/1875 [======>.......................] - ETA: 11s - loss: 0.2560 - accuracy: 0.9048Training: batch 439 begins at 08:26:27.106442\n",
            "Training: batch 440 begins at 08:26:27.112311\n",
            "Training: batch 441 begins at 08:26:27.118666\n",
            "Training: batch 442 begins at 08:26:27.124499\n",
            "Training: batch 443 begins at 08:26:27.131304\n",
            "Training: batch 444 begins at 08:26:27.138942\n",
            "Training: batch 445 begins at 08:26:27.146574\n",
            "Training: batch 446 begins at 08:26:27.154319\n",
            " 447/1875 [======>.......................] - ETA: 11s - loss: 0.2555 - accuracy: 0.9049Training: batch 447 begins at 08:26:27.163767\n",
            "Training: batch 448 begins at 08:26:27.169760\n",
            "Training: batch 449 begins at 08:26:27.178118\n",
            "Training: batch 450 begins at 08:26:27.186505\n",
            "Training: batch 451 begins at 08:26:27.193439\n",
            "Training: batch 452 begins at 08:26:27.200289\n",
            "Training: batch 453 begins at 08:26:27.206613\n",
            " 454/1875 [======>.......................] - ETA: 11s - loss: 0.2565 - accuracy: 0.9046Training: batch 454 begins at 08:26:27.215648\n",
            "Training: batch 455 begins at 08:26:27.223027\n",
            "Training: batch 456 begins at 08:26:27.230488\n",
            "Training: batch 457 begins at 08:26:27.238171\n",
            "Training: batch 458 begins at 08:26:27.245469\n",
            "Training: batch 459 begins at 08:26:27.253380\n",
            "Training: batch 460 begins at 08:26:27.261067\n",
            " 461/1875 [======>.......................] - ETA: 11s - loss: 0.2566 - accuracy: 0.9045Training: batch 461 begins at 08:26:27.270474\n",
            "Training: batch 462 begins at 08:26:27.276776\n",
            "Training: batch 463 begins at 08:26:27.284413\n",
            "Training: batch 464 begins at 08:26:27.292734\n",
            "Training: batch 465 begins at 08:26:27.299420\n",
            "Training: batch 466 begins at 08:26:27.306590\n",
            "Training: batch 467 begins at 08:26:27.313530\n",
            " 468/1875 [======>.......................] - ETA: 11s - loss: 0.2571 - accuracy: 0.9045Training: batch 468 begins at 08:26:27.322262\n",
            "Training: batch 469 begins at 08:26:27.328998\n",
            "Training: batch 470 begins at 08:26:27.334928\n",
            "Training: batch 471 begins at 08:26:27.341543\n",
            "Training: batch 472 begins at 08:26:27.350402\n",
            "Training: batch 473 begins at 08:26:27.357623\n",
            "Training: batch 474 begins at 08:26:27.366020\n",
            " 475/1875 [======>.......................] - ETA: 11s - loss: 0.2577 - accuracy: 0.9042Training: batch 475 begins at 08:26:27.376251\n",
            "Training: batch 476 begins at 08:26:27.381891\n",
            "Training: batch 477 begins at 08:26:27.391689\n",
            "Training: batch 478 begins at 08:26:27.401937\n",
            "Training: batch 479 begins at 08:26:27.412810\n",
            "Training: batch 480 begins at 08:26:27.422804\n",
            " 481/1875 [======>.......................] - ETA: 11s - loss: 0.2586 - accuracy: 0.9040Training: batch 481 begins at 08:26:27.432763\n",
            "Training: batch 482 begins at 08:26:27.439369\n",
            "Training: batch 483 begins at 08:26:27.447001\n",
            "Training: batch 484 begins at 08:26:27.455206\n",
            "Training: batch 485 begins at 08:26:27.460995\n",
            "Training: batch 486 begins at 08:26:27.468557\n",
            "Training: batch 487 begins at 08:26:27.476946\n",
            " 488/1875 [======>.......................] - ETA: 11s - loss: 0.2595 - accuracy: 0.9035Training: batch 488 begins at 08:26:27.486016\n",
            "Training: batch 489 begins at 08:26:27.492264\n",
            "Training: batch 490 begins at 08:26:27.500014\n",
            "Training: batch 491 begins at 08:26:27.508362\n",
            "Training: batch 492 begins at 08:26:27.516097\n",
            "Training: batch 493 begins at 08:26:27.521872\n",
            "Training: batch 494 begins at 08:26:27.529813\n",
            " 495/1875 [======>.......................] - ETA: 11s - loss: 0.2601 - accuracy: 0.9032Training: batch 495 begins at 08:26:27.537885\n",
            "Training: batch 496 begins at 08:26:27.545202\n",
            "Training: batch 497 begins at 08:26:27.551072\n",
            "Training: batch 498 begins at 08:26:27.558703\n",
            "Training: batch 499 begins at 08:26:27.566405\n",
            "Training: batch 500 begins at 08:26:27.573243\n",
            "Training: batch 501 begins at 08:26:27.582469\n",
            " 502/1875 [=======>......................] - ETA: 11s - loss: 0.2596 - accuracy: 0.9035Training: batch 502 begins at 08:26:27.590534\n",
            "Training: batch 503 begins at 08:26:27.598197\n",
            "Training: batch 504 begins at 08:26:27.605711\n",
            "Training: batch 505 begins at 08:26:27.613730\n",
            "Training: batch 506 begins at 08:26:27.619563\n",
            "Training: batch 507 begins at 08:26:27.626557\n",
            "Training: batch 508 begins at 08:26:27.633564\n",
            " 509/1875 [=======>......................] - ETA: 11s - loss: 0.2591 - accuracy: 0.9035Training: batch 509 begins at 08:26:27.646349\n",
            "Training: batch 510 begins at 08:26:27.660172\n",
            "Training: batch 511 begins at 08:26:27.674484\n",
            "Training: batch 512 begins at 08:26:27.681802\n",
            "Training: batch 513 begins at 08:26:27.689785\n",
            " 514/1875 [=======>......................] - ETA: 11s - loss: 0.2592 - accuracy: 0.9030Training: batch 514 begins at 08:26:27.699170\n",
            "Training: batch 515 begins at 08:26:27.706140\n",
            "Training: batch 516 begins at 08:26:27.714532\n",
            "Training: batch 517 begins at 08:26:27.723322\n",
            "Training: batch 518 begins at 08:26:27.730850\n",
            "Training: batch 519 begins at 08:26:27.739412\n",
            " 520/1875 [=======>......................] - ETA: 11s - loss: 0.2583 - accuracy: 0.9034Training: batch 520 begins at 08:26:27.750652\n",
            "Training: batch 521 begins at 08:26:27.758720\n",
            "Training: batch 522 begins at 08:26:27.767093\n",
            "Training: batch 523 begins at 08:26:27.775500\n",
            "Training: batch 524 begins at 08:26:27.782960\n",
            "Training: batch 525 begins at 08:26:27.791921\n",
            " 526/1875 [=======>......................] - ETA: 11s - loss: 0.2590 - accuracy: 0.9033Training: batch 526 begins at 08:26:27.802589\n",
            "Training: batch 527 begins at 08:26:27.810557\n",
            "Training: batch 528 begins at 08:26:27.818473\n",
            "Training: batch 529 begins at 08:26:27.826127\n",
            "Training: batch 530 begins at 08:26:27.832957\n",
            "Training: batch 531 begins at 08:26:27.840957\n",
            "Training: batch 532 begins at 08:26:27.848056\n",
            " 533/1875 [=======>......................] - ETA: 11s - loss: 0.2587 - accuracy: 0.9033Training: batch 533 begins at 08:26:27.857486\n",
            "Training: batch 534 begins at 08:26:27.866052\n",
            "Training: batch 535 begins at 08:26:27.873570\n",
            "Training: batch 536 begins at 08:26:27.880459\n",
            "Training: batch 537 begins at 08:26:27.888946\n",
            "Training: batch 538 begins at 08:26:27.896195\n",
            "Training: batch 539 begins at 08:26:27.903015\n",
            " 540/1875 [=======>......................] - ETA: 10s - loss: 0.2580 - accuracy: 0.9037Training: batch 540 begins at 08:26:27.911891\n",
            "Training: batch 541 begins at 08:26:27.919853\n",
            "Training: batch 542 begins at 08:26:27.927298\n",
            "Training: batch 543 begins at 08:26:27.934690\n",
            "Training: batch 544 begins at 08:26:27.941902\n",
            "Training: batch 545 begins at 08:26:27.948421\n",
            "Training: batch 546 begins at 08:26:27.956111\n",
            " 547/1875 [=======>......................] - ETA: 10s - loss: 0.2569 - accuracy: 0.9040Training: batch 547 begins at 08:26:27.965512\n",
            "Training: batch 548 begins at 08:26:27.973130\n",
            "Training: batch 549 begins at 08:26:27.979794\n",
            "Training: batch 550 begins at 08:26:27.986955\n",
            "Training: batch 551 begins at 08:26:27.993770\n",
            "Training: batch 552 begins at 08:26:28.000800\n",
            "Training: batch 553 begins at 08:26:28.008868\n",
            " 554/1875 [=======>......................] - ETA: 10s - loss: 0.2573 - accuracy: 0.9040Training: batch 554 begins at 08:26:28.020745\n",
            "Training: batch 555 begins at 08:26:28.028890\n",
            "Training: batch 556 begins at 08:26:28.036927\n",
            "Training: batch 557 begins at 08:26:28.045067\n",
            "Training: batch 558 begins at 08:26:28.052255\n",
            "Training: batch 559 begins at 08:26:28.058852\n",
            "Training: batch 560 begins at 08:26:28.066641\n",
            " 561/1875 [=======>......................] - ETA: 10s - loss: 0.2575 - accuracy: 0.9040Training: batch 561 begins at 08:26:28.075961\n",
            "Training: batch 562 begins at 08:26:28.084536\n",
            "Training: batch 563 begins at 08:26:28.091498\n",
            "Training: batch 564 begins at 08:26:28.098980\n",
            "Training: batch 565 begins at 08:26:28.105649\n",
            "Training: batch 566 begins at 08:26:28.113484\n",
            "Training: batch 567 begins at 08:26:28.120438\n",
            " 568/1875 [========>.....................] - ETA: 10s - loss: 0.2571 - accuracy: 0.9042Training: batch 568 begins at 08:26:28.129903\n",
            "Training: batch 569 begins at 08:26:28.137476\n",
            "Training: batch 570 begins at 08:26:28.144514\n",
            "Training: batch 571 begins at 08:26:28.151695\n",
            "Training: batch 572 begins at 08:26:28.159444\n",
            "Training: batch 573 begins at 08:26:28.167012\n",
            "Training: batch 574 begins at 08:26:28.174725\n",
            " 575/1875 [========>.....................] - ETA: 10s - loss: 0.2567 - accuracy: 0.9044Training: batch 575 begins at 08:26:28.184261\n",
            "Training: batch 576 begins at 08:26:28.191059\n",
            "Training: batch 577 begins at 08:26:28.198106\n",
            "Training: batch 578 begins at 08:26:28.204915\n",
            "Training: batch 579 begins at 08:26:28.212071\n",
            "Training: batch 580 begins at 08:26:28.219832\n",
            "Training: batch 581 begins at 08:26:28.226464\n",
            " 582/1875 [========>.....................] - ETA: 10s - loss: 0.2561 - accuracy: 0.9048Training: batch 582 begins at 08:26:28.235404\n",
            "Training: batch 583 begins at 08:26:28.242457\n",
            "Training: batch 584 begins at 08:26:28.249486\n",
            "Training: batch 585 begins at 08:26:28.259765\n",
            "Training: batch 586 begins at 08:26:28.265688\n",
            "Training: batch 587 begins at 08:26:28.272653\n",
            "Training: batch 588 begins at 08:26:28.282357\n",
            " 589/1875 [========>.....................] - ETA: 10s - loss: 0.2559 - accuracy: 0.9046Training: batch 589 begins at 08:26:28.289953\n",
            "Training: batch 590 begins at 08:26:28.298329\n",
            "Training: batch 591 begins at 08:26:28.304761\n",
            "Training: batch 592 begins at 08:26:28.311551\n",
            "Training: batch 593 begins at 08:26:28.321898\n",
            "Training: batch 594 begins at 08:26:28.329434\n",
            "Training: batch 595 begins at 08:26:28.337639\n",
            " 596/1875 [========>.....................] - ETA: 10s - loss: 0.2563 - accuracy: 0.9045Training: batch 596 begins at 08:26:28.347578\n",
            "Training: batch 597 begins at 08:26:28.353916\n",
            "Training: batch 598 begins at 08:26:28.362038\n",
            "Training: batch 599 begins at 08:26:28.369190\n",
            "Training: batch 600 begins at 08:26:28.376981\n",
            "Training: batch 601 begins at 08:26:28.386416\n",
            "Training: batch 602 begins at 08:26:28.394545\n",
            " 603/1875 [========>.....................] - ETA: 10s - loss: 0.2562 - accuracy: 0.9045Training: batch 603 begins at 08:26:28.403267\n",
            "Training: batch 604 begins at 08:26:28.410994\n",
            "Training: batch 605 begins at 08:26:28.418881\n",
            "Training: batch 606 begins at 08:26:28.425775\n",
            "Training: batch 607 begins at 08:26:28.432743\n",
            "Training: batch 608 begins at 08:26:28.446578\n",
            " 609/1875 [========>.....................] - ETA: 10s - loss: 0.2554 - accuracy: 0.9048Training: batch 609 begins at 08:26:28.462445\n",
            "Training: batch 610 begins at 08:26:28.469651\n",
            "Training: batch 611 begins at 08:26:28.477232\n",
            "Training: batch 612 begins at 08:26:28.484048\n",
            "Training: batch 613 begins at 08:26:28.492958\n",
            "Training: batch 614 begins at 08:26:28.503136\n",
            "Training: batch 615 begins at 08:26:28.509177\n",
            " 616/1875 [========>.....................] - ETA: 10s - loss: 0.2556 - accuracy: 0.9045Training: batch 616 begins at 08:26:28.518357\n",
            "Training: batch 617 begins at 08:26:28.524180\n",
            "Training: batch 618 begins at 08:26:28.531060\n",
            "Training: batch 619 begins at 08:26:28.538421\n",
            "Training: batch 620 begins at 08:26:28.546411\n",
            "Training: batch 621 begins at 08:26:28.555267\n",
            "Training: batch 622 begins at 08:26:28.562698\n",
            " 623/1875 [========>.....................] - ETA: 10s - loss: 0.2552 - accuracy: 0.9045Training: batch 623 begins at 08:26:28.575932\n",
            "Training: batch 624 begins at 08:26:28.585082\n",
            "Training: batch 625 begins at 08:26:28.593980\n",
            "Training: batch 626 begins at 08:26:28.602832\n",
            "Training: batch 627 begins at 08:26:28.612262\n",
            "Training: batch 628 begins at 08:26:28.621163\n",
            " 629/1875 [=========>....................] - ETA: 10s - loss: 0.2555 - accuracy: 0.9042Training: batch 629 begins at 08:26:28.628535\n",
            "Training: batch 630 begins at 08:26:28.635681\n",
            "Training: batch 631 begins at 08:26:28.643159\n",
            "Training: batch 632 begins at 08:26:28.652015\n",
            "Training: batch 633 begins at 08:26:28.658953\n",
            "Training: batch 634 begins at 08:26:28.670043\n",
            " 635/1875 [=========>....................] - ETA: 10s - loss: 0.2554 - accuracy: 0.9042Training: batch 635 begins at 08:26:28.681497\n",
            "Training: batch 636 begins at 08:26:28.691593\n",
            "Training: batch 637 begins at 08:26:28.698996\n",
            "Training: batch 638 begins at 08:26:28.706458\n",
            "Training: batch 639 begins at 08:26:28.712969\n",
            "Training: batch 640 begins at 08:26:28.722559\n",
            " 641/1875 [=========>....................] - ETA: 10s - loss: 0.2550 - accuracy: 0.9044Training: batch 641 begins at 08:26:28.734083\n",
            "Training: batch 642 begins at 08:26:28.744649\n",
            "Training: batch 643 begins at 08:26:28.751518\n",
            "Training: batch 644 begins at 08:26:28.763067\n",
            "Training: batch 645 begins at 08:26:28.770513\n",
            "Training: batch 646 begins at 08:26:28.779713\n",
            " 647/1875 [=========>....................] - ETA: 10s - loss: 0.2550 - accuracy: 0.9044Training: batch 647 begins at 08:26:28.795756\n",
            "Training: batch 648 begins at 08:26:28.805957\n",
            "Training: batch 649 begins at 08:26:28.812374\n",
            "Training: batch 650 begins at 08:26:28.818502\n",
            "Training: batch 651 begins at 08:26:28.824545\n",
            "Training: batch 652 begins at 08:26:28.830650\n",
            "Training: batch 653 begins at 08:26:28.836638\n",
            " 654/1875 [=========>....................] - ETA: 10s - loss: 0.2551 - accuracy: 0.9042Training: batch 654 begins at 08:26:28.844240\n",
            "Training: batch 655 begins at 08:26:28.849965\n",
            "Training: batch 656 begins at 08:26:28.857693\n",
            "Training: batch 657 begins at 08:26:28.864098\n",
            "Training: batch 658 begins at 08:26:28.871274\n",
            "Training: batch 659 begins at 08:26:28.877904\n",
            "Training: batch 660 begins at 08:26:28.885014\n",
            " 661/1875 [=========>....................] - ETA: 9s - loss: 0.2558 - accuracy: 0.9041 Training: batch 661 begins at 08:26:28.897879\n",
            "Training: batch 662 begins at 08:26:28.903920\n",
            "Training: batch 663 begins at 08:26:28.910794\n",
            "Training: batch 664 begins at 08:26:28.918844\n",
            "Training: batch 665 begins at 08:26:28.926825\n",
            "Training: batch 666 begins at 08:26:28.933364\n",
            "Training: batch 667 begins at 08:26:28.940443\n",
            " 668/1875 [=========>....................] - ETA: 9s - loss: 0.2554 - accuracy: 0.9040Training: batch 668 begins at 08:26:28.949648\n",
            "Training: batch 669 begins at 08:26:28.957180\n",
            "Training: batch 670 begins at 08:26:28.964911\n",
            "Training: batch 671 begins at 08:26:28.972173\n",
            "Training: batch 672 begins at 08:26:28.980223\n",
            "Training: batch 673 begins at 08:26:28.989087\n",
            "Training: batch 674 begins at 08:26:28.998050\n",
            " 675/1875 [=========>....................] - ETA: 9s - loss: 0.2549 - accuracy: 0.9043Training: batch 675 begins at 08:26:29.009586\n",
            "Training: batch 676 begins at 08:26:29.017884\n",
            "Training: batch 677 begins at 08:26:29.025739\n",
            "Training: batch 678 begins at 08:26:29.034026\n",
            "Training: batch 679 begins at 08:26:29.041226\n",
            "Training: batch 680 begins at 08:26:29.048067\n",
            " 681/1875 [=========>....................] - ETA: 9s - loss: 0.2558 - accuracy: 0.9041Training: batch 681 begins at 08:26:29.065115\n",
            "Training: batch 682 begins at 08:26:29.073670\n",
            "Training: batch 683 begins at 08:26:29.081100\n",
            "Training: batch 684 begins at 08:26:29.090783\n",
            "Training: batch 685 begins at 08:26:29.101031\n",
            "Training: batch 686 begins at 08:26:29.108865\n",
            " 687/1875 [=========>....................] - ETA: 9s - loss: 0.2559 - accuracy: 0.9040Training: batch 687 begins at 08:26:29.118322\n",
            "Training: batch 688 begins at 08:26:29.129689\n",
            "Training: batch 689 begins at 08:26:29.136172\n",
            "Training: batch 690 begins at 08:26:29.142031\n",
            "Training: batch 691 begins at 08:26:29.147987\n",
            "Training: batch 692 begins at 08:26:29.159293\n",
            " 693/1875 [==========>...................] - ETA: 9s - loss: 0.2560 - accuracy: 0.9040Training: batch 693 begins at 08:26:29.172478\n",
            "Training: batch 694 begins at 08:26:29.183706\n",
            "Training: batch 695 begins at 08:26:29.191432\n",
            "Training: batch 696 begins at 08:26:29.199532\n",
            "Training: batch 697 begins at 08:26:29.210269\n",
            " 698/1875 [==========>...................] - ETA: 9s - loss: 0.2565 - accuracy: 0.9038Training: batch 698 begins at 08:26:29.224098\n",
            "Training: batch 699 begins at 08:26:29.235922\n",
            "Training: batch 700 begins at 08:26:29.243603\n",
            "Training: batch 701 begins at 08:26:29.250661\n",
            "Training: batch 702 begins at 08:26:29.257391\n",
            "Training: batch 703 begins at 08:26:29.264396\n",
            " 704/1875 [==========>...................] - ETA: 9s - loss: 0.2562 - accuracy: 0.9037Training: batch 704 begins at 08:26:29.277256\n",
            "Training: batch 705 begins at 08:26:29.284030\n",
            "Training: batch 706 begins at 08:26:29.291170\n",
            "Training: batch 707 begins at 08:26:29.298910\n",
            "Training: batch 708 begins at 08:26:29.305970\n",
            "Training: batch 709 begins at 08:26:29.312855\n",
            "Training: batch 710 begins at 08:26:29.319724\n",
            " 711/1875 [==========>...................] - ETA: 9s - loss: 0.2559 - accuracy: 0.9040Training: batch 711 begins at 08:26:29.329466\n",
            "Training: batch 712 begins at 08:26:29.337044\n",
            "Training: batch 713 begins at 08:26:29.343796\n",
            "Training: batch 714 begins at 08:26:29.351436\n",
            "Training: batch 715 begins at 08:26:29.361205\n",
            "Training: batch 716 begins at 08:26:29.371560\n",
            " 717/1875 [==========>...................] - ETA: 9s - loss: 0.2557 - accuracy: 0.9042Training: batch 717 begins at 08:26:29.382629\n",
            "Training: batch 718 begins at 08:26:29.393286\n",
            "Training: batch 719 begins at 08:26:29.399792\n",
            "Training: batch 720 begins at 08:26:29.409781\n",
            "Training: batch 721 begins at 08:26:29.416604\n",
            "Training: batch 722 begins at 08:26:29.424044\n",
            "Training: batch 723 begins at 08:26:29.429384\n",
            " 724/1875 [==========>...................] - ETA: 9s - loss: 0.2553 - accuracy: 0.9043Training: batch 724 begins at 08:26:29.440310\n",
            "Training: batch 725 begins at 08:26:29.450824\n",
            "Training: batch 726 begins at 08:26:29.458135\n",
            "Training: batch 727 begins at 08:26:29.464114\n",
            "Training: batch 728 begins at 08:26:29.469749\n",
            "Training: batch 729 begins at 08:26:29.475935\n",
            "Training: batch 730 begins at 08:26:29.482538\n",
            " 731/1875 [==========>...................] - ETA: 9s - loss: 0.2555 - accuracy: 0.9042Training: batch 731 begins at 08:26:29.493281\n",
            "Training: batch 732 begins at 08:26:29.499134\n",
            "Training: batch 733 begins at 08:26:29.506811\n",
            "Training: batch 734 begins at 08:26:29.514995\n",
            "Training: batch 735 begins at 08:26:29.523515\n",
            "Training: batch 736 begins at 08:26:29.530591\n",
            " 737/1875 [==========>...................] - ETA: 9s - loss: 0.2554 - accuracy: 0.9043Training: batch 737 begins at 08:26:29.544622\n",
            "Training: batch 738 begins at 08:26:29.550617\n",
            "Training: batch 739 begins at 08:26:29.557133\n",
            "Training: batch 740 begins at 08:26:29.564308\n",
            "Training: batch 741 begins at 08:26:29.570741\n",
            "Training: batch 742 begins at 08:26:29.578240\n",
            "Training: batch 743 begins at 08:26:29.585679\n",
            "Training: batch 744 begins at 08:26:29.592325\n",
            " 745/1875 [==========>...................] - ETA: 9s - loss: 0.2552 - accuracy: 0.9044Training: batch 745 begins at 08:26:29.601585\n",
            "Training: batch 746 begins at 08:26:29.608245\n",
            "Training: batch 747 begins at 08:26:29.615463\n",
            "Training: batch 748 begins at 08:26:29.622246\n",
            "Training: batch 749 begins at 08:26:29.629363\n",
            "Training: batch 750 begins at 08:26:29.637182\n",
            "Training: batch 751 begins at 08:26:29.644450\n",
            " 752/1875 [===========>..................] - ETA: 9s - loss: 0.2566 - accuracy: 0.9041Training: batch 752 begins at 08:26:29.655136\n",
            "Training: batch 753 begins at 08:26:29.661436\n",
            "Training: batch 754 begins at 08:26:29.667263\n",
            "Training: batch 755 begins at 08:26:29.672932\n",
            "Training: batch 756 begins at 08:26:29.678642\n",
            "Training: batch 757 begins at 08:26:29.684561\n",
            "Training: batch 758 begins at 08:26:29.690417\n",
            "Training: batch 759 begins at 08:26:29.696188\n",
            " 760/1875 [===========>..................] - ETA: 9s - loss: 0.2569 - accuracy: 0.9039Training: batch 760 begins at 08:26:29.704216\n",
            "Training: batch 761 begins at 08:26:29.709834\n",
            "Training: batch 762 begins at 08:26:29.717350\n",
            "Training: batch 763 begins at 08:26:29.723253\n",
            "Training: batch 764 begins at 08:26:29.730142\n",
            "Training: batch 765 begins at 08:26:29.736508\n",
            "Training: batch 766 begins at 08:26:29.744047\n",
            "Training: batch 767 begins at 08:26:29.750558\n",
            " 768/1875 [===========>..................] - ETA: 9s - loss: 0.2571 - accuracy: 0.9038Training: batch 768 begins at 08:26:29.759758\n",
            "Training: batch 769 begins at 08:26:29.766437\n",
            "Training: batch 770 begins at 08:26:29.773663\n",
            "Training: batch 771 begins at 08:26:29.781113\n",
            "Training: batch 772 begins at 08:26:29.790210\n",
            "Training: batch 773 begins at 08:26:29.798953\n",
            "Training: batch 774 begins at 08:26:29.806722\n",
            " 775/1875 [===========>..................] - ETA: 8s - loss: 0.2564 - accuracy: 0.9039Training: batch 775 begins at 08:26:29.816535\n",
            "Training: batch 776 begins at 08:26:29.824417\n",
            "Training: batch 777 begins at 08:26:29.831843\n",
            "Training: batch 778 begins at 08:26:29.839603\n",
            "Training: batch 779 begins at 08:26:29.846557\n",
            "Training: batch 780 begins at 08:26:29.853802\n",
            "Training: batch 781 begins at 08:26:29.861402\n",
            " 782/1875 [===========>..................] - ETA: 8s - loss: 0.2560 - accuracy: 0.9040Training: batch 782 begins at 08:26:29.869739\n",
            "Training: batch 783 begins at 08:26:29.876314\n",
            "Training: batch 784 begins at 08:26:29.882551\n",
            "Training: batch 785 begins at 08:26:29.888888\n",
            "Training: batch 786 begins at 08:26:29.900176\n",
            "Training: batch 787 begins at 08:26:29.911808\n",
            " 788/1875 [===========>..................] - ETA: 8s - loss: 0.2561 - accuracy: 0.9039Training: batch 788 begins at 08:26:29.924693\n",
            "Training: batch 789 begins at 08:26:29.932620\n",
            "Training: batch 790 begins at 08:26:29.941003\n",
            "Training: batch 791 begins at 08:26:29.947419\n",
            "Training: batch 792 begins at 08:26:29.956687\n",
            "Training: batch 793 begins at 08:26:29.964407\n",
            " 794/1875 [===========>..................] - ETA: 8s - loss: 0.2560 - accuracy: 0.9039Training: batch 794 begins at 08:26:29.976534\n",
            "Training: batch 795 begins at 08:26:29.984578\n",
            "Training: batch 796 begins at 08:26:29.992567\n",
            "Training: batch 797 begins at 08:26:30.000254\n",
            "Training: batch 798 begins at 08:26:30.010581\n",
            "Training: batch 799 begins at 08:26:30.019755\n",
            " 800/1875 [===========>..................] - ETA: 8s - loss: 0.2559 - accuracy: 0.9039Training: batch 800 begins at 08:26:30.031310\n",
            "Training: batch 801 begins at 08:26:30.039850\n",
            "Training: batch 802 begins at 08:26:30.048844\n",
            "Training: batch 803 begins at 08:26:30.056747\n",
            "Training: batch 804 begins at 08:26:30.065322\n",
            "Training: batch 805 begins at 08:26:30.075049\n",
            " 806/1875 [===========>..................] - ETA: 8s - loss: 0.2554 - accuracy: 0.9041Training: batch 806 begins at 08:26:30.085126\n",
            "Training: batch 807 begins at 08:26:30.092679\n",
            "Training: batch 808 begins at 08:26:30.098712\n",
            "Training: batch 809 begins at 08:26:30.105891\n",
            "Training: batch 810 begins at 08:26:30.113952\n",
            "Training: batch 811 begins at 08:26:30.121635\n",
            "Training: batch 812 begins at 08:26:30.128743\n",
            " 813/1875 [============>.................] - ETA: 8s - loss: 0.2551 - accuracy: 0.9042Training: batch 813 begins at 08:26:30.137624\n",
            "Training: batch 814 begins at 08:26:30.145693\n",
            "Training: batch 815 begins at 08:26:30.152770\n",
            "Training: batch 816 begins at 08:26:30.160128\n",
            "Training: batch 817 begins at 08:26:30.168692\n",
            "Training: batch 818 begins at 08:26:30.176188\n",
            "Training: batch 819 begins at 08:26:30.182829\n",
            " 820/1875 [============>.................] - ETA: 8s - loss: 0.2557 - accuracy: 0.9040Training: batch 820 begins at 08:26:30.193202\n",
            "Training: batch 821 begins at 08:26:30.203049\n",
            "Training: batch 822 begins at 08:26:30.210415\n",
            "Training: batch 823 begins at 08:26:30.218045\n",
            "Training: batch 824 begins at 08:26:30.226825\n",
            "Training: batch 825 begins at 08:26:30.235973\n",
            " 826/1875 [============>.................] - ETA: 8s - loss: 0.2556 - accuracy: 0.9042Training: batch 826 begins at 08:26:30.247112\n",
            "Training: batch 827 begins at 08:26:30.257659\n",
            "Training: batch 828 begins at 08:26:30.266199\n",
            "Training: batch 829 begins at 08:26:30.274650\n",
            "Training: batch 830 begins at 08:26:30.281893\n",
            "Training: batch 831 begins at 08:26:30.289263\n",
            " 832/1875 [============>.................] - ETA: 8s - loss: 0.2551 - accuracy: 0.9043Training: batch 832 begins at 08:26:30.299521\n",
            "Training: batch 833 begins at 08:26:30.306795\n",
            "Training: batch 834 begins at 08:26:30.316205\n",
            "Training: batch 835 begins at 08:26:30.323976\n",
            "Training: batch 836 begins at 08:26:30.331565\n",
            "Training: batch 837 begins at 08:26:30.339672\n",
            " 838/1875 [============>.................] - ETA: 8s - loss: 0.2551 - accuracy: 0.9045Training: batch 838 begins at 08:26:30.348441\n",
            "Training: batch 839 begins at 08:26:30.355249\n",
            "Training: batch 840 begins at 08:26:30.362719\n",
            "Training: batch 841 begins at 08:26:30.369813\n",
            "Training: batch 842 begins at 08:26:30.377666\n",
            "Training: batch 843 begins at 08:26:30.384139\n",
            "Training: batch 844 begins at 08:26:30.390196\n",
            " 845/1875 [============>.................] - ETA: 8s - loss: 0.2551 - accuracy: 0.9044Training: batch 845 begins at 08:26:30.399633\n",
            "Training: batch 846 begins at 08:26:30.407280\n",
            "Training: batch 847 begins at 08:26:30.413954\n",
            "Training: batch 848 begins at 08:26:30.424666\n",
            "Training: batch 849 begins at 08:26:30.431837\n",
            "Training: batch 850 begins at 08:26:30.440481\n",
            "Training: batch 851 begins at 08:26:30.446832\n",
            " 852/1875 [============>.................] - ETA: 8s - loss: 0.2542 - accuracy: 0.9047Training: batch 852 begins at 08:26:30.456938\n",
            "Training: batch 853 begins at 08:26:30.466779\n",
            "Training: batch 854 begins at 08:26:30.476054\n",
            "Training: batch 855 begins at 08:26:30.481984\n",
            "Training: batch 856 begins at 08:26:30.489996\n",
            "Training: batch 857 begins at 08:26:30.500069\n",
            " 858/1875 [============>.................] - ETA: 8s - loss: 0.2542 - accuracy: 0.9046Training: batch 858 begins at 08:26:30.514268\n",
            "Training: batch 859 begins at 08:26:30.526307\n",
            "Training: batch 860 begins at 08:26:30.534390\n",
            "Training: batch 861 begins at 08:26:30.542440\n",
            "Training: batch 862 begins at 08:26:30.550958\n",
            "Training: batch 863 begins at 08:26:30.557769\n",
            " 864/1875 [============>.................] - ETA: 8s - loss: 0.2540 - accuracy: 0.9048Training: batch 864 begins at 08:26:30.569921\n",
            "Training: batch 865 begins at 08:26:30.578317\n",
            "Training: batch 866 begins at 08:26:30.584101\n",
            "Training: batch 867 begins at 08:26:30.590004\n",
            "Training: batch 868 begins at 08:26:30.595866\n",
            "Training: batch 869 begins at 08:26:30.601659\n",
            "Training: batch 870 begins at 08:26:30.609133\n",
            "Training: batch 871 begins at 08:26:30.614885\n",
            " 872/1875 [============>.................] - ETA: 8s - loss: 0.2543 - accuracy: 0.9047Training: batch 872 begins at 08:26:30.622812\n",
            "Training: batch 873 begins at 08:26:30.628575\n",
            "Training: batch 874 begins at 08:26:30.636348\n",
            "Training: batch 875 begins at 08:26:30.643314\n",
            "Training: batch 876 begins at 08:26:30.651423\n",
            "Training: batch 877 begins at 08:26:30.659358\n",
            "Training: batch 878 begins at 08:26:30.665902\n",
            " 879/1875 [=============>................] - ETA: 8s - loss: 0.2545 - accuracy: 0.9047Training: batch 879 begins at 08:26:30.675266\n",
            "Training: batch 880 begins at 08:26:30.681257\n",
            "Training: batch 881 begins at 08:26:30.688971\n",
            "Training: batch 882 begins at 08:26:30.695568\n",
            "Training: batch 883 begins at 08:26:30.702942\n",
            "Training: batch 884 begins at 08:26:30.709531\n",
            "Training: batch 885 begins at 08:26:30.716515\n",
            " 886/1875 [=============>................] - ETA: 8s - loss: 0.2542 - accuracy: 0.9048Training: batch 886 begins at 08:26:30.726033\n",
            "Training: batch 887 begins at 08:26:30.733515\n",
            "Training: batch 888 begins at 08:26:30.739812\n",
            "Training: batch 889 begins at 08:26:30.747763\n",
            "Training: batch 890 begins at 08:26:30.754886\n",
            "Training: batch 891 begins at 08:26:30.761919\n",
            "Training: batch 892 begins at 08:26:30.769362\n",
            " 893/1875 [=============>................] - ETA: 8s - loss: 0.2545 - accuracy: 0.9047Training: batch 893 begins at 08:26:30.778552\n",
            "Training: batch 894 begins at 08:26:30.785714\n",
            "Training: batch 895 begins at 08:26:30.794617\n",
            "Training: batch 896 begins at 08:26:30.801854\n",
            "Training: batch 897 begins at 08:26:30.810105\n",
            "Training: batch 898 begins at 08:26:30.823023\n",
            " 899/1875 [=============>................] - ETA: 7s - loss: 0.2542 - accuracy: 0.9049Training: batch 899 begins at 08:26:30.836638\n",
            "Training: batch 900 begins at 08:26:30.845565\n",
            "Training: batch 901 begins at 08:26:30.854586\n",
            "Training: batch 902 begins at 08:26:30.859795\n",
            "Training: batch 903 begins at 08:26:30.867749\n",
            "Training: batch 904 begins at 08:26:30.874393\n",
            "Training: batch 905 begins at 08:26:30.881541\n",
            " 906/1875 [=============>................] - ETA: 7s - loss: 0.2541 - accuracy: 0.9049Training: batch 906 begins at 08:26:30.889917\n",
            "Training: batch 907 begins at 08:26:30.897044\n",
            "Training: batch 908 begins at 08:26:30.905297\n",
            "Training: batch 909 begins at 08:26:30.912414\n",
            "Training: batch 910 begins at 08:26:30.919404\n",
            "Training: batch 911 begins at 08:26:30.926011\n",
            "Training: batch 912 begins at 08:26:30.934616\n",
            " 913/1875 [=============>................] - ETA: 7s - loss: 0.2543 - accuracy: 0.9048Training: batch 913 begins at 08:26:30.943377\n",
            "Training: batch 914 begins at 08:26:30.950700\n",
            "Training: batch 915 begins at 08:26:30.958113\n",
            "Training: batch 916 begins at 08:26:30.965903\n",
            "Training: batch 917 begins at 08:26:30.973096\n",
            "Training: batch 918 begins at 08:26:30.980250\n",
            "Training: batch 919 begins at 08:26:30.987065\n",
            " 920/1875 [=============>................] - ETA: 7s - loss: 0.2541 - accuracy: 0.9048Training: batch 920 begins at 08:26:31.001027\n",
            "Training: batch 921 begins at 08:26:31.013733\n",
            "Training: batch 922 begins at 08:26:31.020927\n",
            "Training: batch 923 begins at 08:26:31.026854\n",
            "Training: batch 924 begins at 08:26:31.035115\n",
            "Training: batch 925 begins at 08:26:31.041885\n",
            " 926/1875 [=============>................] - ETA: 7s - loss: 0.2544 - accuracy: 0.9047Training: batch 926 begins at 08:26:31.051884\n",
            "Training: batch 927 begins at 08:26:31.057197\n",
            "Training: batch 928 begins at 08:26:31.064972\n",
            "Training: batch 929 begins at 08:26:31.071423\n",
            "Training: batch 930 begins at 08:26:31.079471\n",
            "Training: batch 931 begins at 08:26:31.084854\n",
            "Training: batch 932 begins at 08:26:31.091689\n",
            "Training: batch 933 begins at 08:26:31.099418\n",
            " 934/1875 [=============>................] - ETA: 7s - loss: 0.2542 - accuracy: 0.9048Training: batch 934 begins at 08:26:31.109048\n",
            "Training: batch 935 begins at 08:26:31.115534\n",
            "Training: batch 936 begins at 08:26:31.122779\n",
            "Training: batch 937 begins at 08:26:31.129480\n",
            "Training: batch 938 begins at 08:26:31.136579\n",
            "Training: batch 939 begins at 08:26:31.143098\n",
            "Training: batch 940 begins at 08:26:31.149136\n",
            "Training: batch 941 begins at 08:26:31.156651\n",
            " 942/1875 [==============>...............] - ETA: 7s - loss: 0.2543 - accuracy: 0.9048Training: batch 942 begins at 08:26:31.168649\n",
            "Training: batch 943 begins at 08:26:31.178488\n",
            "Training: batch 944 begins at 08:26:31.185418\n",
            "Training: batch 945 begins at 08:26:31.193016\n",
            "Training: batch 946 begins at 08:26:31.201816\n",
            "Training: batch 947 begins at 08:26:31.209861\n",
            "Training: batch 948 begins at 08:26:31.216729\n",
            " 949/1875 [==============>...............] - ETA: 7s - loss: 0.2540 - accuracy: 0.9049Training: batch 949 begins at 08:26:31.229411\n",
            "Training: batch 950 begins at 08:26:31.237776\n",
            "Training: batch 951 begins at 08:26:31.247942\n",
            "Training: batch 952 begins at 08:26:31.256924\n",
            "Training: batch 953 begins at 08:26:31.265845\n",
            "Training: batch 954 begins at 08:26:31.275077\n",
            " 955/1875 [==============>...............] - ETA: 7s - loss: 0.2535 - accuracy: 0.9051Training: batch 955 begins at 08:26:31.283885\n",
            "Training: batch 956 begins at 08:26:31.290561\n",
            "Training: batch 957 begins at 08:26:31.297634\n",
            "Training: batch 958 begins at 08:26:31.307895\n",
            "Training: batch 959 begins at 08:26:31.313690\n",
            "Training: batch 960 begins at 08:26:31.320475\n",
            "Training: batch 961 begins at 08:26:31.326201\n",
            " 962/1875 [==============>...............] - ETA: 7s - loss: 0.2535 - accuracy: 0.9050Training: batch 962 begins at 08:26:31.336339\n",
            "Training: batch 963 begins at 08:26:31.341585\n",
            "Training: batch 964 begins at 08:26:31.348304\n",
            "Training: batch 965 begins at 08:26:31.357657\n",
            "Training: batch 966 begins at 08:26:31.366871\n",
            "Training: batch 967 begins at 08:26:31.376119\n",
            " 968/1875 [==============>...............] - ETA: 7s - loss: 0.2539 - accuracy: 0.9050Training: batch 968 begins at 08:26:31.386760\n",
            "Training: batch 969 begins at 08:26:31.395589\n",
            "Training: batch 970 begins at 08:26:31.404961\n",
            "Training: batch 971 begins at 08:26:31.412833\n",
            "Training: batch 972 begins at 08:26:31.420884\n",
            "Training: batch 973 begins at 08:26:31.431025\n",
            " 974/1875 [==============>...............] - ETA: 7s - loss: 0.2535 - accuracy: 0.9051Training: batch 974 begins at 08:26:31.441202\n",
            "Training: batch 975 begins at 08:26:31.448695\n",
            "Training: batch 976 begins at 08:26:31.456138\n",
            "Training: batch 977 begins at 08:26:31.464354\n",
            "Training: batch 978 begins at 08:26:31.473659\n",
            "Training: batch 979 begins at 08:26:31.479976\n",
            "Training: batch 980 begins at 08:26:31.488445\n",
            " 981/1875 [==============>...............] - ETA: 7s - loss: 0.2535 - accuracy: 0.9052Training: batch 981 begins at 08:26:31.495864\n",
            "Training: batch 982 begins at 08:26:31.503546\n",
            "Training: batch 983 begins at 08:26:31.513424\n",
            "Training: batch 984 begins at 08:26:31.519724\n",
            "Training: batch 985 begins at 08:26:31.531869\n",
            "Training: batch 986 begins at 08:26:31.537310\n",
            " 987/1875 [==============>...............] - ETA: 7s - loss: 0.2538 - accuracy: 0.9051Training: batch 987 begins at 08:26:31.546957\n",
            "Training: batch 988 begins at 08:26:31.555065\n",
            "Training: batch 989 begins at 08:26:31.559516\n",
            "Training: batch 990 begins at 08:26:31.568918\n",
            "Training: batch 991 begins at 08:26:31.576778\n",
            "Training: batch 992 begins at 08:26:31.584397\n",
            "Training: batch 993 begins at 08:26:31.592062\n",
            " 994/1875 [==============>...............] - ETA: 7s - loss: 0.2536 - accuracy: 0.9052Training: batch 994 begins at 08:26:31.599090\n",
            "Training: batch 995 begins at 08:26:31.605856\n",
            "Training: batch 996 begins at 08:26:31.611411\n",
            "Training: batch 997 begins at 08:26:31.616967\n",
            "Training: batch 998 begins at 08:26:31.624877\n",
            "Training: batch 999 begins at 08:26:31.631790\n",
            "Training: batch 1000 begins at 08:26:31.639845\n",
            "Training: batch 1001 begins at 08:26:31.647377\n",
            "1002/1875 [===============>..............] - ETA: 7s - loss: 0.2531 - accuracy: 0.9054Training: batch 1002 begins at 08:26:31.656610\n",
            "Training: batch 1003 begins at 08:26:31.664644\n",
            "Training: batch 1004 begins at 08:26:31.672354\n",
            "Training: batch 1005 begins at 08:26:31.679710\n",
            "Training: batch 1006 begins at 08:26:31.686011\n",
            "Training: batch 1007 begins at 08:26:31.693259\n",
            "Training: batch 1008 begins at 08:26:31.700596\n",
            "1009/1875 [===============>..............] - ETA: 7s - loss: 0.2527 - accuracy: 0.9055Training: batch 1009 begins at 08:26:31.708803\n",
            "Training: batch 1010 begins at 08:26:31.715751\n",
            "Training: batch 1011 begins at 08:26:31.722905\n",
            "Training: batch 1012 begins at 08:26:31.730654\n",
            "Training: batch 1013 begins at 08:26:31.737414\n",
            "Training: batch 1014 begins at 08:26:31.744066\n",
            "Training: batch 1015 begins at 08:26:31.750934\n",
            "1016/1875 [===============>..............] - ETA: 6s - loss: 0.2531 - accuracy: 0.9052Training: batch 1016 begins at 08:26:31.759310\n",
            "Training: batch 1017 begins at 08:26:31.765726\n",
            "Training: batch 1018 begins at 08:26:31.771679\n",
            "Training: batch 1019 begins at 08:26:31.778732\n",
            "Training: batch 1020 begins at 08:26:31.787127\n",
            "Training: batch 1021 begins at 08:26:31.795723\n",
            "Training: batch 1022 begins at 08:26:31.802888\n",
            "1023/1875 [===============>..............] - ETA: 6s - loss: 0.2529 - accuracy: 0.9053Training: batch 1023 begins at 08:26:31.811130\n",
            "Training: batch 1024 begins at 08:26:31.817906\n",
            "Training: batch 1025 begins at 08:26:31.823830\n",
            "Training: batch 1026 begins at 08:26:31.829795\n",
            "Training: batch 1027 begins at 08:26:31.837067\n",
            "Training: batch 1028 begins at 08:26:31.843416\n",
            "Training: batch 1029 begins at 08:26:31.851650\n",
            "Training: batch 1030 begins at 08:26:31.857207\n",
            "1031/1875 [===============>..............] - ETA: 6s - loss: 0.2528 - accuracy: 0.9053Training: batch 1031 begins at 08:26:31.865746\n",
            "Training: batch 1032 begins at 08:26:31.872645\n",
            "Training: batch 1033 begins at 08:26:31.879905\n",
            "Training: batch 1034 begins at 08:26:31.887678\n",
            "Training: batch 1035 begins at 08:26:31.893816\n",
            "Training: batch 1036 begins at 08:26:31.900275\n",
            "Training: batch 1037 begins at 08:26:31.905741\n",
            "Training: batch 1038 begins at 08:26:31.913310\n",
            "1039/1875 [===============>..............] - ETA: 6s - loss: 0.2528 - accuracy: 0.9053Training: batch 1039 begins at 08:26:31.925042\n",
            "Training: batch 1040 begins at 08:26:31.933815\n",
            "Training: batch 1041 begins at 08:26:31.939752\n",
            "Training: batch 1042 begins at 08:26:31.944522\n",
            "Training: batch 1043 begins at 08:26:31.953938\n",
            "Training: batch 1044 begins at 08:26:31.961318\n",
            "Training: batch 1045 begins at 08:26:31.971688\n",
            "1046/1875 [===============>..............] - ETA: 6s - loss: 0.2534 - accuracy: 0.9051Training: batch 1046 begins at 08:26:31.987615\n",
            "Training: batch 1047 begins at 08:26:31.993453\n",
            "Training: batch 1048 begins at 08:26:32.003758\n",
            "Training: batch 1049 begins at 08:26:32.013406\n",
            "Training: batch 1050 begins at 08:26:32.021429\n",
            "Training: batch 1051 begins at 08:26:32.030233\n",
            "1052/1875 [===============>..............] - ETA: 6s - loss: 0.2535 - accuracy: 0.9049Training: batch 1052 begins at 08:26:32.042478\n",
            "Training: batch 1053 begins at 08:26:32.050484\n",
            "Training: batch 1054 begins at 08:26:32.060169\n",
            "Training: batch 1055 begins at 08:26:32.067637\n",
            "Training: batch 1056 begins at 08:26:32.075520\n",
            "Training: batch 1057 begins at 08:26:32.082327\n",
            "Training: batch 1058 begins at 08:26:32.089460\n",
            "1059/1875 [===============>..............] - ETA: 6s - loss: 0.2541 - accuracy: 0.9046Training: batch 1059 begins at 08:26:32.098046\n",
            "Training: batch 1060 begins at 08:26:32.104764\n",
            "Training: batch 1061 begins at 08:26:32.110980\n",
            "Training: batch 1062 begins at 08:26:32.118044\n",
            "Training: batch 1063 begins at 08:26:32.126183\n",
            "Training: batch 1064 begins at 08:26:32.134070\n",
            "Training: batch 1065 begins at 08:26:32.141524\n",
            "1066/1875 [================>.............] - ETA: 6s - loss: 0.2546 - accuracy: 0.9044Training: batch 1066 begins at 08:26:32.150233\n",
            "Training: batch 1067 begins at 08:26:32.157456\n",
            "Training: batch 1068 begins at 08:26:32.164880\n",
            "Training: batch 1069 begins at 08:26:32.173475\n",
            "Training: batch 1070 begins at 08:26:32.181389\n",
            "Training: batch 1071 begins at 08:26:32.189059\n",
            "Training: batch 1072 begins at 08:26:32.195717\n",
            "1073/1875 [================>.............] - ETA: 6s - loss: 0.2548 - accuracy: 0.9043Training: batch 1073 begins at 08:26:32.205613\n",
            "Training: batch 1074 begins at 08:26:32.212343\n",
            "Training: batch 1075 begins at 08:26:32.218851\n",
            "Training: batch 1076 begins at 08:26:32.226699\n",
            "Training: batch 1077 begins at 08:26:32.234273\n",
            "Training: batch 1078 begins at 08:26:32.240674\n",
            "Training: batch 1079 begins at 08:26:32.248867\n",
            "1080/1875 [================>.............] - ETA: 6s - loss: 0.2548 - accuracy: 0.9044Training: batch 1080 begins at 08:26:32.257108\n",
            "Training: batch 1081 begins at 08:26:32.265587\n",
            "Training: batch 1082 begins at 08:26:32.273117\n",
            "Training: batch 1083 begins at 08:26:32.281926\n",
            "Training: batch 1084 begins at 08:26:32.289185\n",
            "Training: batch 1085 begins at 08:26:32.295378\n",
            "Training: batch 1086 begins at 08:26:32.302924\n",
            "1087/1875 [================>.............] - ETA: 6s - loss: 0.2546 - accuracy: 0.9045Training: batch 1087 begins at 08:26:32.312620\n",
            "Training: batch 1088 begins at 08:26:32.319576\n",
            "Training: batch 1089 begins at 08:26:32.326482\n",
            "Training: batch 1090 begins at 08:26:32.333768\n",
            "Training: batch 1091 begins at 08:26:32.340383\n",
            "Training: batch 1092 begins at 08:26:32.347732\n",
            "Training: batch 1093 begins at 08:26:32.356041\n",
            "1094/1875 [================>.............] - ETA: 6s - loss: 0.2546 - accuracy: 0.9043Training: batch 1094 begins at 08:26:32.364521\n",
            "Training: batch 1095 begins at 08:26:32.371290\n",
            "Training: batch 1096 begins at 08:26:32.378711\n",
            "Training: batch 1097 begins at 08:26:32.387658\n",
            "Training: batch 1098 begins at 08:26:32.395270\n",
            "Training: batch 1099 begins at 08:26:32.402765\n",
            "Training: batch 1100 begins at 08:26:32.410520\n",
            "1101/1875 [================>.............] - ETA: 6s - loss: 0.2551 - accuracy: 0.9041Training: batch 1101 begins at 08:26:32.420182\n",
            "Training: batch 1102 begins at 08:26:32.430709\n",
            "Training: batch 1103 begins at 08:26:32.437652\n",
            "Training: batch 1104 begins at 08:26:32.445214\n",
            "Training: batch 1105 begins at 08:26:32.451948\n",
            "Training: batch 1106 begins at 08:26:32.458228\n",
            "Training: batch 1107 begins at 08:26:32.465894\n",
            "1108/1875 [================>.............] - ETA: 6s - loss: 0.2555 - accuracy: 0.9039Training: batch 1108 begins at 08:26:32.475725\n",
            "Training: batch 1109 begins at 08:26:32.482222\n",
            "Training: batch 1110 begins at 08:26:32.489843\n",
            "Training: batch 1111 begins at 08:26:32.496517\n",
            "Training: batch 1112 begins at 08:26:32.504357\n",
            "Training: batch 1113 begins at 08:26:32.510601\n",
            "Training: batch 1114 begins at 08:26:32.519536\n",
            "1115/1875 [================>.............] - ETA: 6s - loss: 0.2558 - accuracy: 0.9039Training: batch 1115 begins at 08:26:32.528295\n",
            "Training: batch 1116 begins at 08:26:32.534970\n",
            "Training: batch 1117 begins at 08:26:32.542915\n",
            "Training: batch 1118 begins at 08:26:32.549559\n",
            "Training: batch 1119 begins at 08:26:32.556954\n",
            "Training: batch 1120 begins at 08:26:32.564431\n",
            "Training: batch 1121 begins at 08:26:32.572348\n",
            "1122/1875 [================>.............] - ETA: 6s - loss: 0.2555 - accuracy: 0.9040Training: batch 1122 begins at 08:26:32.584938\n",
            "Training: batch 1123 begins at 08:26:32.594894\n",
            "Training: batch 1124 begins at 08:26:32.603940\n",
            "Training: batch 1125 begins at 08:26:32.611632\n",
            "Training: batch 1126 begins at 08:26:32.618124\n",
            "Training: batch 1127 begins at 08:26:32.625510\n",
            "Training: batch 1128 begins at 08:26:32.632320\n",
            "1129/1875 [=================>............] - ETA: 6s - loss: 0.2554 - accuracy: 0.9041Training: batch 1129 begins at 08:26:32.641462\n",
            "Training: batch 1130 begins at 08:26:32.648032\n",
            "Training: batch 1131 begins at 08:26:32.655410\n",
            "Training: batch 1132 begins at 08:26:32.663309\n",
            "Training: batch 1133 begins at 08:26:32.670116\n",
            "Training: batch 1134 begins at 08:26:32.677225\n",
            "Training: batch 1135 begins at 08:26:32.685245\n",
            "1136/1875 [=================>............] - ETA: 5s - loss: 0.2556 - accuracy: 0.9040Training: batch 1136 begins at 08:26:32.695443\n",
            "Training: batch 1137 begins at 08:26:32.703573\n",
            "Training: batch 1138 begins at 08:26:32.709974\n",
            "Training: batch 1139 begins at 08:26:32.717121\n",
            "Training: batch 1140 begins at 08:26:32.724840\n",
            "Training: batch 1141 begins at 08:26:32.732667\n",
            "Training: batch 1142 begins at 08:26:32.740807\n",
            "1143/1875 [=================>............] - ETA: 5s - loss: 0.2555 - accuracy: 0.9040Training: batch 1143 begins at 08:26:32.750774\n",
            "Training: batch 1144 begins at 08:26:32.758737\n",
            "Training: batch 1145 begins at 08:26:32.767798\n",
            "Training: batch 1146 begins at 08:26:32.774866\n",
            "Training: batch 1147 begins at 08:26:32.784022\n",
            "Training: batch 1148 begins at 08:26:32.795866\n",
            "1149/1875 [=================>............] - ETA: 5s - loss: 0.2555 - accuracy: 0.9040Training: batch 1149 begins at 08:26:32.803842\n",
            "Training: batch 1150 begins at 08:26:32.812696\n",
            "Training: batch 1151 begins at 08:26:32.825973\n",
            "Training: batch 1152 begins at 08:26:32.836551\n",
            "1153/1875 [=================>............] - ETA: 5s - loss: 0.2558 - accuracy: 0.9038Training: batch 1153 begins at 08:26:32.855237\n",
            "Training: batch 1154 begins at 08:26:32.865376\n",
            "Training: batch 1155 begins at 08:26:32.875260\n",
            "Training: batch 1156 begins at 08:26:32.884026\n",
            "Training: batch 1157 begins at 08:26:32.893249\n",
            "Training: batch 1158 begins at 08:26:32.901366\n",
            "1159/1875 [=================>............] - ETA: 5s - loss: 0.2561 - accuracy: 0.9039Training: batch 1159 begins at 08:26:32.915601\n",
            "Training: batch 1160 begins at 08:26:32.927729\n",
            "Training: batch 1161 begins at 08:26:32.938890\n",
            "Training: batch 1162 begins at 08:26:32.943783\n",
            "Training: batch 1163 begins at 08:26:32.952300\n",
            "Training: batch 1164 begins at 08:26:32.959308\n",
            "1165/1875 [=================>............] - ETA: 5s - loss: 0.2559 - accuracy: 0.9039Training: batch 1165 begins at 08:26:32.969663\n",
            "Training: batch 1166 begins at 08:26:32.977298\n",
            "Training: batch 1167 begins at 08:26:32.984273\n",
            "Training: batch 1168 begins at 08:26:32.991707\n",
            "Training: batch 1169 begins at 08:26:32.998717\n",
            "Training: batch 1170 begins at 08:26:33.005095\n",
            "Training: batch 1171 begins at 08:26:33.014815\n",
            "1172/1875 [=================>............] - ETA: 5s - loss: 0.2557 - accuracy: 0.9040Training: batch 1172 begins at 08:26:33.025461\n",
            "Training: batch 1173 begins at 08:26:33.034513\n",
            "Training: batch 1174 begins at 08:26:33.042355\n",
            "Training: batch 1175 begins at 08:26:33.050867\n",
            "Training: batch 1176 begins at 08:26:33.059272\n",
            "Training: batch 1177 begins at 08:26:33.067792\n",
            "1178/1875 [=================>............] - ETA: 5s - loss: 0.2555 - accuracy: 0.9040Training: batch 1178 begins at 08:26:33.077128\n",
            "Training: batch 1179 begins at 08:26:33.086529\n",
            "Training: batch 1180 begins at 08:26:33.095048\n",
            "Training: batch 1181 begins at 08:26:33.102876\n",
            "Training: batch 1182 begins at 08:26:33.112042\n",
            "Training: batch 1183 begins at 08:26:33.119911\n",
            "1184/1875 [=================>............] - ETA: 5s - loss: 0.2551 - accuracy: 0.9042Training: batch 1184 begins at 08:26:33.128771\n",
            "Training: batch 1185 begins at 08:26:33.136498\n",
            "Training: batch 1186 begins at 08:26:33.144944\n",
            "Training: batch 1187 begins at 08:26:33.152655\n",
            "Training: batch 1188 begins at 08:26:33.161074\n",
            "Training: batch 1189 begins at 08:26:33.168411\n",
            "Training: batch 1190 begins at 08:26:33.176126\n",
            "1191/1875 [==================>...........] - ETA: 5s - loss: 0.2556 - accuracy: 0.9041Training: batch 1191 begins at 08:26:33.184564\n",
            "Training: batch 1192 begins at 08:26:33.191255\n",
            "Training: batch 1193 begins at 08:26:33.197573\n",
            "Training: batch 1194 begins at 08:26:33.204767\n",
            "Training: batch 1195 begins at 08:26:33.219968\n",
            "Training: batch 1196 begins at 08:26:33.226936\n",
            "1197/1875 [==================>...........] - ETA: 5s - loss: 0.2555 - accuracy: 0.9042Training: batch 1197 begins at 08:26:33.236309\n",
            "Training: batch 1198 begins at 08:26:33.244134\n",
            "Training: batch 1199 begins at 08:26:33.252288\n",
            "Training: batch 1200 begins at 08:26:33.260672\n",
            "Training: batch 1201 begins at 08:26:33.268294\n",
            "Training: batch 1202 begins at 08:26:33.275366\n",
            "Training: batch 1203 begins at 08:26:33.282333\n",
            "1204/1875 [==================>...........] - ETA: 5s - loss: 0.2553 - accuracy: 0.9042Training: batch 1204 begins at 08:26:33.293185\n",
            "Training: batch 1205 begins at 08:26:33.300093\n",
            "Training: batch 1206 begins at 08:26:33.307360\n",
            "Training: batch 1207 begins at 08:26:33.314867\n",
            "Training: batch 1208 begins at 08:26:33.322306\n",
            "Training: batch 1209 begins at 08:26:33.330471\n",
            "Training: batch 1210 begins at 08:26:33.338874\n",
            "1211/1875 [==================>...........] - ETA: 5s - loss: 0.2556 - accuracy: 0.9041Training: batch 1211 begins at 08:26:33.350742\n",
            "Training: batch 1212 begins at 08:26:33.357697\n",
            "Training: batch 1213 begins at 08:26:33.365801\n",
            "Training: batch 1214 begins at 08:26:33.373251\n",
            "Training: batch 1215 begins at 08:26:33.379458\n",
            "Training: batch 1216 begins at 08:26:33.386361\n",
            "Training: batch 1217 begins at 08:26:33.393801\n",
            "1218/1875 [==================>...........] - ETA: 5s - loss: 0.2553 - accuracy: 0.9044Training: batch 1218 begins at 08:26:33.402923\n",
            "Training: batch 1219 begins at 08:26:33.411032\n",
            "Training: batch 1220 begins at 08:26:33.418580\n",
            "Training: batch 1221 begins at 08:26:33.426052\n",
            "Training: batch 1222 begins at 08:26:33.434822\n",
            "Training: batch 1223 begins at 08:26:33.447833\n",
            "1224/1875 [==================>...........] - ETA: 5s - loss: 0.2554 - accuracy: 0.9044Training: batch 1224 begins at 08:26:33.459230\n",
            "Training: batch 1225 begins at 08:26:33.468034\n",
            "Training: batch 1226 begins at 08:26:33.476905\n",
            "Training: batch 1227 begins at 08:26:33.484261\n",
            "Training: batch 1228 begins at 08:26:33.492494\n",
            "Training: batch 1229 begins at 08:26:33.499643\n",
            "1230/1875 [==================>...........] - ETA: 5s - loss: 0.2555 - accuracy: 0.9043Training: batch 1230 begins at 08:26:33.509883\n",
            "Training: batch 1231 begins at 08:26:33.517251\n",
            "Training: batch 1232 begins at 08:26:33.524789\n",
            "Training: batch 1233 begins at 08:26:33.532264\n",
            "Training: batch 1234 begins at 08:26:33.540034\n",
            "Training: batch 1235 begins at 08:26:33.546355\n",
            "Training: batch 1236 begins at 08:26:33.557108\n",
            "1237/1875 [==================>...........] - ETA: 5s - loss: 0.2553 - accuracy: 0.9044Training: batch 1237 begins at 08:26:33.567774\n",
            "Training: batch 1238 begins at 08:26:33.576053\n",
            "Training: batch 1239 begins at 08:26:33.583028\n",
            "Training: batch 1240 begins at 08:26:33.592132\n",
            "Training: batch 1241 begins at 08:26:33.598748\n",
            "Training: batch 1242 begins at 08:26:33.606714\n",
            "1243/1875 [==================>...........] - ETA: 5s - loss: 0.2553 - accuracy: 0.9043Training: batch 1243 begins at 08:26:33.617699\n",
            "Training: batch 1244 begins at 08:26:33.625195\n",
            "Training: batch 1245 begins at 08:26:33.630962\n",
            "Training: batch 1246 begins at 08:26:33.639816\n",
            "Training: batch 1247 begins at 08:26:33.648714\n",
            "Training: batch 1248 begins at 08:26:33.658642\n",
            "Training: batch 1249 begins at 08:26:33.665568\n",
            "1250/1875 [===================>..........] - ETA: 5s - loss: 0.2553 - accuracy: 0.9043Training: batch 1250 begins at 08:26:33.674166\n",
            "Training: batch 1251 begins at 08:26:33.682837\n",
            "Training: batch 1252 begins at 08:26:33.691611\n",
            "Training: batch 1253 begins at 08:26:33.697500\n",
            "Training: batch 1254 begins at 08:26:33.704192\n",
            "Training: batch 1255 begins at 08:26:33.712120\n",
            "Training: batch 1256 begins at 08:26:33.718391\n",
            "1257/1875 [===================>..........] - ETA: 5s - loss: 0.2552 - accuracy: 0.9045Training: batch 1257 begins at 08:26:33.733209\n",
            "Training: batch 1258 begins at 08:26:33.740328\n",
            "Training: batch 1259 begins at 08:26:33.746284\n",
            "Training: batch 1260 begins at 08:26:33.753443\n",
            "Training: batch 1261 begins at 08:26:33.761475\n",
            "Training: batch 1262 begins at 08:26:33.768839\n",
            "1263/1875 [===================>..........] - ETA: 4s - loss: 0.2551 - accuracy: 0.9044Training: batch 1263 begins at 08:26:33.780705\n",
            "Training: batch 1264 begins at 08:26:33.786685\n",
            "Training: batch 1265 begins at 08:26:33.798216\n",
            "Training: batch 1266 begins at 08:26:33.803829\n",
            "Training: batch 1267 begins at 08:26:33.809844\n",
            "Training: batch 1268 begins at 08:26:33.815267\n",
            "Training: batch 1269 begins at 08:26:33.824859\n",
            "1270/1875 [===================>..........] - ETA: 4s - loss: 0.2554 - accuracy: 0.9042Training: batch 1270 begins at 08:26:33.834366\n",
            "Training: batch 1271 begins at 08:26:33.840200\n",
            "Training: batch 1272 begins at 08:26:33.850037\n",
            "Training: batch 1273 begins at 08:26:33.858851\n",
            "Training: batch 1274 begins at 08:26:33.869237\n",
            "Training: batch 1275 begins at 08:26:33.877522\n",
            "1276/1875 [===================>..........] - ETA: 4s - loss: 0.2550 - accuracy: 0.9044Training: batch 1276 begins at 08:26:33.884552\n",
            "Training: batch 1277 begins at 08:26:33.890755\n",
            "Training: batch 1278 begins at 08:26:33.900309\n",
            "Training: batch 1279 begins at 08:26:33.905641\n",
            "Training: batch 1280 begins at 08:26:33.914780\n",
            "Training: batch 1281 begins at 08:26:33.921104\n",
            "Training: batch 1282 begins at 08:26:33.929012\n",
            "1283/1875 [===================>..........] - ETA: 4s - loss: 0.2548 - accuracy: 0.9044Training: batch 1283 begins at 08:26:33.938352\n",
            "Training: batch 1284 begins at 08:26:33.948068\n",
            "Training: batch 1285 begins at 08:26:33.957670\n",
            "Training: batch 1286 begins at 08:26:33.965007\n",
            "Training: batch 1287 begins at 08:26:33.974709\n",
            "Training: batch 1288 begins at 08:26:33.984328\n",
            "1289/1875 [===================>..........] - ETA: 4s - loss: 0.2545 - accuracy: 0.9044Training: batch 1289 begins at 08:26:33.993366\n",
            "Training: batch 1290 begins at 08:26:33.999071\n",
            "Training: batch 1291 begins at 08:26:34.009344\n",
            "Training: batch 1292 begins at 08:26:34.019316\n",
            "Training: batch 1293 begins at 08:26:34.028090\n",
            "Training: batch 1294 begins at 08:26:34.034738\n",
            "1295/1875 [===================>..........] - ETA: 4s - loss: 0.2546 - accuracy: 0.9043Training: batch 1295 begins at 08:26:34.046020\n",
            "Training: batch 1296 begins at 08:26:34.055054\n",
            "Training: batch 1297 begins at 08:26:34.062484\n",
            "Training: batch 1298 begins at 08:26:34.072511\n",
            "Training: batch 1299 begins at 08:26:34.082218\n",
            "Training: batch 1300 begins at 08:26:34.093287\n",
            "1301/1875 [===================>..........] - ETA: 4s - loss: 0.2545 - accuracy: 0.9044Training: batch 1301 begins at 08:26:34.102583\n",
            "Training: batch 1302 begins at 08:26:34.111424\n",
            "Training: batch 1303 begins at 08:26:34.118997\n",
            "Training: batch 1304 begins at 08:26:34.128845\n",
            "Training: batch 1305 begins at 08:26:34.135800\n",
            "Training: batch 1306 begins at 08:26:34.143091\n",
            "1307/1875 [===================>..........] - ETA: 4s - loss: 0.2547 - accuracy: 0.9043Training: batch 1307 begins at 08:26:34.154376\n",
            "Training: batch 1308 begins at 08:26:34.161308\n",
            "Training: batch 1309 begins at 08:26:34.170245\n",
            "Training: batch 1310 begins at 08:26:34.184407\n",
            "Training: batch 1311 begins at 08:26:34.192603\n",
            "1312/1875 [===================>..........] - ETA: 4s - loss: 0.2548 - accuracy: 0.9042Training: batch 1312 begins at 08:26:34.205079\n",
            "Training: batch 1313 begins at 08:26:34.214546\n",
            "Training: batch 1314 begins at 08:26:34.223684\n",
            "Training: batch 1315 begins at 08:26:34.232911\n",
            "Training: batch 1316 begins at 08:26:34.243486\n",
            "Training: batch 1317 begins at 08:26:34.252043\n",
            "1318/1875 [====================>.........] - ETA: 4s - loss: 0.2547 - accuracy: 0.9044Training: batch 1318 begins at 08:26:34.259624\n",
            "Training: batch 1319 begins at 08:26:34.266183\n",
            "Training: batch 1320 begins at 08:26:34.273882\n",
            "Training: batch 1321 begins at 08:26:34.280918\n",
            "Training: batch 1322 begins at 08:26:34.291541\n",
            "Training: batch 1323 begins at 08:26:34.297401\n",
            "Training: batch 1324 begins at 08:26:34.303892\n",
            "1325/1875 [====================>.........] - ETA: 4s - loss: 0.2543 - accuracy: 0.9046Training: batch 1325 begins at 08:26:34.313411\n",
            "Training: batch 1326 begins at 08:26:34.319476\n",
            "Training: batch 1327 begins at 08:26:34.327106\n",
            "Training: batch 1328 begins at 08:26:34.332808\n",
            "Training: batch 1329 begins at 08:26:34.340221\n",
            "Training: batch 1330 begins at 08:26:34.347089\n",
            "Training: batch 1331 begins at 08:26:34.353949\n",
            "Training: batch 1332 begins at 08:26:34.361905\n",
            "1333/1875 [====================>.........] - ETA: 4s - loss: 0.2542 - accuracy: 0.9047Training: batch 1333 begins at 08:26:34.370528\n",
            "Training: batch 1334 begins at 08:26:34.378429\n",
            "Training: batch 1335 begins at 08:26:34.384122\n",
            "Training: batch 1336 begins at 08:26:34.391137\n",
            "Training: batch 1337 begins at 08:26:34.397841\n",
            "Training: batch 1338 begins at 08:26:34.404968\n",
            "Training: batch 1339 begins at 08:26:34.410409\n",
            "Training: batch 1340 begins at 08:26:34.417986\n",
            "1341/1875 [====================>.........] - ETA: 4s - loss: 0.2544 - accuracy: 0.9045Training: batch 1341 begins at 08:26:34.427659\n",
            "Training: batch 1342 begins at 08:26:34.434597\n",
            "Training: batch 1343 begins at 08:26:34.440803\n",
            "Training: batch 1344 begins at 08:26:34.446806\n",
            "Training: batch 1345 begins at 08:26:34.454430\n",
            "Training: batch 1346 begins at 08:26:34.460609\n",
            "Training: batch 1347 begins at 08:26:34.467840\n",
            "Training: batch 1348 begins at 08:26:34.474783\n",
            "1349/1875 [====================>.........] - ETA: 4s - loss: 0.2542 - accuracy: 0.9045Training: batch 1349 begins at 08:26:34.483280\n",
            "Training: batch 1350 begins at 08:26:34.494278\n",
            "Training: batch 1351 begins at 08:26:34.499195\n",
            "Training: batch 1352 begins at 08:26:34.505368\n",
            "Training: batch 1353 begins at 08:26:34.512880\n",
            "Training: batch 1354 begins at 08:26:34.519904\n",
            "Training: batch 1355 begins at 08:26:34.526759\n",
            "1356/1875 [====================>.........] - ETA: 4s - loss: 0.2541 - accuracy: 0.9045Training: batch 1356 begins at 08:26:34.534417\n",
            "Training: batch 1357 begins at 08:26:34.540528\n",
            "Training: batch 1358 begins at 08:26:34.548872\n",
            "Training: batch 1359 begins at 08:26:34.553585\n",
            "Training: batch 1360 begins at 08:26:34.561398\n",
            "Training: batch 1361 begins at 08:26:34.566106\n",
            "Training: batch 1362 begins at 08:26:34.573038\n",
            "Training: batch 1363 begins at 08:26:34.582541\n",
            "1364/1875 [====================>.........] - ETA: 4s - loss: 0.2541 - accuracy: 0.9045Training: batch 1364 begins at 08:26:34.588708\n",
            "Training: batch 1365 begins at 08:26:34.593464\n",
            "Training: batch 1366 begins at 08:26:34.600043\n",
            "Training: batch 1367 begins at 08:26:34.610839\n",
            "Training: batch 1368 begins at 08:26:34.615581\n",
            "Training: batch 1369 begins at 08:26:34.621170\n",
            "Training: batch 1370 begins at 08:26:34.628555\n",
            "Training: batch 1371 begins at 08:26:34.636525\n",
            "1372/1875 [====================>.........] - ETA: 4s - loss: 0.2541 - accuracy: 0.9045Training: batch 1372 begins at 08:26:34.643167\n",
            "Training: batch 1373 begins at 08:26:34.650931\n",
            "Training: batch 1374 begins at 08:26:34.657070\n",
            "Training: batch 1375 begins at 08:26:34.665067\n",
            "Training: batch 1376 begins at 08:26:34.668816\n",
            "Training: batch 1377 begins at 08:26:34.680014\n",
            "Training: batch 1378 begins at 08:26:34.685867\n",
            "1379/1875 [=====================>........] - ETA: 4s - loss: 0.2538 - accuracy: 0.9046Training: batch 1379 begins at 08:26:34.695582\n",
            "Training: batch 1380 begins at 08:26:34.699991\n",
            "Training: batch 1381 begins at 08:26:34.708454\n",
            "Training: batch 1382 begins at 08:26:34.716087\n",
            "Training: batch 1383 begins at 08:26:34.720806\n",
            "Training: batch 1384 begins at 08:26:34.728777\n",
            "Training: batch 1385 begins at 08:26:34.734170\n",
            "Training: batch 1386 begins at 08:26:34.740913\n",
            "1387/1875 [=====================>........] - ETA: 3s - loss: 0.2537 - accuracy: 0.9047Training: batch 1387 begins at 08:26:34.749310\n",
            "Training: batch 1388 begins at 08:26:34.753955\n",
            "Training: batch 1389 begins at 08:26:34.760598\n",
            "Training: batch 1390 begins at 08:26:34.767485\n",
            "Training: batch 1391 begins at 08:26:34.775460\n",
            "Training: batch 1392 begins at 08:26:34.780342\n",
            "Training: batch 1393 begins at 08:26:34.788649\n",
            "1394/1875 [=====================>........] - ETA: 3s - loss: 0.2539 - accuracy: 0.9045Training: batch 1394 begins at 08:26:34.803715\n",
            "Training: batch 1395 begins at 08:26:34.810880\n",
            "Training: batch 1396 begins at 08:26:34.821578\n",
            "Training: batch 1397 begins at 08:26:34.829230\n",
            "Training: batch 1398 begins at 08:26:34.839786\n",
            "Training: batch 1399 begins at 08:26:34.850335\n",
            "1400/1875 [=====================>........] - ETA: 3s - loss: 0.2543 - accuracy: 0.9044Training: batch 1400 begins at 08:26:34.860246\n",
            "Training: batch 1401 begins at 08:26:34.866806\n",
            "Training: batch 1402 begins at 08:26:34.874454\n",
            "Training: batch 1403 begins at 08:26:34.883521\n",
            "Training: batch 1404 begins at 08:26:34.887948\n",
            "Training: batch 1405 begins at 08:26:34.897861\n",
            "Training: batch 1406 begins at 08:26:34.905226\n",
            "1407/1875 [=====================>........] - ETA: 3s - loss: 0.2541 - accuracy: 0.9045Training: batch 1407 begins at 08:26:34.912551\n",
            "Training: batch 1408 begins at 08:26:34.921894\n",
            "Training: batch 1409 begins at 08:26:34.930907\n",
            "Training: batch 1410 begins at 08:26:34.939840\n",
            "Training: batch 1411 begins at 08:26:34.946398\n",
            "Training: batch 1412 begins at 08:26:34.952386\n",
            "Training: batch 1413 begins at 08:26:34.960290\n",
            "1414/1875 [=====================>........] - ETA: 3s - loss: 0.2538 - accuracy: 0.9047Training: batch 1414 begins at 08:26:34.968174\n",
            "Training: batch 1415 begins at 08:26:34.976554\n",
            "Training: batch 1416 begins at 08:26:34.984841\n",
            "Training: batch 1417 begins at 08:26:34.991803\n",
            "Training: batch 1418 begins at 08:26:35.002955\n",
            "Training: batch 1419 begins at 08:26:35.011201\n",
            "1420/1875 [=====================>........] - ETA: 3s - loss: 0.2541 - accuracy: 0.9045Training: batch 1420 begins at 08:26:35.018392\n",
            "Training: batch 1421 begins at 08:26:35.026749\n",
            "Training: batch 1422 begins at 08:26:35.032762\n",
            "Training: batch 1423 begins at 08:26:35.041410\n",
            "Training: batch 1424 begins at 08:26:35.051758\n",
            "Training: batch 1425 begins at 08:26:35.060719\n",
            "Training: batch 1426 begins at 08:26:35.066772\n",
            "1427/1875 [=====================>........] - ETA: 3s - loss: 0.2542 - accuracy: 0.9044Training: batch 1427 begins at 08:26:35.079615\n",
            "Training: batch 1428 begins at 08:26:35.085673\n",
            "Training: batch 1429 begins at 08:26:35.091475\n",
            "Training: batch 1430 begins at 08:26:35.097373\n",
            "Training: batch 1431 begins at 08:26:35.107092\n",
            "Training: batch 1432 begins at 08:26:35.112933\n",
            "Training: batch 1433 begins at 08:26:35.121578\n",
            "1434/1875 [=====================>........] - ETA: 3s - loss: 0.2545 - accuracy: 0.9043Training: batch 1434 begins at 08:26:35.129645\n",
            "Training: batch 1435 begins at 08:26:35.135667\n",
            "Training: batch 1436 begins at 08:26:35.144816\n",
            "Training: batch 1437 begins at 08:26:35.150692\n",
            "Training: batch 1438 begins at 08:26:35.158839\n",
            "Training: batch 1439 begins at 08:26:35.167321\n",
            "Training: batch 1440 begins at 08:26:35.173311\n",
            "1441/1875 [======================>.......] - ETA: 3s - loss: 0.2544 - accuracy: 0.9043Training: batch 1441 begins at 08:26:35.184201\n",
            "Training: batch 1442 begins at 08:26:35.189976\n",
            "Training: batch 1443 begins at 08:26:35.197455\n",
            "Training: batch 1444 begins at 08:26:35.205632\n",
            "Training: batch 1445 begins at 08:26:35.212962\n",
            "Training: batch 1446 begins at 08:26:35.218430\n",
            "Training: batch 1447 begins at 08:26:35.226084\n",
            "Training: batch 1448 begins at 08:26:35.231599\n",
            "1449/1875 [======================>.......] - ETA: 3s - loss: 0.2543 - accuracy: 0.9044Training: batch 1449 begins at 08:26:35.243576\n",
            "Training: batch 1450 begins at 08:26:35.249068\n",
            "Training: batch 1451 begins at 08:26:35.256682\n",
            "Training: batch 1452 begins at 08:26:35.262205\n",
            "Training: batch 1453 begins at 08:26:35.269389\n",
            "Training: batch 1454 begins at 08:26:35.278818\n",
            "Training: batch 1455 begins at 08:26:35.284314\n",
            "1456/1875 [======================>.......] - ETA: 3s - loss: 0.2541 - accuracy: 0.9043Training: batch 1456 begins at 08:26:35.294773\n",
            "Training: batch 1457 begins at 08:26:35.299947\n",
            "Training: batch 1458 begins at 08:26:35.307487\n",
            "Training: batch 1459 begins at 08:26:35.313079\n",
            "Training: batch 1460 begins at 08:26:35.321769\n",
            "Training: batch 1461 begins at 08:26:35.327219\n",
            "Training: batch 1462 begins at 08:26:35.332590\n",
            "1463/1875 [======================>.......] - ETA: 3s - loss: 0.2541 - accuracy: 0.9044Training: batch 1463 begins at 08:26:35.346578\n",
            "Training: batch 1464 begins at 08:26:35.351997\n",
            "Training: batch 1465 begins at 08:26:35.361360\n",
            "Training: batch 1466 begins at 08:26:35.366669\n",
            "Training: batch 1467 begins at 08:26:35.374336\n",
            "Training: batch 1468 begins at 08:26:35.381830\n",
            "Training: batch 1469 begins at 08:26:35.387327\n",
            "1470/1875 [======================>.......] - ETA: 3s - loss: 0.2540 - accuracy: 0.9044Training: batch 1470 begins at 08:26:35.401772\n",
            "Training: batch 1471 begins at 08:26:35.408640\n",
            "Training: batch 1472 begins at 08:26:35.417892\n",
            "Training: batch 1473 begins at 08:26:35.429742\n",
            "Training: batch 1474 begins at 08:26:35.442043\n",
            "1475/1875 [======================>.......] - ETA: 3s - loss: 0.2542 - accuracy: 0.9044Training: batch 1475 begins at 08:26:35.453566\n",
            "Training: batch 1476 begins at 08:26:35.460749\n",
            "Training: batch 1477 begins at 08:26:35.468763\n",
            "Training: batch 1478 begins at 08:26:35.477503\n",
            "Training: batch 1479 begins at 08:26:35.489998\n",
            "Training: batch 1480 begins at 08:26:35.499138\n",
            "1481/1875 [======================>.......] - ETA: 3s - loss: 0.2542 - accuracy: 0.9044Training: batch 1481 begins at 08:26:35.511891\n",
            "Training: batch 1482 begins at 08:26:35.518803\n",
            "Training: batch 1483 begins at 08:26:35.526757\n",
            "Training: batch 1484 begins at 08:26:35.532729\n",
            "Training: batch 1485 begins at 08:26:35.540396\n",
            "Training: batch 1486 begins at 08:26:35.550962\n",
            "Training: batch 1487 begins at 08:26:35.558798\n",
            "1488/1875 [======================>.......] - ETA: 3s - loss: 0.2542 - accuracy: 0.9044Training: batch 1488 begins at 08:26:35.572362\n",
            "Training: batch 1489 begins at 08:26:35.581109\n",
            "Training: batch 1490 begins at 08:26:35.586166\n",
            "Training: batch 1491 begins at 08:26:35.591791\n",
            "Training: batch 1492 begins at 08:26:35.601524\n",
            "Training: batch 1493 begins at 08:26:35.611375\n",
            "1494/1875 [======================>.......] - ETA: 3s - loss: 0.2544 - accuracy: 0.9043Training: batch 1494 begins at 08:26:35.622638\n",
            "Training: batch 1495 begins at 08:26:35.630374\n",
            "Training: batch 1496 begins at 08:26:35.639368\n",
            "Training: batch 1497 begins at 08:26:35.645344\n",
            "Training: batch 1498 begins at 08:26:35.652710\n",
            "Training: batch 1499 begins at 08:26:35.658361\n",
            "Training: batch 1500 begins at 08:26:35.666271\n",
            "1501/1875 [=======================>......] - ETA: 3s - loss: 0.2543 - accuracy: 0.9044Training: batch 1501 begins at 08:26:35.674579\n",
            "Training: batch 1502 begins at 08:26:35.685448\n",
            "Training: batch 1503 begins at 08:26:35.693601\n",
            "Training: batch 1504 begins at 08:26:35.700599\n",
            "Training: batch 1505 begins at 08:26:35.708673\n",
            "Training: batch 1506 begins at 08:26:35.715529\n",
            "1507/1875 [=======================>......] - ETA: 2s - loss: 0.2544 - accuracy: 0.9043Training: batch 1507 begins at 08:26:35.727255\n",
            "Training: batch 1508 begins at 08:26:35.732742\n",
            "Training: batch 1509 begins at 08:26:35.740354\n",
            "Training: batch 1510 begins at 08:26:35.749748\n",
            "Training: batch 1511 begins at 08:26:35.757254\n",
            "Training: batch 1512 begins at 08:26:35.767896\n",
            "1513/1875 [=======================>......] - ETA: 2s - loss: 0.2543 - accuracy: 0.9043Training: batch 1513 begins at 08:26:35.780414\n",
            "Training: batch 1514 begins at 08:26:35.787013\n",
            "Training: batch 1515 begins at 08:26:35.794034\n",
            "Training: batch 1516 begins at 08:26:35.804769\n",
            "Training: batch 1517 begins at 08:26:35.812516\n",
            "Training: batch 1518 begins at 08:26:35.821788\n",
            "1519/1875 [=======================>......] - ETA: 2s - loss: 0.2546 - accuracy: 0.9041Training: batch 1519 begins at 08:26:35.834393\n",
            "Training: batch 1520 begins at 08:26:35.841811\n",
            "Training: batch 1521 begins at 08:26:35.850491\n",
            "Training: batch 1522 begins at 08:26:35.858424\n",
            "Training: batch 1523 begins at 08:26:35.865736\n",
            "Training: batch 1524 begins at 08:26:35.871266\n",
            "Training: batch 1525 begins at 08:26:35.876121\n",
            "1526/1875 [=======================>......] - ETA: 2s - loss: 0.2545 - accuracy: 0.9041Training: batch 1526 begins at 08:26:35.888007\n",
            "Training: batch 1527 begins at 08:26:35.893503\n",
            "Training: batch 1528 begins at 08:26:35.900238\n",
            "Training: batch 1529 begins at 08:26:35.907235\n",
            "Training: batch 1530 begins at 08:26:35.912673\n",
            "Training: batch 1531 begins at 08:26:35.917840\n",
            "Training: batch 1532 begins at 08:26:35.923190\n",
            "Training: batch 1533 begins at 08:26:35.931602\n",
            "1534/1875 [=======================>......] - ETA: 2s - loss: 0.2543 - accuracy: 0.9043Training: batch 1534 begins at 08:26:35.943285\n",
            "Training: batch 1535 begins at 08:26:35.947852\n",
            "Training: batch 1536 begins at 08:26:35.953703\n",
            "Training: batch 1537 begins at 08:26:35.958977\n",
            "Training: batch 1538 begins at 08:26:35.964298\n",
            "Training: batch 1539 begins at 08:26:35.973758\n",
            "Training: batch 1540 begins at 08:26:35.980841\n",
            "1541/1875 [=======================>......] - ETA: 2s - loss: 0.2546 - accuracy: 0.9041Training: batch 1541 begins at 08:26:35.992025\n",
            "Training: batch 1542 begins at 08:26:36.000198\n",
            "Training: batch 1543 begins at 08:26:36.010376\n",
            "Training: batch 1544 begins at 08:26:36.019961\n",
            "Training: batch 1545 begins at 08:26:36.026850\n",
            "Training: batch 1546 begins at 08:26:36.036389\n",
            "1547/1875 [=======================>......] - ETA: 2s - loss: 0.2544 - accuracy: 0.9043Training: batch 1547 begins at 08:26:36.046286\n",
            "Training: batch 1548 begins at 08:26:36.051833\n",
            "Training: batch 1549 begins at 08:26:36.056864\n",
            "Training: batch 1550 begins at 08:26:36.065622\n",
            "Training: batch 1551 begins at 08:26:36.073089\n",
            "Training: batch 1552 begins at 08:26:36.078573\n",
            "Training: batch 1553 begins at 08:26:36.083177\n",
            "1554/1875 [=======================>......] - ETA: 2s - loss: 0.2542 - accuracy: 0.9043Training: batch 1554 begins at 08:26:36.095284\n",
            "Training: batch 1555 begins at 08:26:36.102081\n",
            "Training: batch 1556 begins at 08:26:36.107978\n",
            "Training: batch 1557 begins at 08:26:36.114937\n",
            "Training: batch 1558 begins at 08:26:36.120868\n",
            "Training: batch 1559 begins at 08:26:36.131566\n",
            "Training: batch 1560 begins at 08:26:36.142097\n",
            "1561/1875 [=======================>......] - ETA: 2s - loss: 0.2544 - accuracy: 0.9041Training: batch 1561 begins at 08:26:36.152544\n",
            "Training: batch 1562 begins at 08:26:36.160941\n",
            "Training: batch 1563 begins at 08:26:36.166847\n",
            "Training: batch 1564 begins at 08:26:36.175381\n",
            "Training: batch 1565 begins at 08:26:36.182822\n",
            "Training: batch 1566 begins at 08:26:36.191861\n",
            "1567/1875 [========================>.....] - ETA: 2s - loss: 0.2544 - accuracy: 0.9041Training: batch 1567 begins at 08:26:36.202622\n",
            "Training: batch 1568 begins at 08:26:36.211998\n",
            "Training: batch 1569 begins at 08:26:36.219023\n",
            "Training: batch 1570 begins at 08:26:36.226873\n",
            "Training: batch 1571 begins at 08:26:36.235975\n",
            "Training: batch 1572 begins at 08:26:36.244677\n",
            "1573/1875 [========================>.....] - ETA: 2s - loss: 0.2542 - accuracy: 0.9041Training: batch 1573 begins at 08:26:36.255430\n",
            "Training: batch 1574 begins at 08:26:36.261755\n",
            "Training: batch 1575 begins at 08:26:36.270882\n",
            "Training: batch 1576 begins at 08:26:36.276890\n",
            "Training: batch 1577 begins at 08:26:36.282829\n",
            "Training: batch 1578 begins at 08:26:36.289764\n",
            "Training: batch 1579 begins at 08:26:36.296017\n",
            "1580/1875 [========================>.....] - ETA: 2s - loss: 0.2548 - accuracy: 0.9040Training: batch 1580 begins at 08:26:36.309308\n",
            "Training: batch 1581 begins at 08:26:36.316070\n",
            "Training: batch 1582 begins at 08:26:36.322796\n",
            "Training: batch 1583 begins at 08:26:36.329100\n",
            "Training: batch 1584 begins at 08:26:36.338291\n",
            "Training: batch 1585 begins at 08:26:36.346673\n",
            "1586/1875 [========================>.....] - ETA: 2s - loss: 0.2546 - accuracy: 0.9041Training: batch 1586 begins at 08:26:36.361377\n",
            "Training: batch 1587 begins at 08:26:36.368508\n",
            "Training: batch 1588 begins at 08:26:36.378408\n",
            "Training: batch 1589 begins at 08:26:36.387248\n",
            "Training: batch 1590 begins at 08:26:36.392964\n",
            "Training: batch 1591 begins at 08:26:36.403547\n",
            "1592/1875 [========================>.....] - ETA: 2s - loss: 0.2547 - accuracy: 0.9041Training: batch 1592 begins at 08:26:36.409974\n",
            "Training: batch 1593 begins at 08:26:36.417312\n",
            "Training: batch 1594 begins at 08:26:36.422223\n",
            "Training: batch 1595 begins at 08:26:36.431304\n",
            "Training: batch 1596 begins at 08:26:36.437962\n",
            "Training: batch 1597 begins at 08:26:36.442504\n",
            "Training: batch 1598 begins at 08:26:36.451967\n",
            "1599/1875 [========================>.....] - ETA: 2s - loss: 0.2545 - accuracy: 0.9042Training: batch 1599 begins at 08:26:36.462215\n",
            "Training: batch 1600 begins at 08:26:36.467084\n",
            "Training: batch 1601 begins at 08:26:36.473821\n",
            "Training: batch 1602 begins at 08:26:36.482267\n",
            "Training: batch 1603 begins at 08:26:36.488699\n",
            "Training: batch 1604 begins at 08:26:36.496184\n",
            "Training: batch 1605 begins at 08:26:36.500166\n",
            "Training: batch 1606 begins at 08:26:36.508078\n",
            "1607/1875 [========================>.....] - ETA: 2s - loss: 0.2546 - accuracy: 0.9041Training: batch 1607 begins at 08:26:36.518271\n",
            "Training: batch 1608 begins at 08:26:36.525777\n",
            "Training: batch 1609 begins at 08:26:36.532043\n",
            "Training: batch 1610 begins at 08:26:36.542060\n",
            "Training: batch 1611 begins at 08:26:36.548458\n",
            "Training: batch 1612 begins at 08:26:36.557158\n",
            "Training: batch 1613 begins at 08:26:36.563380\n",
            "1614/1875 [========================>.....] - ETA: 2s - loss: 0.2545 - accuracy: 0.9041Training: batch 1614 begins at 08:26:36.573753\n",
            "Training: batch 1615 begins at 08:26:36.582497\n",
            "Training: batch 1616 begins at 08:26:36.588038\n",
            "Training: batch 1617 begins at 08:26:36.595009\n",
            "Training: batch 1618 begins at 08:26:36.601845\n",
            "Training: batch 1619 begins at 08:26:36.607099\n",
            "Training: batch 1620 begins at 08:26:36.618093\n",
            "1621/1875 [========================>.....] - ETA: 2s - loss: 0.2543 - accuracy: 0.9041Training: batch 1621 begins at 08:26:36.624692\n",
            "Training: batch 1622 begins at 08:26:36.633721\n",
            "Training: batch 1623 begins at 08:26:36.641994\n",
            "Training: batch 1624 begins at 08:26:36.647963\n",
            "Training: batch 1625 begins at 08:26:36.656807\n",
            "Training: batch 1626 begins at 08:26:36.665791\n",
            "Training: batch 1627 begins at 08:26:36.672797\n",
            "1628/1875 [=========================>....] - ETA: 2s - loss: 0.2542 - accuracy: 0.9042Training: batch 1628 begins at 08:26:36.683073\n",
            "Training: batch 1629 begins at 08:26:36.690015\n",
            "Training: batch 1630 begins at 08:26:36.697243\n",
            "Training: batch 1631 begins at 08:26:36.704273\n",
            "Training: batch 1632 begins at 08:26:36.712748\n",
            "Training: batch 1633 begins at 08:26:36.718790\n",
            "Training: batch 1634 begins at 08:26:36.728400\n",
            "1635/1875 [=========================>....] - ETA: 1s - loss: 0.2542 - accuracy: 0.9041Training: batch 1635 begins at 08:26:36.736758\n",
            "Training: batch 1636 begins at 08:26:36.745235\n",
            "Training: batch 1637 begins at 08:26:36.752982\n",
            "Training: batch 1638 begins at 08:26:36.759323\n",
            "Training: batch 1639 begins at 08:26:36.766366\n",
            "Training: batch 1640 begins at 08:26:36.773100\n",
            "Training: batch 1641 begins at 08:26:36.783036\n",
            "1642/1875 [=========================>....] - ETA: 1s - loss: 0.2538 - accuracy: 0.9043Training: batch 1642 begins at 08:26:36.796211\n",
            "Training: batch 1643 begins at 08:26:36.803638\n",
            "Training: batch 1644 begins at 08:26:36.812901\n",
            "Training: batch 1645 begins at 08:26:36.819346\n",
            "Training: batch 1646 begins at 08:26:36.828730\n",
            "Training: batch 1647 begins at 08:26:36.838128\n",
            "1648/1875 [=========================>....] - ETA: 1s - loss: 0.2539 - accuracy: 0.9043Training: batch 1648 begins at 08:26:36.851117\n",
            "Training: batch 1649 begins at 08:26:36.857284\n",
            "Training: batch 1650 begins at 08:26:36.866429\n",
            "Training: batch 1651 begins at 08:26:36.875178\n",
            "Training: batch 1652 begins at 08:26:36.883515\n",
            "Training: batch 1653 begins at 08:26:36.891500\n",
            "1654/1875 [=========================>....] - ETA: 1s - loss: 0.2538 - accuracy: 0.9043Training: batch 1654 begins at 08:26:36.901998\n",
            "Training: batch 1655 begins at 08:26:36.907984\n",
            "Training: batch 1656 begins at 08:26:36.917803\n",
            "Training: batch 1657 begins at 08:26:36.925739\n",
            "Training: batch 1658 begins at 08:26:36.933623\n",
            "Training: batch 1659 begins at 08:26:36.941078\n",
            "Training: batch 1660 begins at 08:26:36.949080\n",
            "1661/1875 [=========================>....] - ETA: 1s - loss: 0.2539 - accuracy: 0.9042Training: batch 1661 begins at 08:26:36.960159\n",
            "Training: batch 1662 begins at 08:26:36.967521\n",
            "Training: batch 1663 begins at 08:26:36.976793\n",
            "Training: batch 1664 begins at 08:26:36.982399\n",
            "Training: batch 1665 begins at 08:26:36.989264\n",
            "Training: batch 1666 begins at 08:26:36.996937\n",
            "Training: batch 1667 begins at 08:26:37.002918\n",
            "1668/1875 [=========================>....] - ETA: 1s - loss: 0.2540 - accuracy: 0.9041Training: batch 1668 begins at 08:26:37.014227\n",
            "Training: batch 1669 begins at 08:26:37.021983\n",
            "Training: batch 1670 begins at 08:26:37.028930\n",
            "Training: batch 1671 begins at 08:26:37.037414\n",
            "Training: batch 1672 begins at 08:26:37.045558\n",
            "Training: batch 1673 begins at 08:26:37.051582\n",
            "Training: batch 1674 begins at 08:26:37.061363\n",
            "1675/1875 [=========================>....] - ETA: 1s - loss: 0.2543 - accuracy: 0.9039Training: batch 1675 begins at 08:26:37.069535\n",
            "Training: batch 1676 begins at 08:26:37.078716\n",
            "Training: batch 1677 begins at 08:26:37.086898\n",
            "Training: batch 1678 begins at 08:26:37.092688\n",
            "Training: batch 1679 begins at 08:26:37.101904\n",
            "Training: batch 1680 begins at 08:26:37.108775\n",
            "Training: batch 1681 begins at 08:26:37.114491\n",
            "1682/1875 [=========================>....] - ETA: 1s - loss: 0.2546 - accuracy: 0.9039Training: batch 1682 begins at 08:26:37.122795\n",
            "Training: batch 1683 begins at 08:26:37.131882\n",
            "Training: batch 1684 begins at 08:26:37.138753\n",
            "Training: batch 1685 begins at 08:26:37.145546\n",
            "Training: batch 1686 begins at 08:26:37.152809\n",
            "Training: batch 1687 begins at 08:26:37.159017\n",
            "Training: batch 1688 begins at 08:26:37.169787\n",
            "1689/1875 [==========================>...] - ETA: 1s - loss: 0.2545 - accuracy: 0.9039Training: batch 1689 begins at 08:26:37.177634\n",
            "Training: batch 1690 begins at 08:26:37.186770\n",
            "Training: batch 1691 begins at 08:26:37.192671\n",
            "Training: batch 1692 begins at 08:26:37.198262\n",
            "Training: batch 1693 begins at 08:26:37.205880\n",
            "Training: batch 1694 begins at 08:26:37.212266\n",
            "Training: batch 1695 begins at 08:26:37.218977\n",
            "1696/1875 [==========================>...] - ETA: 1s - loss: 0.2545 - accuracy: 0.9039Training: batch 1696 begins at 08:26:37.228574\n",
            "Training: batch 1697 begins at 08:26:37.237251\n",
            "Training: batch 1698 begins at 08:26:37.244642\n",
            "Training: batch 1699 begins at 08:26:37.252046\n",
            "Training: batch 1700 begins at 08:26:37.259669\n",
            "Training: batch 1701 begins at 08:26:37.266593\n",
            "Training: batch 1702 begins at 08:26:37.274452\n",
            "1703/1875 [==========================>...] - ETA: 1s - loss: 0.2548 - accuracy: 0.9039Training: batch 1703 begins at 08:26:37.283817\n",
            "Training: batch 1704 begins at 08:26:37.291668\n",
            "Training: batch 1705 begins at 08:26:37.298482\n",
            "Training: batch 1706 begins at 08:26:37.305635\n",
            "Training: batch 1707 begins at 08:26:37.311954\n",
            "Training: batch 1708 begins at 08:26:37.318193\n",
            "Training: batch 1709 begins at 08:26:37.325070\n",
            "Training: batch 1710 begins at 08:26:37.331460\n",
            "1711/1875 [==========================>...] - ETA: 1s - loss: 0.2546 - accuracy: 0.9040Training: batch 1711 begins at 08:26:37.341017\n",
            "Training: batch 1712 begins at 08:26:37.348297\n",
            "Training: batch 1713 begins at 08:26:37.355759\n",
            "Training: batch 1714 begins at 08:26:37.362672\n",
            "Training: batch 1715 begins at 08:26:37.369842\n",
            "Training: batch 1716 begins at 08:26:37.376950\n",
            "Training: batch 1717 begins at 08:26:37.386835\n",
            "1718/1875 [==========================>...] - ETA: 1s - loss: 0.2546 - accuracy: 0.9040Training: batch 1718 begins at 08:26:37.395253\n",
            "Training: batch 1719 begins at 08:26:37.401626\n",
            "Training: batch 1720 begins at 08:26:37.408636\n",
            "Training: batch 1721 begins at 08:26:37.415289\n",
            "Training: batch 1722 begins at 08:26:37.421576\n",
            "Training: batch 1723 begins at 08:26:37.428468\n",
            "Training: batch 1724 begins at 08:26:37.437013\n",
            "Training: batch 1725 begins at 08:26:37.443354\n",
            "1726/1875 [==========================>...] - ETA: 1s - loss: 0.2544 - accuracy: 0.9041Training: batch 1726 begins at 08:26:37.452604\n",
            "Training: batch 1727 begins at 08:26:37.465782\n",
            "Training: batch 1728 begins at 08:26:37.473109\n",
            "Training: batch 1729 begins at 08:26:37.480362\n",
            "Training: batch 1730 begins at 08:26:37.487774\n",
            "Training: batch 1731 begins at 08:26:37.494955\n",
            "1732/1875 [==========================>...] - ETA: 1s - loss: 0.2546 - accuracy: 0.9040Training: batch 1732 begins at 08:26:37.503221\n",
            "Training: batch 1733 begins at 08:26:37.512352\n",
            "Training: batch 1734 begins at 08:26:37.524054\n",
            "Training: batch 1735 begins at 08:26:37.530508\n",
            "Training: batch 1736 begins at 08:26:37.536710\n",
            "Training: batch 1737 begins at 08:26:37.543141\n",
            "Training: batch 1738 begins at 08:26:37.550690\n",
            "1739/1875 [==========================>...] - ETA: 1s - loss: 0.2547 - accuracy: 0.9039Training: batch 1739 begins at 08:26:37.561364\n",
            "Training: batch 1740 begins at 08:26:37.571666\n",
            "Training: batch 1741 begins at 08:26:37.578918\n",
            "Training: batch 1742 begins at 08:26:37.584877\n",
            "Training: batch 1743 begins at 08:26:37.591477\n",
            "Training: batch 1744 begins at 08:26:37.598001\n",
            "Training: batch 1745 begins at 08:26:37.607346\n",
            "1746/1875 [==========================>...] - ETA: 1s - loss: 0.2548 - accuracy: 0.9039Training: batch 1746 begins at 08:26:37.615818\n",
            "Training: batch 1747 begins at 08:26:37.626666\n",
            "Training: batch 1748 begins at 08:26:37.636895\n",
            "Training: batch 1749 begins at 08:26:37.643761\n",
            "Training: batch 1750 begins at 08:26:37.650133\n",
            "Training: batch 1751 begins at 08:26:37.656905\n",
            "1752/1875 [===========================>..] - ETA: 0s - loss: 0.2546 - accuracy: 0.9040Training: batch 1752 begins at 08:26:37.666357\n",
            "Training: batch 1753 begins at 08:26:37.677845\n",
            "Training: batch 1754 begins at 08:26:37.684956\n",
            "Training: batch 1755 begins at 08:26:37.692597\n",
            "Training: batch 1756 begins at 08:26:37.699715\n",
            "Training: batch 1757 begins at 08:26:37.706800\n",
            "Training: batch 1758 begins at 08:26:37.713080\n",
            "1759/1875 [===========================>..] - ETA: 0s - loss: 0.2546 - accuracy: 0.9040Training: batch 1759 begins at 08:26:37.723375\n",
            "Training: batch 1760 begins at 08:26:37.730849\n",
            "Training: batch 1761 begins at 08:26:37.738172\n",
            "Training: batch 1762 begins at 08:26:37.745302\n",
            "Training: batch 1763 begins at 08:26:37.751621\n",
            "Training: batch 1764 begins at 08:26:37.759205\n",
            "Training: batch 1765 begins at 08:26:37.766623\n",
            "1766/1875 [===========================>..] - ETA: 0s - loss: 0.2546 - accuracy: 0.9041Training: batch 1766 begins at 08:26:37.775704\n",
            "Training: batch 1767 begins at 08:26:37.783791\n",
            "Training: batch 1768 begins at 08:26:37.791109\n",
            "Training: batch 1769 begins at 08:26:37.799766\n",
            "Training: batch 1770 begins at 08:26:37.806575\n",
            "Training: batch 1771 begins at 08:26:37.812617\n",
            "Training: batch 1772 begins at 08:26:37.819766\n",
            "1773/1875 [===========================>..] - ETA: 0s - loss: 0.2548 - accuracy: 0.9041Training: batch 1773 begins at 08:26:37.827796\n",
            "Training: batch 1774 begins at 08:26:37.834683\n",
            "Training: batch 1775 begins at 08:26:37.841935\n",
            "Training: batch 1776 begins at 08:26:37.848468\n",
            "Training: batch 1777 begins at 08:26:37.854910\n",
            "Training: batch 1778 begins at 08:26:37.863896\n",
            "Training: batch 1779 begins at 08:26:37.872403\n",
            "1780/1875 [===========================>..] - ETA: 0s - loss: 0.2546 - accuracy: 0.9041Training: batch 1780 begins at 08:26:37.882737\n",
            "Training: batch 1781 begins at 08:26:37.893310\n",
            "Training: batch 1782 begins at 08:26:37.900428\n",
            "Training: batch 1783 begins at 08:26:37.909818\n",
            "Training: batch 1784 begins at 08:26:37.916340\n",
            "Training: batch 1785 begins at 08:26:37.923702\n",
            "1786/1875 [===========================>..] - ETA: 0s - loss: 0.2545 - accuracy: 0.9042Training: batch 1786 begins at 08:26:37.935894\n",
            "Training: batch 1787 begins at 08:26:37.945081\n",
            "Training: batch 1788 begins at 08:26:37.951734\n",
            "Training: batch 1789 begins at 08:26:37.958754\n",
            "Training: batch 1790 begins at 08:26:37.966002\n",
            "Training: batch 1791 begins at 08:26:37.972468\n",
            "Training: batch 1792 begins at 08:26:37.979815\n",
            "1793/1875 [===========================>..] - ETA: 0s - loss: 0.2548 - accuracy: 0.9041Training: batch 1793 begins at 08:26:37.988831\n",
            "Training: batch 1794 begins at 08:26:37.998797\n",
            "Training: batch 1795 begins at 08:26:38.005878\n",
            "Training: batch 1796 begins at 08:26:38.012878\n",
            "Training: batch 1797 begins at 08:26:38.019394\n",
            "Training: batch 1798 begins at 08:26:38.027433\n",
            "Training: batch 1799 begins at 08:26:38.035819\n",
            "1800/1875 [===========================>..] - ETA: 0s - loss: 0.2552 - accuracy: 0.9040Training: batch 1800 begins at 08:26:38.044050\n",
            "Training: batch 1801 begins at 08:26:38.051801\n",
            "Training: batch 1802 begins at 08:26:38.058110\n",
            "Training: batch 1803 begins at 08:26:38.064453\n",
            "Training: batch 1804 begins at 08:26:38.072092\n",
            "Training: batch 1805 begins at 08:26:38.078944\n",
            "Training: batch 1806 begins at 08:26:38.086861\n",
            "1807/1875 [===========================>..] - ETA: 0s - loss: 0.2555 - accuracy: 0.9040Training: batch 1807 begins at 08:26:38.102966\n",
            "Training: batch 1808 begins at 08:26:38.119285\n",
            "Training: batch 1809 begins at 08:26:38.127003\n",
            "Training: batch 1810 begins at 08:26:38.133891\n",
            "Training: batch 1811 begins at 08:26:38.142271\n",
            "Training: batch 1812 begins at 08:26:38.149849\n",
            "1813/1875 [============================>.] - ETA: 0s - loss: 0.2555 - accuracy: 0.9040Training: batch 1813 begins at 08:26:38.160408\n",
            "Training: batch 1814 begins at 08:26:38.169432\n",
            "Training: batch 1815 begins at 08:26:38.176087\n",
            "Training: batch 1816 begins at 08:26:38.184939\n",
            "Training: batch 1817 begins at 08:26:38.192308\n",
            "Training: batch 1818 begins at 08:26:38.198965\n",
            "Training: batch 1819 begins at 08:26:38.206140\n",
            "1820/1875 [============================>.] - ETA: 0s - loss: 0.2554 - accuracy: 0.9041Training: batch 1820 begins at 08:26:38.215619\n",
            "Training: batch 1821 begins at 08:26:38.222578\n",
            "Training: batch 1822 begins at 08:26:38.234868\n",
            "Training: batch 1823 begins at 08:26:38.241802\n",
            "Training: batch 1824 begins at 08:26:38.249475\n",
            "Training: batch 1825 begins at 08:26:38.257415\n",
            "1826/1875 [============================>.] - ETA: 0s - loss: 0.2554 - accuracy: 0.9041Training: batch 1826 begins at 08:26:38.269650\n",
            "Training: batch 1827 begins at 08:26:38.281109\n",
            "Training: batch 1828 begins at 08:26:38.289490\n",
            "Training: batch 1829 begins at 08:26:38.296721\n",
            "Training: batch 1830 begins at 08:26:38.305070\n",
            "Training: batch 1831 begins at 08:26:38.311806\n",
            "1832/1875 [============================>.] - ETA: 0s - loss: 0.2553 - accuracy: 0.9042Training: batch 1832 begins at 08:26:38.321364\n",
            "Training: batch 1833 begins at 08:26:38.328079\n",
            "Training: batch 1834 begins at 08:26:38.336848\n",
            "Training: batch 1835 begins at 08:26:38.344685\n",
            "Training: batch 1836 begins at 08:26:38.351386\n",
            "Training: batch 1837 begins at 08:26:38.357836\n",
            "Training: batch 1838 begins at 08:26:38.365683\n",
            "1839/1875 [============================>.] - ETA: 0s - loss: 0.2560 - accuracy: 0.9040Training: batch 1839 begins at 08:26:38.374100\n",
            "Training: batch 1840 begins at 08:26:38.380932\n",
            "Training: batch 1841 begins at 08:26:38.388883\n",
            "Training: batch 1842 begins at 08:26:38.396350\n",
            "Training: batch 1843 begins at 08:26:38.402750\n",
            "Training: batch 1844 begins at 08:26:38.410637\n",
            "Training: batch 1845 begins at 08:26:38.416602\n",
            "1846/1875 [============================>.] - ETA: 0s - loss: 0.2559 - accuracy: 0.9040Training: batch 1846 begins at 08:26:38.425468\n",
            "Training: batch 1847 begins at 08:26:38.432817\n",
            "Training: batch 1848 begins at 08:26:38.440310\n",
            "Training: batch 1849 begins at 08:26:38.447321\n",
            "Training: batch 1850 begins at 08:26:38.454848\n",
            "Training: batch 1851 begins at 08:26:38.462433\n",
            "Training: batch 1852 begins at 08:26:38.470442\n",
            "1853/1875 [============================>.] - ETA: 0s - loss: 0.2558 - accuracy: 0.9040Training: batch 1853 begins at 08:26:38.483004\n",
            "Training: batch 1854 begins at 08:26:38.488675\n",
            "Training: batch 1855 begins at 08:26:38.495374\n",
            "Training: batch 1856 begins at 08:26:38.504291\n",
            "Training: batch 1857 begins at 08:26:38.509823\n",
            "Training: batch 1858 begins at 08:26:38.517912\n",
            "Training: batch 1859 begins at 08:26:38.525091\n",
            "1860/1875 [============================>.] - ETA: 0s - loss: 0.2556 - accuracy: 0.9040Training: batch 1860 begins at 08:26:38.535383\n",
            "Training: batch 1861 begins at 08:26:38.541852\n",
            "Training: batch 1862 begins at 08:26:38.550867\n",
            "Training: batch 1863 begins at 08:26:38.556725\n",
            "Training: batch 1864 begins at 08:26:38.563014\n",
            "Training: batch 1865 begins at 08:26:38.570487\n",
            "Training: batch 1866 begins at 08:26:38.583431\n",
            "1867/1875 [============================>.] - ETA: 0s - loss: 0.2554 - accuracy: 0.9041Training: batch 1867 begins at 08:26:38.592097\n",
            "Training: batch 1868 begins at 08:26:38.599236\n",
            "Training: batch 1869 begins at 08:26:38.605206\n",
            "Training: batch 1870 begins at 08:26:38.611933\n",
            "Training: batch 1871 begins at 08:26:38.620175\n",
            "Training: batch 1872 begins at 08:26:38.627989\n",
            "Training: batch 1873 begins at 08:26:38.636747\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.2553 - accuracy: 0.9040Training: batch 1874 begins at 08:26:38.648062\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2552 - accuracy: 0.9041\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3d20789db0>"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(train_images,\n",
        "          train_labels,\n",
        "          epochs=10,\n",
        "          callbacks=[MyCustomCallback()])  ##, DetectOverfittingCallback()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCpr6DGyE28h"
      },
      "source": [
        "### Evaluate accuracy\n",
        "\n",
        "Next, compare how the model performs on the test dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VflXLEeECaXC",
        "outputId": "6f14ae5c-e577-4831-f4a2-7ede09c85911"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3380 - accuracy: 0.8834\n",
            "\n",
            "Test accuracy: 0.883400022983551\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=1)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-PyD1SYE28q"
      },
      "source": [
        "### Make predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gl91RPhdCaXI"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(test_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9Kk1voUCaXJ"
      },
      "source": [
        "Here, the model has predicted the label for each image in the testing set. Let's take a look at the first prediction:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DmJEUinCaXK"
      },
      "outputs": [],
      "source": [
        "predictions[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hw1hgeSCaXN"
      },
      "source": [
        "A prediction is an array of 10 numbers. They represent the model's \"confidence\" that the image corresponds to each of the 10 different articles of clothing. We can see which label has the highest confidence value:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "qsqenuPnCaXO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "057277a7-b30b-49b8-d2ce-2a02bceb1ada"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.argmax(predictions[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E51yS7iCCaXO"
      },
      "source": [
        "So, the model is most confident that this image is an ankle boot, or `class_names[9]`. Examining the test label shows that this classification is correct:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "Sd7Pgsu6CaXP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab35f5b5-b0c9-410f-eb15-5aebf224dc49"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_labels[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh9yABaME29S"
      },
      "source": [
        "### Verify predictions\n",
        "\n",
        "With the model trained, we can use it to make predictions about some images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "DvYmmrpIy6Y1"
      },
      "outputs": [],
      "source": [
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  true_label, img = true_label[i], img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "\n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color)\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  true_label = true_label[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks(range(10))\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
        "  plt.ylim([0, 1])\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('blue')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4Ov9OFDMmOD"
      },
      "source": [
        "Let's look at the 0th image, predictions, and prediction array.\n",
        "-  Correct prediction labels are blue ,and\n",
        "- incorrect prediction labels are red. The number gives the percentage (out of 100) for the predicted label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "HV5jw-5HwSmO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "outputId": "717a84bd-ac12-4902-8907-c0ae4e2f06f2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "i = 0\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions[i], test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions[i],  test_labels)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "Ko-uzOufSCSe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "outputId": "ec0d23cc-f260-4659-8615-f80f6b34d672"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "i = 12\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions[i], test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions[i],  test_labels)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgdvGD52CaXR"
      },
      "source": [
        "Let's plot several images with their predictions. Note that the model can be wrong even when very confident."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "hQlnbqaw2Qu_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "outputId": "fdfd96e3-be6e-4a70-e4fe-480c49e5dcf7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x1000 with 30 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot the first X test images, their predicted labels, and the true labels.\n",
        "# Color correct predictions in blue and incorrect predictions in red.\n",
        "num_rows = 5\n",
        "num_cols = 3\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, predictions[i], test_labels, test_images)\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "  plot_value_array(i, predictions[i], test_labels)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R32zteKHCaXT"
      },
      "source": [
        "## Use the trained model\n",
        "\n",
        "Finally, use the trained model to make a prediction about a single image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "yRJ7JU7JCaXT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb79a952-52fc-485c-b38e-5ffcd7176285"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(28, 28)\n"
          ]
        }
      ],
      "source": [
        "# Grab an image from the test dataset.\n",
        "img = test_images[1]\n",
        "\n",
        "print(img.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz3bVp21CaXV"
      },
      "source": [
        "`tf.keras` models are optimized to make predictions on a *batch*, or collection, of examples at once. Accordingly, even though you're using a single image, you need to add it to a list:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "lDFh5yF_CaXW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d23348f-8d92-46de-dc80-28b2908b7265"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "# Add the image to a batch where it's the only member.\n",
        "img = (np.expand_dims(img,0))\n",
        "\n",
        "print(img.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ5wLTkcCaXY"
      },
      "source": [
        "Now predict the correct label for this image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "o_rzNSdrCaXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5bbaa23-76d5-4473-8dfd-aafb951bfb19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 59ms/step\n",
            "[[3.4170755e-06 1.0594310e-10 9.9789435e-01 9.3825489e-11 1.7019744e-03\n",
            "  3.8703527e-15 4.0026469e-04 7.7889853e-20 6.4308781e-10 8.2844479e-18]]\n"
          ]
        }
      ],
      "source": [
        "predictions_single = model.predict(img)\n",
        "\n",
        "print(predictions_single)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "6Ai-cpLjO-3A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "9ff3c4f2-ebac-44de-d769-cb6091a6e22b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plot_value_array(1, predictions_single[0], test_labels)\n",
        "_ = plt.xticks(range(10), class_names, rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU1Y2OAMCaXb"
      },
      "source": [
        "`tf.keras.Model.predict` returns a list of listsâ€”one list for each image in the batch of data. Grab the predictions for our (only) image in the batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "2tRmdq_8CaXb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75c2dd99-e5c7-4215-abe9-08638cf7e428"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "np.argmax(predictions_single[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFc2HbEVCaXd"
      },
      "source": [
        "And the model predicts a label as expected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APQlP01Im4Vr"
      },
      "source": [
        "## Refrences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttn7Wc83m-t6"
      },
      "source": [
        "[Basic classification: Classify images of clothing | Tensorflow ](https://www.tensorflow.org/tutorials/keras/classification)\n",
        "\n",
        "[Custom Models, Layers, and Loss Functions with TensorFlow |\n",
        "DeepLearning.AI](https://www.coursera.org/learn/custom-distributed-training-with-tensorflow)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}